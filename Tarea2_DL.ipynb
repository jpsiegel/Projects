{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewTarea2-DL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qa3fduSBx5NE",
        "fLOcvDNreUb2",
        "FwHIlQr2ODVS",
        "j8xwUYMbsYdE",
        "pUVwQo6eCcC6"
      ],
      "authorship_tag": "ABX9TyPu0vMiKAT8eHiUM8MxBTEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpsiegel/Projects/blob/master/Tarea2_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3fduSBx5NE"
      },
      "source": [
        "#Tarea 2 Jan P. Siegel - Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mspk4ICBxny2",
        "outputId": "83b080e4-a925-415b-c0d1-9f8ae40ac822"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=3784e435ebafa058429429442362613700a9c6347b9cddca56f25c9e001d6094\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2063EAySx_qJ",
        "outputId": "b3c75ebe-6198-487c-94d8-88a8f9aa67c7"
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]  # Only one GPU on Colab and not guaranteed\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" | Used: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "  print(\"VRAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAM Free: 12.6 GB  | Used: 342.2 MB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xZ2AEIqG00P"
      },
      "source": [
        "##Parte 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZWm4FOUebL2"
      },
      "source": [
        "###Actividad 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUSA5oZ54TlW",
        "outputId": "ca8d1b1a-86ba-49ca-d27e-dc38056ae6f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "sms_data_path = '/content/drive/MyDrive/DL/T2/SMSSpamCollection'\n",
        "wikitext_data_path = '/content/drive/MyDrive/DL/T2/data/wikitext-2'\n",
        "quora_data_path = '/content/drive/MyDrive/DL/T2/quora.csv'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sEJcPW_A_-"
      },
      "source": [
        "!pip install d2l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KLHINtAN9qM",
        "outputId": "6d90a65b-a88c-4e4e-d65e-4f7f108fb9b5"
      },
      "source": [
        "# parse data set\n",
        "\n",
        "from string import punctuation\n",
        "from d2l import torch as d2l\n",
        "\n",
        "#  Reads sms data file\n",
        "raw_data = open(sms_data_path, \"r\")\n",
        "strings = raw_data.readlines()\n",
        "\n",
        "vocab_freq = {} # word : count\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for s in strings:\n",
        "  s = s.strip(\"\\n\")\n",
        "  listed = s.split(\"\\t\")\n",
        "  label = 1 if listed[0] == \"spam\" else 0 # 1 is spam and 0 is not spam\n",
        "  phrase = listed[1].lower()\n",
        "  phrase = \"\".join([c for c in phrase if c not in punctuation]) # eliminate punctuation\n",
        "  words = phrase.split(\" \")\n",
        "  for word in words:\n",
        "    try:\n",
        "      vocab_freq[word] += 1\n",
        "    except KeyError:\n",
        "      vocab_freq[word] = 1\n",
        "  data.append(words)\n",
        "  labels.append(label)\n",
        "\n",
        "vocab = list(vocab_freq.keys())\n",
        "list_len = [len(i) for i in data]\n",
        "longest_phrase = max(list_len)\n",
        "print(\"Data:\", data[:3]) # lists_of_words\n",
        "print(\"Labels:\", labels) # list of corresponding labels\n",
        "print(\"Vocab length:\", len(vocab), \"different words\") # vocabulary of 9662 words\n",
        "print(\"Longest phrase:\", longest_phrase, \"words\")\n",
        "print(\"Total data:\", len(data), \"labeled phrases\") # spamm: 747, no spamm: 4827\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: [['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat'], ['ok', 'lar', 'joking', 'wif', 'u', 'oni'], ['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'questionstd', 'txt', 'ratetcs', 'apply', '08452810075over18s']]\n",
            "Labels: [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
            "Vocab length: 9662 different words\n",
            "Longest phrase: 171 words\n",
            "Total data: 5574 labeled phrases\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jArACI_rQWlU"
      },
      "source": [
        "# obtain GloVe word embedding\n",
        "\n",
        "embedding_dim = \"100\" # dimensiones aceptadas 50, 100, 200, 300 (act 2 y 5)\n",
        "glove_embedding = d2l.TokenEmbedding(f'glove.6b.{embedding_dim}d') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pILAgK_UTok",
        "outputId": "d52c39f2-c9a0-46c0-fd1f-bd378f13b941"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "embeds = glove_embedding[vocab] # generate embedding for every word in vocabulary\n",
        "print(\"Embedding shape:\", embeds.shape) # we have 9662 vectors of 100 dims\n",
        "word_idx = vocab.index(\"go\")\n",
        "word_tensor = embeds[word_idx]\n",
        "\n",
        "# associate word with glove embedding\n",
        "embedding_dict = {} # { word: embedding_vector }\n",
        "for i in range(len(vocab)):\n",
        "  embedding_dict[list(vocab)[i]] = embeds[i]\n",
        "\n",
        "# parse from list of words to tensor for each phrase, padding included\n",
        "processed_data = []\n",
        "for p in range(len(data)): # phrase_idx\n",
        "  word_tensors = []\n",
        "  for w in range(len(data[p])): # word_idx\n",
        "    current_word = data[p][w]\n",
        "    word_idx = vocab.index(current_word)\n",
        "    word_tensor = embeds[word_idx] # word to tensor according to glove embedding\n",
        "    word_tensors.append(word_tensor)\n",
        "  # pasar a 1 tensor para toda la frase de dim largo_phrase x 100\n",
        "  phrase_tensor = torch.stack(word_tensors) # de [tensor.shape(1,100),tensor.shape(1,100)] a tensor.shape(2,1,100)\n",
        "  processed_data.append(phrase_tensor)\n",
        "  # con esto tengo un tensor(x,100) para cada frase, donde x es la cantidad de palabras en esa frase\n",
        "# finalmente dejamos todos los tensores del largo de la frase mas larga, paddeados con 0s\n",
        "padded_data = pad_sequence(processed_data, batch_first=True)\n",
        "\n",
        "print(data[:3]) # primera frase tiene 20 elems, padded deberia quedar con 171 que es frase mas larga\n",
        "print(processed_data[0].shape)\n",
        "print(padded_data[0].shape)\n",
        "print(padded_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding shape: torch.Size([9662, 100])\n",
            "[['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat'], ['ok', 'lar', 'joking', 'wif', 'u', 'oni'], ['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'questionstd', 'txt', 'ratetcs', 'apply', '08452810075over18s']]\n",
            "torch.Size([20, 100])\n",
            "torch.Size([171, 100])\n",
            "tensor([[-0.0789,  0.4616,  0.5778,  ...,  0.2635,  0.5940,  0.2674],\n",
            "        [-0.1100, -0.1945, -0.0746,  ...,  0.6600, -0.0406, -0.2722],\n",
            "        [-0.1955,  0.3734,  0.4894,  ...,  0.1966,  0.9504, -0.6675],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1vpHeC0iyFG",
        "outputId": "9ed65bd8-dbfc-4dc4-e3eb-fee32c45dfd9"
      },
      "source": [
        "# split data set \n",
        "\n",
        "split_frac = 0.8 # 80% train, 10% validation, 10% test\n",
        "amount = len(padded_data)\n",
        "\n",
        "train_x = padded_data[0:int(split_frac*amount)]\n",
        "train_y = labels[0:int(split_frac*amount)]\n",
        "remaining_x = padded_data[int(split_frac*amount):]\n",
        "remaining_y = labels[int(split_frac*amount):]\n",
        "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "test_y = remaining_y[int(len(remaining_y)*0.5):]\n",
        "\n",
        "print(len(train_x))\n",
        "print(len(valid_x))\n",
        "print(len(test_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4459\n",
            "557\n",
            "558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRl0lV4GejSO"
      },
      "source": [
        "La idea de implementar un embedding para las palabras es poder pasar de datos en texto a tensores vectoriales numéricos, esto permite expresar las palabras en un formato que les añada riqueza en su descripción semántica (haciendo que palabras similares tengan valores cercanos) y además las haga consumibles por un modelo de aprendizaje automático.\n",
        "\n",
        "En particular, GloVe no captura solamente las características estadísticas locales como Word2Vec, sino también las (Glo)bales para crear el (Ve)ctor deseado. Para lograr esto,  toma en cuenta relaciones semánticas locales, pero también deriva relaciones semánticas a partir de una matriz de co-ocurrencia, donde se indica qué tan probable es que una palabra aparezca en el contexto de otra. La gracia de GloVe es que puede expresar esta relación en un vector limpiamente con escasa pérdida de información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLOcvDNreUb2"
      },
      "source": [
        "###Actividad 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_1Dc6rS9Llv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8904fa-8f0b-433b-910f-f83a7342ff13"
      },
      "source": [
        "# OJOO Con Softmax y CrossEntropy la red no aprende nada, pero cuando pongo LogSoftMax con NLLoss la red empieza a aprender \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_dim, hidden_dim, num_layers, embedding_dict):\n",
        "    super().__init__() # input_dim es la dimension del x_t, es la dimension que te deja el embedding (glove)\n",
        "    self.hidden_dim = hidden_dim # dimensiones de h_t (capa oculta)\n",
        "    self.num_layers = num_layers # cantidad de capas (filas) ocultas\n",
        "    self.embedding_dict = embedding_dict # { word: embedding_vector }\n",
        "\n",
        "    self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "    self.fc1 = nn.Linear(hidden_dim, 60) # capa intermedia, de ht a st\n",
        "    self.activation = nn.ReLU()\n",
        "    self.linear_out = nn.Linear(60, 2) # de st a yt\n",
        "    self.softmax = nn.Softmax(2)  \n",
        "\n",
        "  # This method defines the forward pass of the RNN\n",
        "  def forward(self, input):\n",
        "    batch_size, _ = input.size()\n",
        "\n",
        "    # Initializing hidden state for first input\n",
        "    h0 = self.init_hidden(batch_size)\n",
        "    # Passing in the input and hidden state to obtain output\n",
        "    _, hidden_state = self.rnn(input.unsqueeze(2), h0)\n",
        "    out = self.linear_out(hidden_state.squeeze())\n",
        "    return out\n",
        "  \n",
        "  def forward(self, text, text_lengths):\n",
        "      \n",
        "    #text = [batch size,sent_length]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "    #packed sequence\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        \n",
        "    packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "    #hidden = [batch size, num layers * num directions,hid dim]\n",
        "    #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "    #concat the final forward and backward hidden state\n",
        "    hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "    #hidden = [batch size, hid dim * num directions]\n",
        "    dense_outputs=self.fc(hidden)\n",
        "\n",
        "    #Final activation function\n",
        "    outputs=self.act(dense_outputs)\n",
        "        \n",
        "    return outputs\n",
        "    \n",
        "  # This method generates the first hidden state of zeros for the forward pass\n",
        "  # This creates a tensor of zeros in the shape of our hidden states.\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
        "    return hidden\n",
        "\n",
        "rnn_model = RNN(input_dim=100, hidden_dim=80, num_layers=1, embedding_dict=embedding_dict)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "rnn_model.to(device)\n",
        "print(rnn_model)\n",
        "\n",
        "# No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(rnn_model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(100, 80, batch_first=True)\n",
            "  (fc1): Linear(in_features=80, out_features=60, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear_out): Linear(in_features=60, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=2)\n",
            ")\n",
            "The model has 19,542 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCYKabwqDasq"
      },
      "source": [
        "El número de parametros depende indirectamente del dataset utilizado, si usamos un dataset de texto muy grande y complejo, necesitaremos más dimensiones para obtener un buen embedding, lo que ser reflejará en la cantidad de parámetros de Wxh. Sin embargo, si se mantienen las dimensiones del embedding, la cantidad de parámetros no se verá afectada al cambiar de dataset.\n",
        "\n",
        "Entonces, podemos ver que se puede reducir la cantidad de parámetros de la red cambiando el embedding usado, por ejemplo si usamos GloVe con 50d (en vez de 100d), tendremos un tensor de 50 dimensiones para capturar las features de cada palabra, en vez de 100 dimensiones para cada palabra. Esto reducirá la cantidad de parámetros entrenables en W_xh, todo lo anterior sin alterar la dimensionalidad de la capa oculta h_t.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmCwjioKEeHd",
        "outputId": "48e22b23-c17f-4d38-c128-a9f592c3906f"
      },
      "source": [
        "new_rnn_model = RNN(input_dim=100, hidden_dim=120, num_layers=1, embedding_dict=embedding_dict)\n",
        "print(f'The new model has {count_parameters(new_rnn_model):,} trainable parameters')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The new model has 34,022 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUZ89RHFjIl"
      },
      "source": [
        "Al pasar de 80 a 120 en la dimension de la capa oculta h_t, vemos que la cantidad de parámetros pasa de 19542 a 34022, es decir, un aumento del 74% lo que es entendible puesto que un aumento en h_t implica incrementar la cantidad de parámetros para todas las transformaciones del modelo, es decir, para W_hx, W_hh y W_yh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwHIlQr2ODVS"
      },
      "source": [
        "#NUEVO INTENTO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5zDw_yNN6fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e353dca0-e939-4126-80fc-f08ffb86e965"
      },
      "source": [
        "# parse data set\n",
        "from string import punctuation\n",
        "\n",
        "#  Reads sms data file\n",
        "raw_data = open(sms_data_path, \"r\")\n",
        "strings = raw_data.readlines()\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for s in strings:\n",
        "  s = s.strip(\"\\n\")\n",
        "  listed = s.split(\"\\t\")\n",
        "  label = 1 if listed[0] == \"spam\" else 0 # 1 is spam and 0 is not spam\n",
        "  phrase = listed[1].lower()\n",
        "  phrase = \"\".join([c for c in phrase if c not in punctuation]) # eliminate punctuation\n",
        "  data.append(phrase)\n",
        "  labels.append(label)\n",
        "\n",
        "print(\"Data:\", data[:3]) # lists_of_words\n",
        "print(\"Labels:\", labels[:3]) # list of corresponding labels\n",
        "print(\"Total data:\", len(data), \"labeled phrases\") # spamm: 747, no spamm: 4827"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: ['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat', 'ok lar joking wif u oni', 'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s']\n",
            "Labels: [0, 0, 1]\n",
            "Total data: 5574 labeled phrases\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFgVupLxOtqv"
      },
      "source": [
        "# get all the words from review dataset\n",
        "\n",
        "all_sms = list()\n",
        "for text in data:\n",
        "  text = text.lower()\n",
        "  text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "  all_sms.append(text)\n",
        "all_text = \" \".join(all_sms)\n",
        "all_words = all_text.split()"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYTxs4iSO8r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ecdb41-3cc8-4d9a-82c2-d0cf6d2d08df"
      },
      "source": [
        "# Count all the words using Counter Method\n",
        "\n",
        "from collections import Counter \n",
        "\n",
        "count_words = Counter(all_words)\n",
        "total_words = len(all_words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "print(\"Top ten occuring words : \", sorted_words[:10])"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top ten occuring words :  [('to', 2251), ('i', 2239), ('you', 2128), ('a', 1442), ('the', 1333), ('u', 1132), ('and', 971), ('is', 893), ('in', 888), ('me', 791)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsGC_r7MPGT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e21ff6-8d1d-4d51-ec75-ac11f5a67645"
      },
      "source": [
        "# dictionary to convert words to Integers based on the number of occurrence of the word\n",
        "\n",
        "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n",
        "print(vocab_to_int)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'to': 1, 'i': 2, 'you': 3, 'a': 4, 'the': 5, 'u': 6, 'and': 7, 'is': 8, 'in': 9, 'me': 10, 'my': 11, 'for': 12, 'your': 13, 'it': 14, 'of': 15, 'call': 16, 'have': 17, 'on': 18, 'that': 19, 'are': 20, '2': 21, 'now': 22, 'im': 23, 'so': 24, 'not': 25, 'but': 26, 'or': 27, 'at': 28, 'can': 29, 'do': 30, 'ur': 31, 'get': 32, 'be': 33, 'will': 34, 'if': 35, 'with': 36, 'just': 37, 'we': 38, 'no': 39, 'this': 40, 'its': 41, 'up': 42, '4': 43, 'dont': 44, 'when': 45, 'go': 46, 'ok': 47, 'from': 48, 'ltgt': 49, 'free': 50, 'all': 51, 'out': 52, 'how': 53, 'what': 54, 'know': 55, 'like': 56, 'got': 57, 'ill': 58, 'good': 59, 'then': 60, 'was': 61, 'come': 62, 'am': 63, 'only': 64, 'time': 65, 'day': 66, 'love': 67, 'there': 68, 'want': 69, 'send': 70, 'text': 71, 'he': 72, 'as': 73, 'by': 74, 'going': 75, 'one': 76, 'ü': 77, 'need': 78, 'about': 79, 'txt': 80, 'home': 81, 'lor': 82, 'see': 83, 'sorry': 84, 'still': 85, 'r': 86, 'back': 87, 'stop': 88, 'our': 89, 'n': 90, 'reply': 91, 'today': 92, 'mobile': 93, 'tell': 94, 'new': 95, 'well': 96, 'later': 97, 'hi': 98, 'think': 99, 'been': 100, 'da': 101, 'she': 102, 'any': 103, 'please': 104, 'take': 105, 'they': 106, 'her': 107, 'phone': 108, 'cant': 109, 'did': 110, 'some': 111, 'here': 112, 'has': 113, 'week': 114, 'night': 115, 'an': 116, 'claim': 117, 'oh': 118, 'who': 119, 'much': 120, 'great': 121, 'hey': 122, 'dear': 123, 'him': 124, 'more': 125, 'pls': 126, 'happy': 127, 'd': 128, 'too': 129, 'hope': 130, 'had': 131, 'give': 132, 'make': 133, 'way': 134, 'where': 135, 'work': 136, 'wat': 137, 'should': 138, 'thats': 139, 'number': 140, 'say': 141, 'prize': 142, 'right': 143, 'already': 144, 'tomorrow': 145, 'after': 146, 'ask': 147, 'said': 148, 'yes': 149, 'really': 150, 'yeah': 151, 'doing': 152, 'e': 153, 'amp': 154, 'message': 155, 'were': 156, '1': 157, 'them': 158, 'msg': 159, 'why': 160, 'c': 161, 'miss': 162, 'didnt': 163, 'life': 164, 'meet': 165, 'last': 166, 'morning': 167, 'babe': 168, 'very': 169, 'would': 170, 'cos': 171, 'anything': 172, 'ive': 173, 'cash': 174, 'thanks': 175, 'won': 176, 'lol': 177, 'find': 178, 'win': 179, 'every': 180, 'k': 181, 'sure': 182, 'pick': 183, 'also': 184, 'let': 185, 'over': 186, 'nokia': 187, 'something': 188, 'contact': 189, 'sent': 190, 'keep': 191, 'care': 192, '3': 193, 'b': 194, 'urgent': 195, 'again': 196, 'buy': 197, 'before': 198, 'gud': 199, 'even': 200, 'us': 201, 'next': 202, 'feel': 203, 'first': 204, 'around': 205, 'went': 206, 'off': 207, 'thing': 208, 'tonight': 209, 'his': 210, 'could': 211, 'which': 212, 'someone': 213, 'soon': 214, 'wait': 215, 'place': 216, 'service': 217, 'many': 218, 'per': 219, 'friends': 220, 'customer': 221, 'gonna': 222, 'always': 223, 'nice': 224, 'money': 225, 'wont': 226, 'down': 227, 'late': 228, 'chat': 229, 'ya': 230, 'sleep': 231, 'dun': 232, 'help': 233, 'other': 234, 'leave': 235, 'wan': 236, 'waiting': 237, 'youre': 238, 'things': 239, 'told': 240, '16': 241, 'v': 242, 'wish': 243, 'try': 244, 'x': 245, 'getting': 246, 'year': 247, 'guaranteed': 248, 'yet': 249, 'people': 250, 'thk': 251, 'coming': 252, 'done': 253, 'hello': 254, 'same': 255, 'may': 256, 'haha': 257, 'tone': 258, 'name': 259, 'thought': 260, 'friend': 261, 'live': 262, 'best': 263, 'havent': 264, 'mins': 265, 'talk': 266, 'fine': 267, 'lunch': 268, 'hows': 269, 'man': 270, 'bit': 271, 'class': 272, 'special': 273, 'use': 274, 'being': 275, 'never': 276, 'smile': 277, 'holiday': 278, 'person': 279, 'stuff': 280, 'yup': 281, 'trying': 282, 'meeting': 283, 'job': 284, 'draw': 285, '18': 286, 'few': 287, '5': 288, 'heart': 289, 'finish': 290, 'sms': 291, 'cool': 292, 'y': 293, 'long': 294, 'better': 295, 'line': 296, 'having': 297, 'ready': 298, 'mind': 299, 'end': 300, 'latest': 301, 'car': 302, 'account': 303, 'guys': 304, 'dat': 305, 'than': 306, 'chance': 307, 'min': 308, 'days': 309, 'enjoy': 310, 'lar': 311, 'receive': 312, 'eat': 313, 'half': 314, 'play': 315, 'check': 316, 'awarded': 317, 'wanna': 318, 'box': 319, 'nothing': 320, 'guess': 321, 'because': 322, '1st': 323, 'yo': 324, 'another': 325, 'luv': 326, 'big': 327, 'camera': 328, 'real': 329, 'birthday': 330, 'shows': 331, 'house': 332, 'into': 333, 'dinner': 334, '£1000': 335, 'po': 336, 'lot': 337, 'liao': 338, 'jus': 339, 'start': 340, 'shit': 341, 'problem': 342, 'ever': 343, 'word': 344, 'xxx': 345, 'watching': 346, 'room': 347, 'sweet': 348, '150ppm': 349, 'landline': 350, 'girl': 351, 'sir': 352, 'might': 353, 'quite': 354, 'world': 355, 'early': 356, 'speak': 357, 'cost': 358, 'once': 359, 'aight': 360, 'whats': 361, 'called': 362, 'watch': 363, 'two': 364, 'god': 365, 'probably': 366, 'id': 367, 'pay': 368, 'does': 369, 'hes': 370, 'hear': 371, 'pa': 372, 'bed': 373, 'plan': 374, 'minutes': 375, 'actually': 376, 'den': 377, 'princess': 378, '6': 379, 'apply': 380, 'fun': 381, 'remember': 382, 'left': 383, 'look': 384, 'maybe': 385, 'part': 386, 'between': 387, 'forgot': 388, '£2000': 389, 'offer': 390, 'easy': 391, 'reach': 392, 'thanx': 393, 'video': 394, 'shopping': 395, 'made': 396, 'dunno': 397, 'bad': 398, 'kiss': 399, 'code': 400, 'theres': 401, '2nd': 402, 'weekend': 403, 'dis': 404, 'month': 405, 'ah': 406, 'little': 407, 'boy': 408, 'everything': 409, 'baby': 410, 'hour': 411, 's': 412, 'network': 413, 'selected': 414, 'enough': 415, 'bus': 416, 'looking': 417, 'award': 418, 'those': 419, 'working': 420, 'leh': 421, 'face': 422, 'orange': 423, 'put': 424, 'tcs': 425, 'shall': 426, 'shes': 427, 'thank': 428, 'most': 429, 'todays': 430, 'without': 431, 'tv': 432, 'xmas': 433, 'tmr': 434, 'g': 435, 'asked': 436, 'sat': 437, '7': 438, 'fuck': 439, 'dad': 440, 'until': 441, 'wif': 442, '£150': 443, '9': 444, 'wanted': 445, 'since': 446, 'came': 447, 'afternoon': 448, 'says': 449, 'anyway': 450, 'must': 451, 'school': 452, 'join': 453, 'sexy': 454, 'missing': 455, 'evening': 456, 'collect': 457, 'while': 458, 'town': 459, 'entry': 460, 'goes': 461, 'though': 462, 'doesnt': 463, 'ringtone': 464, 'means': 465, 'abt': 466, 'okay': 467, 'bt': 468, 'able': 469, 'hav': 470, 'important': 471, 'wake': 472, 'true': 473, 'texts': 474, 'bring': 475, 'details': 476, 'collection': 477, 'pain': 478, 'wen': 479, 'show': 480, 'juz': 481, 'years': 482, 'til': 483, '500': 484, 'plz': 485, 'tones': 486, 'office': 487, 'away': 488, 'gift': 489, 'plus': 490, 'update': 491, 'times': 492, 'till': 493, 'calls': 494, 'hair': 495, 'mob': 496, 'wk': 497, 'else': 498, 'price': 499, 'mail': 500, 'weekly': 501, 'wot': 502, 'bored': 503, 'attempt': 504, 'de': 505, 'guy': 506, 'valid': 507, 'tc': 508, 'alright': 509, 'saw': 510, 'yesterday': 511, 'yours': 512, 'run': 513, 'making': 514, 'food': 515, 'haf': 516, 'ltdecimalgt': 517, 'oso': 518, 'music': 519, 'hurt': 520, 'dude': 521, 'stay': 522, '150p': 523, 'makes': 524, 'lei': 525, 'words': 526, 'tried': 527, 'delivery': 528, 'yourself': 529, 'double': 530, 'driving': 531, 'test': 532, 'worry': 533, 'answer': 534, 'top': 535, 'missed': 536, 'hot': 537, 'lets': 538, 'book': 539, 'change': 540, 'rate': 541, 'either': 542, 'these': 543, 'sch': 544, '£100': 545, 'online': 546, 'hours': 547, 'colour': 548, 'ard': 549, 'bonus': 550, 'trip': 551, 'comes': 552, 'address': 553, 'order': 554, 'nite': 555, 'wid': 556, 'full': 557, 'friendship': 558, 'tot': 559, 'sae': 560, 'lose': 561, 'game': 562, 'family': 563, 'together': 564, 'feeling': 565, 'wants': 566, 'goin': 567, '8007': 568, 'sad': 569, 'wife': 570, 'set': 571, 'smiling': 572, '£5000': 573, 'mean': 574, 'old': 575, 'points': 576, 'believe': 577, 'm': 578, 'story': 579, 'both': 580, 'noe': 581, 'shop': 582, 'happen': 583, 'walk': 584, 'vouchers': 585, 'club': 586, 'charge': 587, 'movie': 588, 'calling': 589, 'messages': 590, 'huh': 591, 'beautiful': 592, 'o': 593, 'saying': 594, 'drive': 595, 'await': 596, 'weeks': 597, 'brother': 598, 'pounds': 599, 'aft': 600, 're': 601, 'took': 602, 'finished': 603, 'busy': 604, 'private': 605, 'question': 606, 'leaving': 607, 'gr8': 608, 'awesome': 609, 'minute': 610, 'wil': 611, 'coz': 612, 'ring': 613, '86688': 614, 'okie': 615, 'eve': 616, '£500': 617, 'thinking': 618, 'pics': 619, 'email': 620, 'rite': 621, 'final': 622, 'date': 623, 'forget': 624, 'second': 625, 'congrats': 626, 'started': 627, 'close': 628, 'cause': 629, 'services': 630, 'taking': 631, 'everyone': 632, 'smoke': 633, 'angry': 634, '750': 635, 'unsubscribe': 636, 'post': 637, 'head': 638, 'land': 639, 'simple': 640, 't': 641, 'tscs': 642, 'neva': 643, 'anyone': 644, 'drop': 645, 'dreams': 646, 'news': 647, 'tho': 648, 'lesson': 649, 'tomo': 650, 'lucky': 651, 'search': 652, 'isnt': 653, '12hrs': 654, 'statement': 655, 'expires': 656, 'open': 657, 'lots': 658, 'each': 659, 'worth': 660, 'sis': 661, 'touch': 662, 'found': 663, 'sleeping': 664, 'break': 665, 'company': 666, 'choose': 667, 'card': 668, 'games': 669, 'sister': 670, 'poly': 671, 'drink': 672, 'whatever': 673, 'pub': 674, 'voucher': 675, 'knw': 676, 'alone': 677, 'auction': 678, 'available': 679, 'treat': 680, 'winner': 681, '100': 682, 'pobox': 683, 'wonderful': 684, 'ha': 685, 'smth': 686, 'uk': 687, 'saturday': 688, 'decided': 689, '08000930705': 690, 'girls': 691, 'prob': 692, 'happened': 693, 'unredeemed': 694, 'identifier': 695, 'hard': 696, 'frnd': 697, 'needs': 698, 'boytoy': 699, 'sounds': 700, 'takes': 701, 'anytime': 702, 'far': 703, 'mobileupd8': 704, 'dating': 705, '£250': 706, 'kind': 707, '8': 708, 'mine': 709, 'sun': 710, 'gd': 711, 'parents': 712, 'crazy': 713, 'camcorder': 714, 'used': 715, 'gone': 716, 'bday': 717, 'operator': 718, 'nt': 719, 'type': 720, 'ltd': 721, 'hand': 722, 'content': 723, 'wit': 724, 'carlos': 725, 'finally': 726, 'mrng': 727, 'college': 728, 'oredi': 729, 'secret': 730, 'congratulations': 731, 'hold': 732, 'read': 733, 'light': 734, '150pmsg': 735, '08000839402': 736, 'bout': 737, 'fucking': 738, '10': 739, 'visit': 740, 'nope': 741, 'outside': 742, 'fri': 743, 'pretty': 744, 'sea': 745, 'fast': 746, 'mum': 747, 'lovely': 748, 'mates': 749, 'loving': 750, 'wkly': 751, '12': 752, 'credit': 753, 'hungry': 754, 'seeing': 755, 'telling': 756, 'whole': 757, 'frnds': 758, 'hit': 759, 'friday': 760, 'mu': 761, 'player': 762, 'youll': 763, 'yr': 764, 'their': 765, 'ni8': 766, 'fancy': 767, 'bank': 768, 'youve': 769, 'log': 770, 'course': 771, 'darlin': 772, 'goodmorning': 773, '10p': 774, 'thinks': 775, 'case': 776, 'meant': 777, 'unlimited': 778, 'fone': 779, 'project': 780, 'reason': 781, 'phones': 782, 'ten': 783, 'welcome': 784, 'cum': 785, 'offers': 786, 'cs': 787, 'listen': 788, 'snow': 789, '…': 790, 'b4': 791, 'mate': 792, 'wrong': 793, 'party': 794, 'pic': 795, 'point': 796, 'valued': 797, 'months': 798, 'almost': 799, 'etc': 800, 'cut': 801, 'hee': 802, 'download': 803, '0800': 804, 'mah': 805, 'felt': 806, 'invited': 807, 'caller': 808, 'numbers': 809, 'quiz': 810, 'msgs': 811, 'age': 812, 'march': 813, 'side': 814, 'tel': 815, 'fr': 816, '87066': 817, 'dnt': 818, 'bslvyl': 819, 'lost': 820, 'reading': 821, 'txts': 822, 'currently': 823, 'motorola': 824, 'talking': 825, 'couple': 826, 'ass': 827, 'pm': 828, 'savamob': 829, 'within': 830, '2003': 831, '800': 832, 'yar': 833, 'happiness': 834, 'area': 835, '£350': 836, 'opt': 837, 'sex': 838, 'mayb': 839, 'wats': 840, 'knew': 841, 'least': 842, 'earlier': 843, 'nyt': 844, 'chennai': 845, 'enter': 846, 'w': 847, 'gas': 848, 'wasnt': 849, 'freemsg': 850, 'mobiles': 851, 'eh': 852, 'national': 853, 'eg': 854, 'wow': 855, 'correct': 856, 'song': 857, 'complimentary': 858, 'xx': 859, 'gotta': 860, 'computer': 861, 'mom': 862, 'askd': 863, 'uncle': 864, 'sending': 865, 'direct': 866, 'tired': 867, 'hell': 868, 'mr': 869, 'semester': 870, 'bcoz': 871, 'laptop': 872, 'blue': 873, 'questions': 874, 'swing': 875, 'ends': 876, 'die': 877, 'christmas': 878, 'via': 879, '150': 880, 'ago': 881, 'st': 882, 'chikku': 883, 'seen': 884, 'rental': 885, 'th': 886, 'supposed': 887, 'park': 888, 'ipod': 889, 'through': 890, 'gym': 891, 'darren': 892, 'ans': 893, 'picking': 894, 'ugh': 895, 'extra': 896, 'information': 897, 'surprise': 898, 'grins': 899, 'luck': 900, 'difficult': 901, 'john': 902, 'father': 903, 'comp': 904, 'usf': 905, 'comin': 906, 'charged': 907, 'confirm': 908, 'abiola': 909, 'crave': 910, 'gets': 911, 'pass': 912, 'move': 913, 'checking': 914, 'loads': 915, 'shower': 916, 'entered': 917, 'match': 918, 'dogging': 919, 'txting': 920, 'wine': 921, 'safe': 922, 'muz': 923, 'bath': 924, 'orchard': 925, 'kate': 926, 'exam': 927, 'wana': 928, 'sim': 929, 'somebody': 930, 'plans': 931, 'small': 932, 'jay': 933, 'discount': 934, 'slow': 935, 'rock': 936, 'india': 937, 'doin': 938, 'hmm': 939, 'asking': 940, 'terms': 941, 'noon': 942, 'sound': 943, 'paper': 944, 'sell': 945, 'wonder': 946, 'whenever': 947, 'sort': 948, 'truth': 949, 'feels': 950, 'heard': 951, 'frm': 952, 'don': 953, 'support': 954, 'loved': 955, 'slowly': 956, 'nah': 957, 'callertune': 958, 'press': 959, 'reward': 960, 'info': 961, 'wap': 962, 'link': 963, 'england': 964, 'myself': 965, 'knows': 966, 'oops': 967, 'hospital': 968, 'reached': 969, 'forever': 970, 'rply': 971, 'save': 972, 'tickets': 973, 'representative': 974, 'gave': 975, 'weekends': 976, 'rates': 977, 'del': 978, 'uks': 979, 'lovable': 980, 'dream': 981, 'spend': 982, 'ones': 983, 'wed': 984, 'bathe': 985, 'rs': 986, 'bill': 987, 'admirer': 988, 'deep': 989, 'own': 990, 'leaves': 991, 'hmv': 992, 'stupid': 993, 'somewhere': 994, 'pete': 995, 'immediately': 996, 'valentines': 997, 'figure': 998, 'weed': 999, 'met': 1000, 'ex': 1001, 'moment': 1002, 'woke': 1003, 'mm': 1004, 'yep': 1005, 'voice': 1006, 'ldn': 1007, 'booked': 1008, 'ure': 1009, 'different': 1010, 'remove': 1011, 'monday': 1012, 'water': 1013, 'near': 1014, 'less': 1015, 'hoping': 1016, 'across': 1017, 'warm': 1018, 'cheap': 1019, 'kids': 1020, 'em': 1021, 'drugs': 1022, 'laugh': 1023, 'fantastic': 1024, 'glad': 1025, 'wishing': 1026, 'store': 1027, 'gettin': 1028, 'understand': 1029, 'poor': 1030, 'asap': 1031, 'otherwise': 1032, 'ntt': 1033, '10pmin': 1034, 'na': 1035, 'gal': 1036, 'whos': 1037, 'film': 1038, 'energy': 1039, 'write': 1040, 'fact': 1041, 'empty': 1042, 'cup': 1043, 'std': 1044, 'copy': 1045, '11': 1046, 'promise': 1047, 'seriously': 1048, 'worried': 1049, 'sick': 1050, 'catch': 1051, 'moms': 1052, 'decide': 1053, 'situation': 1054, 'short': 1055, 'rain': 1056, 'men': 1057, 'boss': 1058, 'specially': 1059, 'ending': 1060, 'buying': 1061, 'sunshine': 1062, 'sony': 1063, 'lazy': 1064, 'lect': 1065, 'completely': 1066, 'hmmm': 1067, 'staying': 1068, 'especially': 1069, 'studying': 1070, 'trust': 1071, 'using': 1072, 'itself': 1073, 'mrt': 1074, 'lessons': 1075, 'street': 1076, 'cd': 1077, 'lover': 1078, 'disturb': 1079, 'credits': 1080, 'worries': 1081, 'unless': 1082, 'accept': 1083, '£200': 1084, 'normal': 1085, 'rest': 1086, '11mths': 1087, 'merry': 1088, 'access': 1089, 'urself': 1090, 'bluetooth': 1091, 'brings': 1092, 'starts': 1093, 'kinda': 1094, 'loan': 1095, 'optout': 1096, 'meh': 1097, 'rent': 1098, 'silent': 1099, 'sub': 1100, 'self': 1101, 'train': 1102, 'forwarded': 1103, '–': 1104, 'starting': 1105, 'study': 1106, 'ho': 1107, 'xy': 1108, 'king': 1109, 'seems': 1110, 'eyes': 1111, 'summer': 1112, 'no1': 1113, 'wwwgetzedcouk': 1114, 'aint': 1115, 'charity': 1116, 'tampa': 1117, 'user': 1118, 'against': 1119, '£800': 1120, 'hiya': 1121, 'f': 1122, 'convey': 1123, 'p': 1124, 'doctor': 1125, 'nobody': 1126, 'mode': 1127, 'wondering': 1128, 'others': 1129, 'frens': 1130, 'tht': 1131, 'reaching': 1132, '2nite': 1133, 'gods': 1134, 'joys': 1135, 'thinkin': 1136, 'sitting': 1137, 'flag': 1138, 'colleagues': 1139, 'request': 1140, 'entitled': 1141, 'anymore': 1142, 'sunday': 1143, '87077': 1144, 'mark': 1145, 'pizza': 1146, 'cheers': 1147, 'quick': 1148, 'replying': 1149, 'youd': 1150, 'nigeria': 1151, 'ice': 1152, 'cinema': 1153, 'spent': 1154, 'trouble': 1155, 'hurts': 1156, 'loves': 1157, 'planning': 1158, 'coffee': 1159, 'ave': 1160, 'wishes': 1161, 'apartment': 1162, 'inc': 1163, 'paying': 1164, '2004': 1165, 'bak': 1166, 'dvd': 1167, 'pray': 1168, 'sometimes': 1169, 'goto': 1170, 'wheres': 1171, 'freephone': 1172, 'deal': 1173, 'however': 1174, 'dead': 1175, 'slept': 1176, 'gt': 1177, 'sign': 1178, 'road': 1179, 'kick': 1180, 'ufind': 1181, 'rreveal': 1182, 'specialcall': 1183, 'goodnight': 1184, 'lemme': 1185, 'rose': 1186, '4u': 1187, '2day': 1188, 'power': 1189, 'fixed': 1190, 'wiv': 1191, 'round': 1192, 'hgsuite3422lands': 1193, 'reference': 1194, 'facebook': 1195, 'none': 1196, 'yahoo': 1197, 'aha': 1198, '3030': 1199, 'giving': 1200, '50': 1201, 'din': 1202, 'style': 1203, 'opinion': 1204, 'single': 1205, 'fingers': 1206, 'workin': 1207, 'daddy': 1208, 'door': 1209, 'pound': 1210, 'valentine': 1211, 'future': 1212, 'longer': 1213, '25p': 1214, 'matches': 1215, 'pc': 1216, 'tuesday': 1217, 'tonite': 1218, 'add': 1219, 'library': 1220, 'theyre': 1221, 'slave': 1222, 'omg': 1223, 'polys': 1224, 'yrs': 1225, 'training': 1226, 'possible': 1227, 'sale': 1228, 'registered': 1229, 'mo': 1230, 'medical': 1231, 'il': 1232, 'miracle': 1233, 'during': 1234, 'movies': 1235, 'digital': 1236, 'awaiting': 1237, 'cancel': 1238, 'cute': 1239, 'complete': 1240, 'picked': 1241, 'bb': 1242, 'south': 1243, 'inside': 1244, 'btnationalrate': 1245, 'wednesday': 1246, 'mon': 1247, 'mood': 1248, 'sofa': 1249, 'police': 1250, 'bugis': 1251, 'la': 1252, 'cine': 1253, '£900': 1254, 'co': 1255, 'click': 1256, 'sucks': 1257, 'eating': 1258, 'learn': 1259, 'ahead': 1260, 'kept': 1261, 'liked': 1262, 'wun': 1263, 'following': 1264, 'stand': 1265, 'pleasure': 1266, '530': 1267, 'password': 1268, 'changed': 1269, 'cuz': 1270, 'page': 1271, 'umma': 1272, 'eatin': 1273, 'bother': 1274, 'country': 1275, 'persons': 1276, 'become': 1277, '62468': 1278, 'menu': 1279, 'waste': 1280, 'hop': 1281, 'experience': 1282, 'towards': 1283, 'net': 1284, 'bucks': 1285, 'past': 1286, 'appreciate': 1287, 'battery': 1288, 'flirt': 1289, 'uve': 1290, 'showing': 1291, 'horny': 1292, 'naked': 1293, 'quality': 1294, 'definitely': 1295, 'usual': 1296, 'ge': 1297, 'sense': 1298, 'loyalty': 1299, 'high': 1300, 'imagine': 1301, 'arent': 1302, 'kb': 1303, 'yoga': 1304, 'rcvd': 1305, 'interested': 1306, 'insurance': 1307, 'cashbalance': 1308, 'maximize': 1309, 'cashin': 1310, 'forward': 1311, 'happening': 1312, 'mistake': 1313, 'al': 1314, 'lift': 1315, 'tough': 1316, 'thru': 1317, 'notice': 1318, 'tenerife': 1319, 'depends': 1320, 'mp3': 1321, '85023': 1322, 'member': 1323, '£300': 1324, 'malaria': 1325, 'fat': 1326, 'married': 1327, 'rather': 1328, 'hotel': 1329, 'omw': 1330, 'hurry': 1331, 'weight': 1332, 'clean': 1333, 'izzit': 1334, 'spree': 1335, 'custcare': 1336, 'present': 1337, 'ar': 1338, 'imma': 1339, 'shuhui': 1340, 'alex': 1341, 'paid': 1342, 'funny': 1343, 'login': 1344, 'under': 1345, '20': 1346, 'awake': 1347, 'bedroom': 1348, 'torch': 1349, 'bold': 1350, 'looks': 1351, 'idea': 1352, 'sit': 1353, 'holla': 1354, 'yest': 1355, 'damn': 1356, 'space': 1357, 'lttimegt': 1358, '36504': 1359, 'bid': 1360, 'hai': 1361, 'mid': 1362, 'midnight': 1363, 'january': 1364, 'gay': 1365, '08712460324': 1366, 'photo': 1367, 'sk38xh': 1368, 'recently': 1369, 'heavy': 1370, '3g': 1371, 'j': 1372, 'onto': 1373, 'honey': 1374, 'cell': 1375, 'dog': 1376, 'shd': 1377, 'vl': 1378, '20p': 1379, '1327': 1380, 'croydon': 1381, 'cr9': 1382, '5wb': 1383, 'walking': 1384, 'players': 1385, 'share': 1386, 'arrive': 1387, 'excellent': 1388, 'instead': 1389, 'buzz': 1390, 'sight': 1391, 'holding': 1392, 'list': 1393, 'thnk': 1394, 'excuse': 1395, 'costa': 1396, 'sol': 1397, 'pix': 1398, 'tear': 1399, 'worse': 1400, 'hw': 1401, 'murdered': 1402, 'murderer': 1403, 'happens': 1404, 'planned': 1405, 'joking': 1406, 'melle': 1407, 'hl': 1408, 'naughty': 1409, 'team': 1410, 'tea': 1411, 'texting': 1412, 'usually': 1413, 'fyi': 1414, '150pm': 1415, 'pleased': 1416, 'review': 1417, 'don‘t': 1418, 'simply': 1419, 'flights': 1420, 'directly': 1421, '08712300220': 1422, 'standard': 1423, 'app': 1424, 'q': 1425, 'replied': 1426, 'local': 1427, 'ki': 1428, 'arrange': 1429, 'inviting': 1430, 'turns': 1431, 'spoke': 1432, 'joined': 1433, 'personal': 1434, 'balance': 1435, 'straight': 1436, 'system': 1437, 'died': 1438, 'kallis': 1439, 'tncs': 1440, 'cal': 1441, 'handset': 1442, 'dint': 1443, 'ended': 1444, 'sunny': 1445, 'babes': 1446, 'sport': 1447, 'track': 1448, 'return': 1449, 'report': 1450, '1000s': 1451, 'yijue': 1452, 'num': 1453, 'fault': 1454, 'ish': 1455, 'cc': 1456, 'cold': 1457, 'posted': 1458, 'air': 1459, '1000': 1460, 'willing': 1461, 'mei': 1462, 'body': 1463, 'relax': 1464, 'pilates': 1465, 'putting': 1466, 'dai': 1467, 'fullonsmscom': 1468, 'competition': 1469, 'shell': 1470, 'wnt': 1471, 'vry': 1472, 'vary': 1473, 'ticket': 1474, 'askin': 1475, 'group': 1476, 'ttyl': 1477, 'gives': 1478, 'moan': 1479, 'll': 1480, '8th': 1481, 'fb': 1482, 'activate': 1483, 'character': 1484, 'tat': 1485, '40gb': 1486, 'pin': 1487, 'children': 1488, 'campus': 1489, 'lady': 1490, 'l8r': 1491, 'confidence': 1492, 'aiyo': 1493, 'barely': 1494, 'scream': 1495, 'marriage': 1496, 'announcement': 1497, 'daily': 1498, 'weather': 1499, 'vodafone': 1500, 'holder': 1501, 'evng': 1502, 'envelope': 1503, 'fetch': 1504, 'gap': 1505, 'wer': 1506, 'aftr': 1507, 'running': 1508, 'exactly': 1509, 'yay': 1510, 'advance': 1511, 'pobox84': 1512, 'w45wq': 1513, 'norm150ptone': 1514, 'model': 1515, 'boo': 1516, '2u': 1517, 'teasing': 1518, 'zed': 1519, 'surely': 1520, 'five': 1521, 'version': 1522, 'fall': 1523, 'sup': 1524, 'murder': 1525, 'due': 1526, 'teach': 1527, 'iam': 1528, 'ate': 1529, 'wherever': 1530, 'expensive': 1531, 'ull': 1532, 'brand': 1533, 'nxt': 1534, 'contract': 1535, 'asleep': 1536, 'loverboy': 1537, 'serious': 1538, 'flower': 1539, 'works': 1540, 'regards': 1541, 'fight': 1542, 'sipix': 1543, 'black': 1544, 'aiyah': 1545, 'httpwwwurawinnercom': 1546, 'howz': 1547, 'raining': 1548, 'station': 1549, 'tour': 1550, 'alrite': 1551, 'super': 1552, 'marry': 1553, 'problems': 1554, 'fantasies': 1555, '08707509020': 1556, 'meaning': 1557, 'girlfrnd': 1558, 'lmao': 1559, '4th': 1560, 'nature': 1561, 'keeping': 1562, '0870': 1563, 'except': 1564, 'internet': 1565, 'screaming': 1566, '86021': 1567, 'london': 1568, 'lookin': 1569, 'boys': 1570, 'arcade': 1571, 'created': 1572, 'exciting': 1573, '09050090044': 1574, 'toclaim': 1575, 'pobox334': 1576, 'stockport': 1577, 'cost£150pm': 1578, 'max10mins': 1579, 'theatre': 1580, 'ahmad': 1581, 'official': 1582, 'vikky': 1583, 'sed': 1584, 'role': 1585, 'checked': 1586, 'added': 1587, 'pussy': 1588, 'budget': 1589, 'plenty': 1590, 'behind': 1591, 'amazing': 1592, 'hrs': 1593, 'cancer': 1594, 'feb': 1595, 'tariffs': 1596, 'tick': 1597, 'meds': 1598, '£400': 1599, 'darling': 1600, 'callers': 1601, 'searching': 1602, 'wet': 1603, 'i‘m': 1604, 'stock': 1605, 'roommates': 1606, 'hopefully': 1607, 'tyler': 1608, 'weak': 1609, 'ride': 1610, 'red': 1611, 'joke': 1612, 'plane': 1613, 'urgnt': 1614, 'boston': 1615, 'truly': 1616, 'jokes': 1617, 'scared': 1618, 'cabin': 1619, 'informed': 1620, 'voda': 1621, 'quoting': 1622, 'hasnt': 1623, 'shouldnt': 1624, '82277': 1625, 'locations': 1626, 'rooms': 1627, 'begin': 1628, 'discuss': 1629, 'transaction': 1630, 'cannot': 1631, 'connection': 1632, 'partner': 1633, 'sam': 1634, '25': 1635, 'argument': 1636, 'wins': 1637, 'website': 1638, 'fix': 1639, 'childish': 1640, 'singles': 1641, 'rays': 1642, 'bf': 1643, 'anybody': 1644, 'cry': 1645, 'selection': 1646, 'december': 1647, 'ppl': 1648, 'surfing': 1649, 'basically': 1650, 'sonyericsson': 1651, 'geeee': 1652, 'didt': 1653, 'sighs': 1654, 'guide': 1655, 'intro': 1656, 'current': 1657, 'pictures': 1658, 'yan': 1659, 'jiu': 1660, 'pobox36504w45wq': 1661, 'contacted': 1662, 'hostel': 1663, 'hv': 1664, 'amt': 1665, 'respond': 1666, 'dollars': 1667, 'si': 1668, 'woman': 1669, 'don\\x92t': 1670, 'flat': 1671, 'charges': 1672, 'sec': 1673, 'conditions': 1674, 'fighting': 1675, 'some1': 1676, 'village': 1677, 'stylish': 1678, 'unsub': 1679, 'returns': 1680, 'age16': 1681, 'quote': 1682, 'english': 1683, '2mrw': 1684, 'smiles': 1685, 'jazz': 1686, 'yogasana': 1687, '1x150pwk': 1688, 'stopped': 1689, 'indian': 1690, 'ladies': 1691, 'somethin': 1692, 'euro2004': 1693, 'results': 1694, 'drinks': 1695, '80062': 1696, 'thursday': 1697, 'cartoon': 1698, 'listening': 1699, 'gentle': 1700, 'hella': 1701, 'drug': 1702, 'earth': 1703, 'belly': 1704, 'law': 1705, 'dey': 1706, 'timing': 1707, 'twice': 1708, '£10': 1709, 'realy': 1710, 'tis': 1711, 'sing': 1712, 'couldnt': 1713, 'living': 1714, 'polyphonic': 1715, 'bag': 1716, 'wwwcomuknet': 1717, 'mother': 1718, 'playing': 1719, 'sn': 1720, 'cds': 1721, 'records': 1722, 'matter': 1723, 'birds': 1724, 'travel': 1725, 'lead': 1726, 'white': 1727, 'cheaper': 1728, 'ym': 1729, 'pissed': 1730, 'wear': 1731, '£10000': 1732, 'places': 1733, 'photos': 1734, '08718720201': 1735, 'site': 1736, 'ad': 1737, 'boring': 1738, 'videophones': 1739, 'videochat': 1740, 'java': 1741, 'dload': 1742, 'noline': 1743, 'rentl': 1744, 'dropped': 1745, 'yun': 1746, 'jesus': 1747, 'kerala': 1748, '3rd': 1749, 'april': 1750, 'bitch': 1751, 'revealed': 1752, 'xchat': 1753, 'frndship': 1754, 'hands': 1755, 'receipt': 1756, 'interesting': 1757, 'uni': 1758, 'o2': 1759, 'italian': 1760, 'adult': 1761, 'oz': 1762, 'horrible': 1763, 'nw': 1764, 'choice': 1765, 'strong': 1766, 'mite': 1767, '150ptone': 1768, 'chinese': 1769, 'cbe': 1770, 'broke': 1771, 'original': 1772, 'arrested': 1773, 'linerental': 1774, 'cafe': 1775, 'vote': 1776, 'gee': 1777, 'moon': 1778, 'tells': 1779, 'totally': 1780, 'rem': 1781, 'exams': 1782, 'bought': 1783, 'google': 1784, 'vomit': 1785, 'centre': 1786, 'airport': 1787, 'costs': 1788, '250': 1789, 'eerie': 1790, 'waking': 1791, 'ran': 1792, 'rd': 1793, 'hook': 1794, 'bin': 1795, 'social': 1796, 'selling': 1797, 'buns': 1798, 'hate': 1799, 'season': 1800, 'moral': 1801, 'nvm': 1802, 'obviously': 1803, 'boost': 1804, 'inclusive': 1805, 'ip4': 1806, '5we': 1807, 'armand': 1808, 'looked': 1809, 'expecting': 1810, 'minuts': 1811, 'latr': 1812, 'caken': 1813, 'unable': 1814, 'remind': 1815, 'whether': 1816, 'ringtones': 1817, 'spook': 1818, 'fantasy': 1819, 'sky': 1820, 'random': 1821, 'ru': 1822, 'cars': 1823, 'er': 1824, 'deliver': 1825, 'amount': 1826, 'advice': 1827, 'issues': 1828, 'hr': 1829, 'ignore': 1830, '28': 1831, 'cover': 1832, 'thurs': 1833, 'wouldnt': 1834, 'relation': 1835, 'lik': 1836, 'asks': 1837, '3510i': 1838, '300': 1839, 'mths': 1840, 'common': 1841, 'oni': 1842, 'fa': 1843, 'tkts': 1844, '87121': 1845, 'lives': 1846, 'tb': 1847, 'oru': 1848, 'six': 1849, '87575': 1850, 'that\\x92s': 1851, 'str': 1852, 'sooner': 1853, 'turn': 1854, 'egg': 1855, 'subscription': 1856, 'letter': 1857, 'inches': 1858, 'embarassed': 1859, 'seemed': 1860, 'ac': 1861, 'series': 1862, 'iq': 1863, '£1500': 1864, 'valuable': 1865, 'wah': 1866, 'machan': 1867, 'coins': 1868, 'becoz': 1869, 'fml': 1870, 'hols': 1871, 'appointment': 1872, 'legal': 1873, 'nyc': 1874, 'considering': 1875, 'research': 1876, 'tt': 1877, '786': 1878, 'kkhow': 1879, 'ansr': 1880, 'sptyrone': 1881, 'laid': 1882, 'largest': 1883, 'ec2a': 1884, 'befor': 1885, 'activities': 1886, 'biggest': 1887, 'netcollex': 1888, 'qatar': 1889, 'deleted': 1890, 'shirt': 1891, 'joy': 1892, 'interview': 1893, 'escape': 1894, 'bloody': 1895, 'anyways': 1896, '0808': 1897, '145': 1898, '4742': 1899, '9am11pm': 1900, 'radio': 1901, 'settled': 1902, 'shoot': 1903, 'nights': 1904, 'files': 1905, '2optout': 1906, 'career': 1907, 'followed': 1908, 'teaches': 1909, 'cross': 1910, 'closer': 1911, 'theory': 1912, 'argue': 1913, 'wwwldewcom1win150ppmx3age16': 1914, 'bcums': 1915, 'affection': 1916, 'kettoda': 1917, 'manda': 1918, 'expect': 1919, 'mmm': 1920, 'h': 1921, 'bay': 1922, 'passed': 1923, 'throw': 1924, 'cam': 1925, 'accidentally': 1926, 'def': 1927, 'meal': 1928, 'dates': 1929, 'hanging': 1930, 'belovd': 1931, 'enemy': 1932, 'afraid': 1933, '08002986906': 1934, 'kisses': 1935, 'cud': 1936, 'waitin': 1937, '85': 1938, '83600': 1939, 'wtf': 1940, 'roww1j6hl': 1941, 'further': 1942, '87131': 1943, 'cream': 1944, 'tree': 1945, 'logo': 1946, 'esplanade': 1947, 'fifteen': 1948, '3mins': 1949, 'wc1n3xx': 1950, 'gorgeous': 1951, 'jen': 1952, 'purpose': 1953, 'tenants': 1954, 'refused': 1955, 'intelligent': 1956, 'result': 1957, 'reasons': 1958, 'bye': 1959, 'receiving': 1960, '5000': 1961, 'cw25wx': 1962, 'dry': 1963, 'center': 1964, 'bringing': 1965, 'jada': 1966, 'kusruthi': 1967, 'spl': 1968, 'matured': 1969, '83355': 1970, 'cha': 1971, 'rude': 1972, 'pg': 1973, 'passionate': 1974, 'losing': 1975, 'btw': 1976, 'three': 1977, 'i‘ll': 1978, 'essential': 1979, 'lab': 1980, '2000': 1981, 'quit': 1982, '08715705022': 1983, 'grand': 1984, '542': 1985, 'pie': 1986, 'mums': 1987, 'answers': 1988, 'often': 1989, 'uncles': 1990, 'bud': 1991, 'temple': 1992, 'church': 1993, 'bet': 1994, 'prepare': 1995, 'seem': 1996, 'lonely': 1997, 'explain': 1998, 'purchase': 1999, 'weird': 2000, 'drivin': 2001, 'height': 2002, 'students': 2003, '10am7pm': 2004, 'assume': 2005, 'txtauction': 2006, 'faster': 2007, 'gals': 2008, '£3': 2009, 'weve': 2010, 'spoken': 2011, 'city': 2012, 'meetin': 2013, 'apparently': 2014, 'row': 2015, 'smokes': 2016, 'perfect': 2017, 'enjoyed': 2018, 'dictionary': 2019, 'm263uz': 2020, 'appt': 2021, 'xxxx': 2022, 'ache': 2023, '3qxj9': 2024, '9ae': 2025, 'profit': 2026, 'green': 2027, 'reveal': 2028, 'cust': 2029, 'ages': 2030, 'sura': 2031, 'ibiza': 2032, 'ppm': 2033, 'meanwhile': 2034, 'suite': 2035, 'careful': 2036, 'vip': 2037, 'ta': 2038, 'saved': 2039, 'played': 2040, 'wanting': 2041, 'derek': 2042, 'pig': 2043, 'addicted': 2044, 'ma': 2045, 'attend': 2046, 'diet': 2047, 'acc': 2048, 'fever': 2049, 'gravity': 2050, 'carefully': 2051, 'bowl': 2052, 'decision': 2053, 'salary': 2054, 'sore': 2055, '150pmin': 2056, 'throat': 2057, 'lecture': 2058, 'raise': 2059, 'fool': 2060, 'june': 2061, 'bathing': 2062, 'vijay': 2063, 'dem': 2064, 'clock': 2065, 'subscriber': 2066, 'aiyar': 2067, 'wearing': 2068, 'rally': 2069, 'shame': 2070, '£3wk': 2071, 'credited': 2072, 'understanding': 2073, 'delivered': 2074, 'arms': 2075, 'easier': 2076, 'txtin': 2077, '4info': 2078, '08712405020': 2079, 'songs': 2080, 'exact': 2081, '2moro': 2082, 'thts': 2083, 'favour': 2084, 'wwwringtonescouk': 2085, '3gbp': 2086, 'idiot': 2087, 'february': 2088, 'rush': 2089, '6hrs': 2090, 'blackberry': 2091, 'pple': 2092, 'moji': 2093, 'fill': 2094, '4get': 2095, 'urn': 2096, 'tuition': 2097, '150pmsgrcvdhgsuite3422landsroww1j6hl': 2098, 've': 2099, 'aiya': 2100, 'bright': 2101, 'pod': 2102, '020603': 2103, 'wonders': 2104, '7th': 2105, '6th': 2106, '5th': 2107, 'personality': 2108, 'purity': 2109, 'messageits': 2110, 'sha': 2111, 'total': 2112, 'along': 2113, 'file': 2114, 'shortly': 2115, '7250i': 2116, 'roww1jhl': 2117, 'yuo': 2118, 'tihs': 2119, 'bishan': 2120, 'preferably': 2121, 'idk': 2122, 'whom': 2123, 'laughing': 2124, 'brought': 2125, 'surprised': 2126, 'jst': 2127, 'moby': 2128, 'action': 2129, 'ideas': 2130, 'remain': 2131, 'received': 2132, 'ordered': 2133, 'queen': 2134, 'fren': 2135, '60pmin': 2136, 'connect': 2137, 'bahamas': 2138, 'settings': 2139, 'alert': 2140, 'atlanta': 2141, 'fills': 2142, 'gaps': 2143, 'takin': 2144, 'answering': 2145, 'beer': 2146, 'jess': 2147, 'dirty': 2148, 'package': 2149, 'upto': 2150, '08001950382': 2151, 'godi': 2152, 'youclean': 2153, 'bloodsend': 2154, 'itplspls': 2155, 'skype': 2156, 'masters': 2157, 'cleaning': 2158, 'cat': 2159, 'hip': 2160, 'havnt': 2161, '87239': 2162, 'freefone': 2163, 'natural': 2164, 'lie': 2165, 'infernal': 2166, 'yer': 2167, '84199': 2168, 'eng': 2169, 'box39822': 2170, 'w111wx': 2171, 'subs': 2172, 'feet': 2173, 'med': 2174, 'mad': 2175, 'kidz': 2176, 'ntwk': 2177, 'pages': 2178, '630': 2179, 'freak': 2180, '£450': 2181, '8552': 2182, 'wkend': 2183, 'letters': 2184, 'football': 2185, 'happend': 2186, 'sugar': 2187, 'roger': 2188, 'solve': 2189, 'cooking': 2190, 'brilliant': 2191, 'indians': 2192, 'key': 2193, 'released': 2194, 'bx420': 2195, 'spending': 2196, 'whens': 2197, 'response': 2198, 'sept': 2199, 'housemaid': 2200, 'public': 2201, 'govtinstituitions': 2202, 'closedincluding': 2203, 'dare': 2204, 'iz': 2205, 'handle': 2206, 'note': 2207, 'porn': 2208, 'celebrate': 2209, '730': 2210, 'tm': 2211, 'abi': 2212, 'hill': 2213, 'grl': 2214, 'hug': 2215, '09061221066': 2216, 'fromm': 2217, 'wylie': 2218, 'basic': 2219, 'outta': 2220, 'inform': 2221, 'blank': 2222, 'texted': 2223, 'doc': 2224, 'taunton': 2225, 'loss': 2226, 'santa': 2227, 'step': 2228, '21st': 2229, '2005': 2230, 'minnaminunginte': 2231, 'nurungu': 2232, 'vettam': 2233, 'membership': 2234, 'spell': 2235, 'scotland': 2236, 'frying': 2237, 'clear': 2238, 'child': 2239, 'caught': 2240, 'fear': 2241, 'xuhui': 2242, 'invite': 2243, 'yummy': 2244, 'callsmessagesmissed': 2245, 'fair': 2246, 'gram': 2247, 'runs': 2248, 'realized': 2249, 'lturlgt': 2250, '09061209465': 2251, 'suprman': 2252, 'matrix3': 2253, 'starwars3': 2254, 'bx420ip45we': 2255, 'burger': 2256, 'dresser': 2257, 'advise': 2258, 'recent': 2259, 'gentleman': 2260, 'dignity': 2261, 'respect': 2262, 'requests': 2263, 'sheets': 2264, 'sum1': 2265, 'lido': 2266, 'collected': 2267, 'mix': 2268, 'verify': 2269, 'four': 2270, 'vava': 2271, 'loud': 2272, 'k52': 2273, 'wa': 2274, 'sentence': 2275, 'anythin': 2276, 'needed': 2277, '45239': 2278, 'üll': 2279, 'apologise': 2280, 'hardcore': 2281, 'dot': 2282, 'female': 2283, 'birla': 2284, 'soft': 2285, 'floor': 2286, 'spanish': 2287, 'mall': 2288, 'maneesha': 2289, 'satisfied': 2290, 'toll': 2291, 'mummy': 2292, 'finishes': 2293, 'unique': 2294, 'august': 2295, 'suggest': 2296, 'successfully': 2297, 'dats': 2298, 'atm': 2299, 'register': 2300, 'romantic': 2301, '89545': 2302, '£1': 2303, 'www4tcbiz': 2304, '08718726270150gbpmtmsg18': 2305, 'teacher': 2306, 'pence': 2307, 'loses': 2308, 'tomarrow': 2309, 'avent': 2310, 'touched': 2311, 'slippers': 2312, 'bat': 2313, 'innings': 2314, 'dearly': 2315, '125gift': 2316, 'ranjith': 2317, '5min': 2318, 'shipping': 2319, 'parked': 2320, 'mini': 2321, 'flash': 2322, 'jealous': 2323, 'sorting': 2324, 'genuine': 2325, 'infowww100percentrealcom': 2326, 'handed': 2327, 'gautham': 2328, 'buzy': 2329, 'tmobile': 2330, 'upgrade': 2331, '0845': 2332, 'tease': 2333, 'scary': 2334, 'themob': 2335, 'newest': 2336, 'gossip': 2337, 'fit': 2338, 'garage': 2339, 'keys': 2340, 'dayu': 2341, 'dear1': 2342, 'best1': 2343, 'clos1': 2344, 'lvblefrnd': 2345, 'jstfrnd': 2346, 'cutefrnd': 2347, 'lifpartnr': 2348, 'swtheart': 2349, 'bstfrnd': 2350, 'smart': 2351, 'm26': 2352, '3uz': 2353, 'pongal': 2354, 'cake': 2355, 'gona': 2356, 'flight': 2357, 'record': 2358, 'women': 2359, 'germany': 2360, 'supervisor': 2361, 'lifetime': 2362, 'sleepingand': 2363, 'favourite': 2364, 'cleared': 2365, 'slap': 2366, 'alcohol': 2367, 'remembered': 2368, 'ptbo': 2369, 'tests': 2370, '6months': 2371, '4mths': 2372, 'mobilesdirect': 2373, '08000938767': 2374, 'or2stoptxt': 2375, 'shut': 2376, 'period': 2377, 'business': 2378, 'picture': 2379, 'quickly': 2380, 'chechi': 2381, 'skip': 2382, 'blah': 2383, 'goal': 2384, 'names': 2385, 'irritating': 2386, 'aathiwhere': 2387, 'bmw': 2388, 'urgentlyits': 2389, 'urgentbut': 2390, 'shortage': 2391, 'lacsthere': 2392, 'source': 2393, 'arng': 2394, 'lacsthats': 2395, 'iouri': 2396, 'yeshe': 2397, 'oic': 2398, '£75000': 2399, 'homeowners': 2400, 'previously': 2401, '1956669': 2402, 'july': 2403, 'railway': 2404, 'doggy': 2405, 'fave': 2406, 'dave': 2407, 'transfered': 2408, 'banks': 2409, '9ja': 2410, 'wise': 2411, '9t': 2412, 'aathilove': 2413, 'boye': 2414, 'accounts': 2415, 'fightng': 2416, 'dificult': 2417, 'fish': 2418, '123': 2419, '£1450': 2420, 'tcsstop': 2421, 'fees': 2422, 'prabhaim': 2423, 'sorydarealyfrm': 2424, 'sory': 2425, 'ibhltd': 2426, 'ldnw15h': 2427, '150pmtmsgrcvd18': 2428, 'mono': 2429, 'nos': 2430, 'booking': 2431, 'behave': 2432, 'elsewhere': 2433, 'box95qu': 2434, '08717898035': 2435, 'todaysundaysunday': 2436, 'holidayso': 2437, 'lt': 2438, 'ummmmmaah': 2439, 'tirupur': 2440, 'cock': 2441, 'generally': 2442, 'blood': 2443, 'milk': 2444, 'it‘s': 2445, 'that‘s': 2446, 'likely': 2447, 'american': 2448, 'callin': 2449, 'dick': 2450, 'snake': 2451, 'bite': 2452, 'headache': 2453, '80878': 2454, 'lines': 2455, 'exhausted': 2456, 'swimming': 2457, '2morow': 2458, 'nichols': 2459, '83222': 2460, 'leona': 2461, 'market': 2462, 'pop': 2463, 'postcode': 2464, 'seven': 2465, 'thanksgiving': 2466, 'we‘re': 2467, 'peace': 2468, '89555': 2469, 'textoperator': 2470, 'building': 2471, 'map': 2472, 'ws': 2473, 'stress': 2474, 'uu': 2475, 'max£7': 2476, 'shouted': 2477, 'shorter': 2478, 'subscribed': 2479, 'realize': 2480, 'gimme': 2481, 'paris': 2482, 'mt': 2483, 'mas': 2484, '88039': 2485, 'skilgme': 2486, 'anywhere': 2487, 'diff': 2488, 'community': 2489, 'subpoly': 2490, 'bein': 2491, 'jan': 2492, 'pieces': 2493, '3d': 2494, 'hint': 2495, 'responding': 2496, '08702840625comuk': 2497, '220cm2': 2498, 'alfie': 2499, 'moons': 2500, 'm8s': 2501, 'nokias': 2502, '08701417012': 2503, 'hahahause': 2504, 'brain': 2505, 'recd': 2506, 'given': 2507, 'successful': 2508, '2morrow': 2509, '434': 2510, 'sk3': 2511, '8wp': 2512, 'xavier': 2513, 'seconds': 2514, 'jays': 2515, 'stomach': 2516, 'spk': 2517, 'returned': 2518, 'worlds': 2519, 'supply': 2520, 'walls': 2521, 'cuddle': 2522, 'nap': 2523, 'shesil': 2524, '10k': 2525, 'liverpool': 2526, 'reminder': 2527, 'failed': 2528, 'wifehow': 2529, 'opportunity': 2530, 'outstanding': 2531, 'greet': 2532, 'male': 2533, 'msging': 2534, '88600': 2535, 'moments': 2536, '11414': 2537, 'tcrw1': 2538, 'magical': 2539, 'welp': 2540, 'valid12hrs': 2541, 'chicken': 2542, 'potential': 2543, 'talent': 2544, '09063458130': 2545, 'polyph': 2546, 'fuckin': 2547, 'butt': 2548, 'yetunde': 2549, 'terrible': 2550, 'exe': 2551, 'prey': 2552, 'fancies': 2553, 'foreign': 2554, 'stamps': 2555, 'speechless': 2556, 'roast': 2557, 'concentrate': 2558, 'chatting': 2559, 'walked': 2560, 'euro': 2561, 'drunk': 2562, '84025': 2563, 'technical': 2564, 'juicy': 2565, 'dearer': 2566, 'evn': 2567, 'alwys': 2568, '09061790121': 2569, 'ne': 2570, 'speed': 2571, 'okok': 2572, 'okthenwhats': 2573, 'catching': 2574, 'falls': 2575, 'hgsuite3422landsroww1j6hl': 2576, 'roommate': 2577, 'bigger': 2578, 'islands': 2579, 'jordan': 2580, 'pocketbabecouk': 2581, 'voicemail': 2582, 'natuition': 2583, 'walmart': 2584, 'kkim': 2585, 'score': 2586, '87021': 2587, 'apps': 2588, 'rofl': 2589, 'anti': 2590, 'various': 2591, 'morn': 2592, 'docs': 2593, 'havin': 2594, 'hun': 2595, 'rang': 2596, 'executive': 2597, 'jane': 2598, 'express': 2599, 'fran': 2600, 'knackered': 2601, 'ps': 2602, 'software': 2603, 'whenevr': 2604, 'among': 2605, 'cares': 2606, 'chill': 2607, 'chillin': 2608, 'saucy': 2609, 'chain': 2610, 'suntec': 2611, 'messenger': 2612, '3cover': 2613, 'screen': 2614, '4press': 2615, '5gently': 2616, 'tom': 2617, 'upload': 2618, 'shot': 2619, 'storming': 2620, 'phne': 2621, 'wt': 2622, 'margaret': 2623, 'grahmbell': 2624, 'invnted': 2625, 'telphone': 2626, 'moralone': 2627, 'popped': 2628, 'unsold': 2629, 'shld': 2630, 'beware': 2631, 'caring': 2632, 'option': 2633, 'goodnite': 2634, 'arsenal': 2635, 'painful': 2636, 'everybody': 2637, 'sen': 2638, 'missin': 2639, 'guilty': 2640, 'cardiff': 2641, 'addie': 2642, 'certainly': 2643, 'stupidits': 2644, 'claire': 2645, 'twelve': 2646, 'aah': 2647, '09066362231': 2648, '07xxxxxxxxx': 2649, 'blakes': 2650, 'lotr': 2651, '80488': 2652, 'stars': 2653, 'karaoke': 2654, 'eight': 2655, 'ron': 2656, 'ese': 2657, 'prospects': 2658, 'buff': 2659, 'gang': 2660, 'tablets': 2661, 'finishing': 2662, 'doors': 2663, 'brothas': 2664, 'chasing': 2665, 'lt3': 2666, 'force': 2667, 'blame': 2668, 'blessings': 2669, 'freezing': 2670, 'winning': 2671, '6pm': 2672, 'title': 2673, 'titles': 2674, '82242': 2675, 'monthly': 2676, 'maintain': 2677, 'cramps': 2678, 'nan': 2679, '81303': 2680, 'likes': 2681, 'dislikes': 2682, 'promises': 2683, '121': 2684, 'standing': 2685, 'james': 2686, 'chosen': 2687, 'di': 2688, 'cruise': 2689, '18only': 2690, 'i\\x92m': 2691, 'follow': 2692, 'stuck': 2693, 'regarding': 2694, 'adore': 2695, '0': 2696, 'arun': 2697, 'philosophy': 2698, 'eye': 2699, 'husband': 2700, 'norm': 2701, 'toa': 2702, 'payoh': 2703, 'fathima': 2704, 'mmmm': 2705, 'nearly': 2706, 'beyond': 2707, '18yrs': 2708, 'abta': 2709, '80182': 2710, '08452810073': 2711, 'ikea': 2712, 'cn': 2713, 'kadeem': 2714, 'se': 2715, 'carry': 2716, 'avatar': 2717, 'stops': 2718, 'constantly': 2719, 'lousy': 2720, 'ic': 2721, 'honeybee': 2722, 'sweetest': 2723, 'laughed': 2724, 'waitu': 2725, 'crack': 2726, 'gmgngegn': 2727, 'boat': 2728, 'proof': 2729, 'provided': 2730, 'downloads': 2731, 'members': 2732, 'major': 2733, 'birth': 2734, 'rule': 2735, 'onwards': 2736, 'pack': 2737, 'including': 2738, 'calicut': 2739, 'box97n7qp': 2740, 'giv': 2741, 'normally': 2742, 'rich': 2743, 'm8': 2744, 'yor': 2745, 'jason': 2746, 'art': 2747, 'argh': 2748, 'term': 2749, 'tessypls': 2750, 'favor': 2751, 'nimyapls': 2752, 'shijas': 2753, 'china': 2754, 'morphine': 2755, 'prefer': 2756, 'miles': 2757, 'rajipls': 2758, 'nimya': 2759, 'legs': 2760, 'distance': 2761, 'temp': 2762, 'display': 2763, 'soup': 2764, 'management': 2765, 'include': 2766, 'regular': 2767, 'lounge': 2768, 'u4': 2769, '88066': 2770, 'journey': 2771, 'cheer': 2772, 'cornwall': 2773, 'sp': 2774, 'bags': 2775, 'iscoming': 2776, '80082': 2777, 'halloween': 2778, 'logopic': 2779, 'issue': 2780, 'measure': 2781, 'thm': 2782, 'wn': 2783, 'instantly': 2784, 'drinking': 2785, 'impossible': 2786, 'messageno': 2787, 'responcewhat': 2788, 'vodka': 2789, 'thangam': 2790, 'okey': 2791, '1his': 2792, '2police': 2793, 'questioned': 2794, '3wife': 2795, 'siri': 2796, '4cook': 2797, '5gardener': 2798, 'vegetables': 2799, '6housemaid': 2800, '7children': 2801, '8neighbour': 2802, 'settle': 2803, 'bloo': 2804, 'citizen': 2805, '09066612661': 2806, 'greetings': 2807, 'maga': 2808, 'medicine': 2809, 'incident': 2810, 'violence': 2811, 'erm': 2812, 'instructions': 2813, 'death': 2814, 'usualiam': 2815, '1030': 2816, 'hon': 2817, 'reality': 2818, 'wks': 2819, 'booty': 2820, 'remains': 2821, 'bro': 2822, 'bros': 2823, 'pouts': 2824, 'stomps': 2825, 'sports': 2826, 'shirts': 2827, '2stoptxt': 2828, 'officeunderstand': 2829, 'process': 2830, 'luxury': 2831, 'ben': 2832, 'middle': 2833, 'dark': 2834, 'enuff': 2835, 'contents': 2836, 'strike': 2837, 'moved': 2838, 'seat': 2839, '50p': 2840, 'dress': 2841, 'collecting': 2842, 'flaked': 2843, 'gary': 2844, 'history': 2845, 'bell': 2846, 'understood': 2847, 'bottom': 2848, 'hm': 2849, 'crab': 2850, 'footprints': 2851, 'changes': 2852, 'books': 2853, 'prove': 2854, 'blow': 2855, 'knowing': 2856, 'kano': 2857, 'hunny': 2858, 'challenge': 2859, 'randomly': 2860, 'tape': 2861, 'films': 2862, 'lick': 2863, 'auto': 2864, '450': 2865, '1u': 2866, '3u': 2867, 'deliveredtomorrow': 2868, 'smoking': 2869, 'in2': 2870, 'billed': 2871, 'ths': 2872, 'callback': 2873, 'ts': 2874, 'wedding': 2875, 'accident': 2876, 'wisdom': 2877, 'cannt': 2878, 'symbol': 2879, 'prolly': 2880, '\\x96': 2881, 'confirmed': 2882, '200': 2883, 'dubsack': 2884, 'macho': 2885, 'audition': 2886, 'fell': 2887, 'forevr': 2888, 'eaten': 2889, 'possession': 2890, 'concert': 2891, 'born': 2892, 'affairs': 2893, 'university': 2894, 'california': 2895, 'tog': 2896, 'haiz': 2897, 'previous': 2898, 'captain': 2899, 'dsnt': 2900, 'parking': 2901, 'sometime': 2902, 'comedy': 2903, 'é': 2904, 'allah': 2905, 'warner': 2906, 'bottle': 2907, 'buffet': 2908, 'questionstd': 2909, 'ratetcs': 2910, '08452810075over18s': 2911, 'hor': 2912, 'rcv': 2913, 'receivea': 2914, '09061701461': 2915, 'kl341': 2916, '08002986030': 2917, 'chances': 2918, '20000': 2919, 'csh11': 2920, '150pday': 2921, '6days': 2922, 'tsandcs': 2923, '£100000': 2924, 'jackpot': 2925, '81010': 2926, 'wwwdbuknet': 2927, 'lccltd': 2928, '4403ldnw1a7rw18': 2929, 'blessing': 2930, 'slice': 2931, 'sarcastic': 2932, '8am': 2933, 'mmmmmm': 2934, 'burns': 2935, 'hospitals': 2936, 'eighth': 2937, 'sptv': 2938, 'detroit': 2939, 'hockey': 2940, 'odi': 2941, 'killing': 2942, '09066364589': 2943, 'dedicated': 2944, 'dedicate': 2945, 'eurodisinc': 2946, 'trav': 2947, 'acoentry41': 2948, '186£150morefrmmob': 2949, 'shracomorsglsuplt10': 2950, 'ls1': 2951, '3aj': 2952, 'divorce': 2953, 'kkwhere': 2954, 'shy': 2955, 'earn': 2956, 'jacket': 2957, 'nitros': 2958, 'ela': 2959, 'pours': 2960, '169': 2961, '6031': 2962, '10am9pm': 2963, '85069': 2964, 'usher': 2965, 'britney': 2966, '5249': 2967, 'mk17': 2968, '92h': 2969, '450ppw': 2970, 'loans': 2971, 'animation': 2972, 'location': 2973, 'noun': 2974, 'gent': 2975, '09064012160': 2976, 'puttin': 2977, 'goodo': 2978, 'tortilla': 2979, '07742676969': 2980, '08719180248': 2981, '350': 2982, 'sum': 2983, 'algarve': 2984, '69888': 2985, '31pmsg150p': 2986, 'msn': 2987, 'pouch': 2988, 'swt': 2989, 'occupy': 2990, 'staff': 2991, 'randy': 2992, '08700621170150p': 2993, 'flowing': 2994, 'plaza': 2995, 'everywhere': 2996, 'windows': 2997, 'mouth': 2998, '0871277810810': 2999, 'module': 3000, 'avoid': 3001, 'beloved': 3002, 'formclark': 3003, 'utter': 3004, 'completed': 3005, 'stays': 3006, 'wishin': 3007, 'hamster': 3008, 'refilled': 3009, 'inr': 3010, 'keralacircle': 3011, 'prepaid': 3012, 'kr': 3013, 'ericsson': 3014, 'bruv': 3015, 'rewarding': 3016, 'heading': 3017, 'ahsen': 3018, 'os': 3019, 'installing': 3020, 'repair': 3021, 'todayfrom': 3022, 'horo': 3023, 'star': 3024, 'conducts': 3025, 'yeshere': 3026, 'printed': 3027, 'upstairs': 3028, '447801259231': 3029, '09058094597': 3030, 'shining': 3031, 'signing': 3032, 'although': 3033, 'commercial': 3034, 'drpd': 3035, 'deeraj': 3036, 'deepak': 3037, 'doinghow': 3038, '2wks': 3039, 'lag': 3040, 'necessarily': 3041, 'headin': 3042, 'jolt': 3043, 'suzy': 3044, 'networks': 3045, '69698': 3046, '150pwk': 3047, 'mk45': 3048, '2wt': 3049, 'chart': 3050, 'gf': 3051, 'tool': 3052, 'jenny': 3053, 'resend': 3054, '021': 3055, 'grave': 3056, 'tomocant': 3057, 'shocking': 3058, 'crash': 3059, 'taxi': 3060, 'actor': 3061, 'blind': 3062, 'hide': 3063, 'thread': 3064, 'funky': 3065, '82468': 3066, 'tahan': 3067, 'anot': 3068, 'lo': 3069, 'buses': 3070, 'bristol': 3071, 'dahow': 3072, '0844': 3073, '861': 3074, 'prepayment': 3075, 'violated': 3076, 'privacy': 3077, 'paperwork': 3078, 'custcare08718720201': 3079, 'caroline': 3080, 'bless': 3081, 'stranger': 3082, 'gudnitetcpractice': 3083, 'misbehaved': 3084, 'unemployed': 3085, 'status': 3086, 'alive': 3087, 'breathe': 3088, 'updatenow': 3089, 'cuddling': 3090, 'agree': 3091, 'recognise': 3092, 'ovulation': 3093, 'call2optoutn9dx': 3094, 'licks': 3095, 'grace': 3096, 'field': 3097, 'administrator': 3098, 'shipped': 3099, 'loxahatchee': 3100, 'burning': 3101, 'slightly': 3102, 'darlings': 3103, 'wld': 3104, 'messagesome': 3105, 'sendername': 3106, 'sentdate': 3107, 'box334sk38ch': 3108, 'whatsup': 3109, '80086': 3110, 'wwwtxttowincouk': 3111, 'name1': 3112, 'name2': 3113, 'mobno': 3114, 'adam': 3115, '07123456789': 3116, 'txtno': 3117, 'ads': 3118, 'speaking': 3119, 'expression': 3120, '3650': 3121, '09066382422': 3122, '300603': 3123, 'bcm4284': 3124, 'applebees': 3125, 'greatbhaji': 3126, 'cricketer': 3127, 'sachin': 3128, 'worldvery': 3129, 'improve': 3130, 'oreo': 3131, 'truffles': 3132, 'amy': 3133, 'decisions': 3134, 'coping': 3135, '0207': 3136, '153': 3137, '26th': 3138, 'position': 3139, 'roads': 3140, 'language': 3141, '09061743806': 3142, 'box326': 3143, 'screamed': 3144, 'removed': 3145, 'broken': 3146, 'infront': 3147, 'tension': 3148, 'taste': 3149, 'www07781482378com': 3150, 'trade': 3151, 'sorryin': 3152, 'rec': 3153, '7ish': 3154, '09050002311': 3155, 'b4280703': 3156, '08718727868': 3157, 'hyde': 3158, 'anthony': 3159, 'scrounge': 3160, 'forgiven': 3161, 'slide': 3162, 'renewal': 3163, 'transport': 3164, 'definite': 3165, 'ebay': 3166, 'pickle': 3167, 'tacos': 3168, '020903': 3169, '24hrs': 3170, 'channel': 3171, '08718738001': 3172, 'web': 3173, 'develop': 3174, 'ability': 3175, 'recovery': 3176, 'blokes': 3177, 'cutting': 3178, 'reminding': 3179, 'owns': 3180, 'faggy': 3181, 'demand': 3182, 'fo': 3183, 'loose': 3184, 'pan': 3185, 'perhaps': 3186, 'geeeee': 3187, 'oooh': 3188, 'ey': 3189, 'call09050000327': 3190, 'claims': 3191, 'dancing': 3192, 'hardly': 3193, 'wwwtxt2shopcom': 3194, '08712402050': 3195, '10ppm': 3196, 'ag': 3197, 'promo': 3198, '0825': 3199, 'tsunamis': 3200, 'soiree': 3201, '22': 3202, 'ques': 3203, 'suits': 3204, 'reaction': 3205, 'useful': 3206, 'officially': 3207, 'textbuddy': 3208, 'gaytextbuddycom': 3209, '89693': 3210, '4882': 3211, '09064019014': 3212, 'httpwwwetlpcoukexpressoffer': 3213, 'sweetheart': 3214, 'effects': 3215, 'wee': 3216, 'taken': 3217, 'trains': 3218, 'jolly': 3219, '40533': 3220, '311004': 3221, 'rstm': 3222, 'sw7': 3223, '3ss': 3224, 'panic': 3225, 'impatient': 3226, 'river': 3227, 'premium': 3228, 'lays': 3229, 'en': 3230, 'posts': 3231, 'yelling': 3232, 'hex': 3233, 'sue': 3234, 'cochin': 3235, 'farm': 3236, '4d': 3237, 'poop': 3238, 'gpu': 3239, 'deari': 3240, 'aeronautics': 3241, 'professors': 3242, 'calld': 3243, 'aeroplane': 3244, 'hurried': 3245, 'saidif': 3246, 'studentsthis': 3247, 'datz': 3248, 'dorm': 3249, '£1250': 3250, '09071512433': 3251, '050703': 3252, 'tcsbcm4235wc1n3xx': 3253, 'callcost': 3254, 'mobilesvary': 3255, 'cookies': 3256, 'ba': 3257, 'half8th': 3258, 'spring': 3259, 'offerthe': 3260, 'nokia6650': 3261, '81151': 3262, '4tctxt': 3263, '150pmtmsg': 3264, 'attached': 3265, '930': 3266, 'helpline': 3267, '08706091795': 3268, 'gist': 3269, '40': 3270, 'thousands': 3271, 'premier': 3272, 'lip': 3273, 'confused': 3274, 'spare': 3275, 'acting': 3276, 'tscs087147403231winawkage16': 3277, '£150perwksub': 3278, 'schools': 3279, 'closed': 3280, 'inch': 3281, 'begging': 3282, '0578': 3283, 'opening': 3284, 'pole': 3285, '08718727870': 3286, 'thot': 3287, 'nic': 3288, '8077': 3289, 'cashto': 3290, '08000407165': 3291, 'getstop': 3292, '88222': 3293, 'php': 3294, 'imp': 3295, 'bec': 3296, 'borrow': 3297, 'galileo': 3298, 'enjoyin': 3299, 'oktake': 3300, 'loveme': 3301, 'cappuccino': 3302, 'mojibiola': 3303, '09065174042': 3304, '07821230901': 3305, 'hol': 3306, 'haven\\x92t': 3307, 'skyped': 3308, 'kz': 3309, 'ultimatum': 3310, 'countin': 3311, 'aburo': 3312, '08002888812': 3313, 'inconsiderate': 3314, 'nag': 3315, 'recession': 3316, 'hence': 3317, 'soo': 3318, '09066350750': 3319, '10000': 3320, 'kkwhen': 3321, 'warning': 3322, 'nowi': 3323, 'shoes': 3324, 'lovejen': 3325, 'discreet': 3326, 'named': 3327, 'genius': 3328, 'connections': 3329, 'lotta': 3330, 'lately': 3331, 'virgin': 3332, 'mystery': 3333, 'wwwsmsconet': 3334, 'approx': 3335, 'consider': 3336, 'peaceful': 3337, '41685': 3338, '071104': 3339, '5k': 3340, '09064011000': 3341, 'cr01327bt': 3342, 'fixedline': 3343, 'castor': 3344, '09058094565': 3345, 'downloaded': 3346, 'ear': 3347, 'oil': 3348, 'mac': 3349, 'usb': 3350, 'gibbs': 3351, 'unbelievable': 3352, 'ie': 3353, 'superb': 3354, 'several': 3355, 'taylor': 3356, 'worst': 3357, 'charles': 3358, 'stores': 3359, '08709222922': 3360, '15pmin': 3361, '78pmin': 3362, 'peak': 3363, 'sweets': 3364, 'chip': 3365, 'yck': 3366, 'jeans': 3367, 'bleh': 3368, 'tons': 3369, 'scores': 3370, 'application': 3371, 'filthy': 3372, 'simpler': 3373, '09050001808': 3374, 'm95': 3375, 'necklace': 3376, 'racing': 3377, 'rice': 3378, 'closes': 3379, 'crap': 3380, 'borin': 3381, 'chocolate': 3382, 'dayshe': 3383, 'reckon': 3384, 'ubi': 3385, 'tech': 3386, 'sd': 3387, 'blessed': 3388, 'quiet': 3389, 'aunts': 3390, 'helen': 3391, 'fan': 3392, 'lovers': 3393, 'anniversary': 3394, 'secretly': 3395, 'datebox1282essexcm61xn': 3396, 'pattern': 3397, 'plm': 3398, 'sheffield': 3399, 'zoe': 3400, 'setting': 3401, 'filling': 3402, 'sufficient': 3403, 'thx': 3404, 'edison': 3405, 'rightly': 3406, 'viva': 3407, 'gmgngegnt': 3408, 'i\\x92d': 3409, 'ls15hb': 3410, 'educational': 3411, 'flirting': 3412, 'bloke': 3413, 'kickoff': 3414, 'sells': 3415, 'thesis': 3416, 'sends': 3417, 'deciding': 3418, 'eastenders': 3419, 'compare': 3420, 'herself': 3421, 'violet': 3422, 'tulip': 3423, 'lily': 3424, 'wkent150p16': 3425, 'prepared': 3426, '09058091854': 3427, 'box385': 3428, 'm6': 3429, '6wu': 3430, '09050003091': 3431, 'c52': 3432, 'oi': 3433, 'breath': 3434, 'heri': 3435, 'craziest': 3436, 'herlove': 3437, 'singing': 3438, 'curry': 3439, 'lotwill': 3440, '09061221061': 3441, '28days': 3442, 'box177': 3443, 'm221bp': 3444, '2yr': 3445, 'warranty': 3446, 'p£399': 3447, 'tomorro': 3448, 'fret': 3449, 'depressed': 3450, 'wind': 3451, 'math': 3452, 'rocks': 3453, 'durban': 3454, 'speedchat': 3455, '08000776320': 3456, 'survey': 3457, 'difficulties': 3458, 'sar': 3459, 'tank': 3460, '4fil': 3461, 'silently': 3462, 'wrc': 3463, 'lucozade': 3464, 'le': 3465, '61200': 3466, 'packs': 3467, 'lucozadecoukwrc': 3468, 'itcould': 3469, 'toot': 3470, 'annoying': 3471, 'makin': 3472, '2go': 3473, 'neft': 3474, 'beneficiary': 3475, 'wwwldewcomsubs161win150ppmx3': 3476, 'appreciated': 3477, 'apart': 3478, 'creepy': 3479, '08719181513': 3480, 'finewhen': 3481, 'nok': 3482, 'invest': 3483, '1hr': 3484, 'delay': 3485, '84128': 3486, 'wwwtextcompcom': 3487, '1s': 3488, 'purse': 3489, 'europe': 3490, 'flip': 3491, 'jd': 3492, 'weirdest': 3493, 'l8tr': 3494, 'calls£1minmoremobsemspobox45po139wa': 3495, 'tee': 3496, 'dough': 3497, 'control': 3498, 'jerry': 3499, 'irritates': 3500, 'fails': 3501, 'drinkin': 3502, '5pm': 3503, 'birthdate': 3504, 'nydc': 3505, 'ola': 3506, 'garbage': 3507, 'items': 3508, 'dads': 3509, 'jamster': 3510, 'gold': 3511, '16only': 3512, 'lions': 3513, 'lionm': 3514, 'lionp': 3515, 'jokin': 3516, 'colours': 3517, 'potter': 3518, 'phoenix': 3519, 'harry': 3520, 'readers': 3521, 'canada': 3522, 'goodnoon': 3523, 'interest': 3524, 'free2day': 3525, 'georges': 3526, 'jordantxt': 3527, '89080': 3528, 'celeb4': 3529, '0870241182716': 3530, 'tmrw': 3531, 'soul': 3532, 'ned': 3533, 'hurting': 3534, 'main': 3535, 'sweetie': 3536, '4a': 3537, 'whn': 3538, 'dance': 3539, '0870k': 3540, 'bar': 3541, 'bears': 3542, '08718730666': 3543, 'juan': 3544, 'call2optoutlf56': 3545, 'tlk': 3546, 'ideal': 3547, 'front': 3548, 'arm': 3549, 'tirunelvali': 3550, 'effect': 3551, 'bk': 3552, 'kidding': 3553, 'stretch': 3554, 'sinco': 3555, 'payee': 3556, 'icicibankcom': 3557, 'frauds': 3558, 'disclose': 3559, 'kaiez': 3560, 'practicing': 3561, 'babies': 3562, 'beneath': 3563, 'pale': 3564, 'silver': 3565, 'silence': 3566, 'wwwldewcom': 3567, 'revision': 3568, 'exeter': 3569, 'whose': 3570, 'coat': 3571, 'tues': 3572, 'restaurant': 3573, 'textpod': 3574, 'wwwtextpodnet': 3575, 'desperate': 3576, 'monkeys': 3577, 'practical': 3578, 'mails': 3579, 'costing': 3580, 'lyfu': 3581, 'lyf': 3582, 'ke': 3583, 'lucy': 3584, 'hubby': 3585, 'calls£1minmobsmorelkpobox177hp51fl': 3586, 'modules': 3587, 'musthu': 3588, 'jsco': 3589, 'dawhats': 3590, 'testing': 3591, 'nit': 3592, 'format': 3593, 'sarcasm': 3594, 'forum': 3595, 'aunt': 3596, 'unfortunately': 3597, 'konw': 3598, 'waht': 3599, 'rael': 3600, 'gving': 3601, 'exmpel': 3602, 'jsut': 3603, 'evrey': 3604, 'splleing': 3605, 'wrnog': 3606, 'sitll': 3607, 'raed': 3608, 'wihtuot': 3609, 'ayn': 3610, 'mitsake': 3611, 'sleepsweet': 3612, 'joining': 3613, 'finance': 3614, 'filled': 3615, 'jia': 3616, 'sux': 3617, 'kegger': 3618, 'rhythm': 3619, 'adventure': 3620, 'wifi': 3621, 'noi': 3622, 'rumour': 3623, '7250': 3624, 'boyfriend': 3625, 'driver': 3626, 'kicks': 3627, 'dime': 3628, 'transfer': 3629, 'falling': 3630, 'smeone': 3631, 'fire': 3632, 'flame': 3633, 'propose': 3634, 'kthen': 3635, 'dippeditinadew': 3636, 'lovingly': 3637, 'itwhichturnedinto': 3638, 'gifted': 3639, 'tomeandsaidthis': 3640, 'batch': 3641, 'flaky': 3642, 'sooooo': 3643, 'tooo': 3644, '09058094599': 3645, 'confuses': 3646, 'wating': 3647, 'british': 3648, 'hotels': 3649, 'sw73ss': 3650, 'adoring': 3651, 'dracula': 3652, 'ghost': 3653, 'addamsfa': 3654, 'munsters': 3655, 'exorcist': 3656, 'twilight': 3657, 'constant': 3658, 'cared': 3659, 'allow': 3660, 'msg150p': 3661, '2rcv': 3662, 'hlp': 3663, '08712317606': 3664, 'switch': 3665, 'event': 3666, 'bagi': 3667, '80608': 3668, 'wwwmovietriviatv': 3669, '08712405022': 3670, 'partnership': 3671, 'mostly': 3672, 'compromised': 3673, 'mornin': 3674, 'toughest': 3675, '£6': 3676, 'shjas': 3677, 'ringtoneget': 3678, 'freesend': 3679, '816183': 3680, 'weekstop': 3681, 'sms08718727870': 3682, 'poker': 3683, 'messy': 3684, 'traffic': 3685, 'moves': 3686, 'slip': 3687, 'wkg': 3688, 'keeps': 3689, 'gotten': 3690, 'unknown': 3691, 'album': 3692, '09094646899': 3693, 'vu': 3694, 'bcm1896wc1n3xx': 3695, '2007': 3696, 'stick': 3697, 'indeed': 3698, 'maangalyam': 3699, 'alaipayuthe': 3700, 'easter': 3701, 'telephone': 3702, 'callfreefone': 3703, '08081560665': 3704, 'of£2000': 3705, '07786200117': 3706, 'calm': 3707, 'up4': 3708, 'becomes': 3709, 'habit': 3710, 'schedule': 3711, 'contacts': 3712, 'forgets': 3713, 'mandan': 3714, '07734396839': 3715, 'ibh': 3716, 'nokia6600': 3717, 'txtauctiontxt': 3718, 'wordstart': 3719, 'no81151': 3720, 'now4t': 3721, 'invaders': 3722, 'orig': 3723, 'console': 3724, 'o2coukgames': 3725, 'transfr': 3726, 'didn\\x92t': 3727, 'foley': 3728, 'prizes': 3729, 'wwwwin82050couk': 3730, 'desparate': 3731, '3100': 3732, 'combine': 3733, 'sian': 3734, 'g696ga': 3735, 'joanna': 3736, 'replacement': 3737, 'telly': 3738, '12mths': 3739, 'btooth': 3740, 'delete': 3741, 'laundry': 3742, 'underwear': 3743, 'waheed': 3744, 'pushes': 3745, 'knees': 3746, 'avoiding': 3747, '0776xxxxxxx': 3748, '326': 3749, 'uh': 3750, 'heads': 3751, 'vday': 3752, 'therere': 3753, 'table': 3754, 'build': 3755, 'snowman': 3756, 'fights': 3757, 'prescription': 3758, 'electricity': 3759, 'fujitsu': 3760, 'scold': 3761, 'accordingly': 3762, 'wud': 3763, '09066358152': 3764, 'prompts': 3765, 'disturbing': 3766, 'upset': 3767, 'flies': 3768, 'kkwhy': 3769, 'woken': 3770, 'aka': 3771, 'delhi': 3772, 'held': 3773, 'fringe': 3774, 'distract': 3775, '61610': 3776, 'help08712400602450p': 3777, 'tones2youcouk': 3778, 'yeh': 3779, 'mel': 3780, 'responsibility': 3781, '08006344447': 3782, 'kid': 3783, 'affair': 3784, 'aom': 3785, 'nd': 3786, 'parco': 3787, 'nb': 3788, 'hallaq': 3789, 'bck': 3790, 'color': 3791, 'gender': 3792, 'sleepwellamptake': 3793, 'mca': 3794, 'tming': 3795, 'vomiting': 3796, 'rub': 3797, 'clever': 3798, 'stamped': 3799, '113': 3800, 'bray': 3801, 'wicklow': 3802, 'eire': 3803, 'wwwidewcom': 3804, 'skillgame': 3805, '1winaweek': 3806, '150ppermesssubscription': 3807, 'xam': 3808, 'manage': 3809, 'shitload': 3810, 'diamonds': 3811, 'aunty': 3812, 'mcat': 3813, 'sacrifice': 3814, 'beg': 3815, 'stayin': 3816, 'sorted': 3817, 'satisfy': 3818, 'cld': 3819, 'kindly': 3820, 'wales': 3821, 'killed': 3822, 'smashed': 3823, 'everybodys': 3824, 'tok': 3825, 'specific': 3826, 'figures': 3827, 'affectionate': 3828, 'cousin': 3829, 'excuses': 3830, 'neck': 3831, 'continue': 3832, 'holy': 3833, 'billion': 3834, 'classes': 3835, 'turning': 3836, 'ref': 3837, 'belive': 3838, 'slots': 3839, 'discussed': 3840, 'prem': 3841, '2morro': 3842, 'spoiled': 3843, 'complaint': 3844, 'lk': 3845, 'lov': 3846, 'comfort': 3847, '300p': 3848, '01223585334': 3849, '2c': 3850, 'shagged': 3851, '2end': 3852, 'waited': 3853, 'huge': 3854, 'mids': 3855, 'oranges': 3856, 'upd8': 3857, 'annie': 3858, '21870000hi': 3859, 'mailbox': 3860, 'messaging': 3861, '21': 3862, '09056242159': 3863, 'retrieve': 3864, 'hrishi': 3865, 'nothin': 3866, 'poem': 3867, 'thatll': 3868, 'quizwin': 3869, 'duchess': 3870, '82277unsub': 3871, '008704050406': 3872, 'nahi': 3873, 'wo': 3874, 'jo': 3875, 'dan': 3876, 'aww': 3877, 'staring': 3878, 'cm': 3879, 'unnecessarily': 3880, '08701417012150p': 3881, 'weigh': 3882, 'regret': 3883, 'gamestar': 3884, 'active': 3885, '£250k': 3886, 'scoring': 3887, 'nowsky': 3888, '88088': 3889, 'opinions': 3890, 'propsd': 3891, 'gv': 3892, 'lv': 3893, 'lttrs': 3894, 'threw': 3895, 'aproach': 3896, 'dt': 3897, 'truck': 3898, 'speeding': 3899, 'girld': 3900, 'thy': 3901, 'lived': 3902, 'happily': 3903, '2gthr': 3904, 'evrydy': 3905, 'msgsd': 3906, 'paragon': 3907, 'bluff': 3908, 'sary': 3909, 'wwwfullonsmscom': 3910, 'gn': 3911, 'piece': 3912, 'wiskey': 3913, 'brandy': 3914, 'rum': 3915, 'gin': 3916, 'scotch': 3917, 'shampain': 3918, 'kudiyarasu': 3919, 'dhina': 3920, 'vaazhthukkal': 3921, 'kg': 3922, 'dumb': 3923, 'dressed': 3924, 'kills': 3925, 'kay': 3926, 'nasty': 3927, 'wasted': 3928, 'christ': 3929, 'tears': 3930, 'science': 3931, 'push': 3932, 'answered': 3933, '8pm': 3934, 'wrote': 3935, 'swiss': 3936, 'crore': 3937, 'jobs': 3938, 'lane': 3939, 'politicians': 3940, 'rights': 3941, 'donno': 3942, 'properly': 3943, 'pongaldo': 3944, 'sry': 3945, 'furniture': 3946, 'lock': 3947, 'shoving': 3948, 'papers': 3949, 'strange': 3950, '24': 3951, 'acl03530150pm': 3952, 'indyarockscom': 3953, 'resume': 3954, 'datoday': 3955, 'bids': 3956, 'yunny': 3957, '83383': 3958, 'mmmmm': 3959, 'relatives': 3960, 'benefits': 3961, 'goodenvironment': 3962, 'terrific': 3963, 'dr': 3964, 'superior': 3965, 'picsfree1': 3966, 'ruin': 3967, 'department': 3968, 'conform': 3969, 'bc': 3970, 'toshiba': 3971, 'wrk': 3972, 'madam': 3973, 'knock': 3974, 'innocent': 3975, 'mental': 3976, 'hoped': 3977, 'bills': 3978, '2marrow': 3979, '900': 3980, 'treated': 3981, '9pm': 3982, 'fab': 3983, 'tiwary': 3984, 'bang': 3985, 'pap': 3986, 'arts': 3987, 'secretary': 3988, 'dollar': 3989, 'pull': 3990, 'amongst': 3991, '69696': 3992, '3lp': 3993, '£150msg': 3994, 'northampton': 3995, 'abj': 3996, 'serving': 3997, 'anna': 3998, 'nagar': 3999, 'petrol': 4000, 'evr': 4001, 'neither': 4002, 'hugs': 4003, 'snogs': 4004, 'west': 4005, 'fastest': 4006, 'growing': 4007, 'chase': 4008, 'steam': 4009, 'reg': 4010, 'canary': 4011, 'sleepy': 4012, 'mag': 4013, 'diwali': 4014, 'thgt': 4015, 'lower': 4016, 'gudk': 4017, 'exhaust': 4018, 'success': 4019, 'division': 4020, 'creep': 4021, 'lil': 4022, 'lies': 4023, 'property': 4024, 'interflora': 4025, '09058099801': 4026, 'b4190604': 4027, '7876150ppm': 4028, 'nicenicehow': 4029, 'yellow': 4030, '88888': 4031, 'doubt': 4032, 'japanese': 4033, 'proverb': 4034, 'itu': 4035, 'itleave': 4036, 'coin': 4037, 'freedom': 4038, 'twenty': 4039, 'painting': 4040, 'talks': 4041, 'probs': 4042, 'low': 4043, 'swatch': 4044, 'ganesh': 4045, 'trips': 4046, 'helloooo': 4047, 'welcomes': 4048, '2geva': 4049, 'wuld': 4050, 'solved': 4051, 'fucks': 4052, 'sake': 4053, 'bruce': 4054, 'chest': 4055, 'covers': 4056, 'brief': 4057, 'hang': 4058, 'reboot': 4059, 'pt2': 4060, 'phoned': 4061, 'improved': 4062, 'msgs150p': 4063, 'salon': 4064, 'evenings': 4065, 'raj': 4066, 'usc': 4067, 'payment': 4068, 'waves': 4069, 'clearing': 4070, 'range': 4071, 'smiled': 4072, 'admin': 4073, 'visionsmscom': 4074, 'andros': 4075, 'meets': 4076, 'foot': 4077, 'penis': 4078, 'sigh': 4079, 'vth': 4080, 'eveb': 4081, 'window': 4082, 'removal': 4083, '08708034412': 4084, 'cancelled': 4085, 'lookatme': 4086, 'agalla': 4087, 'xxxxx': 4088, 'count': 4089, 'otside': 4090, '830': 4091, 'size': 4092, '08712101358': 4093, 'it\\x92s': 4094, 'tight': 4095, 'av': 4096, 'everyday': 4097, 'curious': 4098, 'postcard': 4099, 'bread': 4100, 'mahal': 4101, 'redred': 4102, 'bloodblood': 4103, 'heartheart': 4104, '4some1': 4105, 'luvs': 4106, 'praying': 4107, 'ding': 4108, 'allowed': 4109, 'necessary': 4110, 'watever': 4111, 'shared': 4112, 'messaged': 4113, 'deus': 4114, 'tap': 4115, 'spile': 4116, 'broad': 4117, 'canal': 4118, 'engin': 4119, 'east': 4120, 'howard': 4121, 'cooked': 4122, 'cheat': 4123, 'block': 4124, 'ruining': 4125, 'muchi': 4126, 'ee': 4127, 'easily': 4128, 'custom': 4129, 'sac': 4130, 'jiayin': 4131, 'pobox45w2tg150p': 4132, 'forgotten': 4133, 'reverse': 4134, 'cheating': 4135, 'mathematics': 4136, '2waxsto': 4137, 'minimum': 4138, 'elaine': 4139, 'drunken': 4140, 'mess': 4141, 'ias': 4142, 'mb': 4143, 'cameravideo': 4144, 'desires': 4145, 'pending': 4146, 'bloomberg': 4147, '447797706009': 4148, 'httpcareers': 4149, 'bloombergcom': 4150, 'priscillas': 4151, 'kent': 4152, 'vale': 4153, 'wan2': 4154, 'meetgreet': 4155, 'westlife': 4156, '1unbreakable': 4157, '2untamed': 4158, '3unkempt': 4159, '83049': 4160, 'granite': 4161, 'strongbuy': 4162, 'explosive': 4163, 'nasdaq': 4164, 'cdgt': 4165, 'base': 4166, 'placement': 4167, 'didn‘t': 4168, 'lion': 4169, 'devouring': 4170, 'airtel': 4171, 'processed': 4172, '69669': 4173, 'jaya': 4174, 'forums': 4175, 'itlet': 4176, 'mumtaz': 4177, 'mumtazs': 4178, 'incredible': 4179, 'o2fwd': 4180, '18ptxt': 4181, 'ship': 4182, 'maturity': 4183, 'decimal': 4184, 'kavalan': 4185, 'causing': 4186, 'tonights': 4187, 'lib': 4188, 'difference': 4189, 'reschedule': 4190, 'despite': 4191, 'swoop': 4192, 'langport': 4193, 'senthil': 4194, 'mistakes': 4195, 'vegas': 4196, 'lou': 4197, 'b\\x92day': 4198, 'vewy': 4199, 'networking': 4200, 'pool': 4201, '09065989182': 4202, 'disconnect': 4203, 'callcoz': 4204, 'terrorist': 4205, 'itz': 4206, 'confirmd': 4207, 'verified': 4208, 'cnn': 4209, 'ibn': 4210, 'hppnss': 4211, 'sorrow': 4212, 'goodfriend': 4213, 'stayed': 4214, 'stone': 4215, 'mila': 4216, 'age23': 4217, 'blonde': 4218, 'mtalk': 4219, '6986618': 4220, '30pptxt': 4221, '5free': 4222, 'increments': 4223, 'help08718728876': 4224, 'ful': 4225, 'stones': 4226, 'atlast': 4227, 'desert': 4228, 'funk': 4229, 'tones2u': 4230, 'funeral': 4231, 'tnc': 4232, 'brah': 4233, 'protect': 4234, 'ethreats': 4235, 'sib': 4236, 'sensitive': 4237, 'passwordsatmsms': 4238, 'blu': 4239, 'ipad': 4240, 'bird': 4241, 'cheese': 4242, 'pink': 4243, 'httptms': 4244, 'widelivecomindex': 4245, '09061702893': 4246, 'practice': 4247, 'melt': 4248, 'ground': 4249, 'eek': 4250, '09061743386': 4251, 'heater': 4252, 'call2optout674': 4253, 'eta': 4254, 'housewives': 4255, '08717507711': 4256, 'btnational': 4257, 'landlines': 4258, 'dial': 4259, '09066364311': 4260, 'literally': 4261, 'kothi': 4262, 'prof': 4263, 'sem': 4264, 'student': 4265, 'actual': 4266, 'sathya': 4267, 'dealing': 4268, 'value': 4269, 'reasonable': 4270, 'kappa': 4271, 'piss': 4272, 'guessing': 4273, 'teeth': 4274, 'royal': 4275, 'sticky': 4276, 'indicate': 4277, 'repeat': 4278, 'calculation': 4279, 'blur': 4280, 'clothes': 4281, 'lush': 4282, 'day2find': 4283, 'greatest': 4284, 'courage': 4285, 'bear': 4286, 'defeat': 4287, 'heartgn': 4288, 'fucked': 4289, '430': 4290, 'beauty': 4291, 'natalja': 4292, '25f': 4293, 'yes440': 4294, 'no440': 4295, 'wwwsmsacunat27081980': 4296, 'moving': 4297, 'sunlight': 4298, 'jogging': 4299, 'shelf': 4300, 'mokka': 4301, '09061744553': 4302, 'polyh': 4303, 'bone': 4304, 'epsilon': 4305, 'mesages': 4306, 'lst': 4307, 'massive': 4308, 'fineabsolutly': 4309, 'wwwtcbiz': 4310, 'polo': 4311, '373': 4312, 'w1j': 4313, '6hl': 4314, 'academic': 4315, 'convinced': 4316, 'coast': 4317, 'suppose': 4318, 'explicit': 4319, '30': 4320, 'secs': 4321, '02073162414': 4322, '20pmin': 4323, 'clearly': 4324, 'gain': 4325, '89070': 4326, 'realise': 4327, 'mnths': 4328, '86888': 4329, 'subscribe6gbpmnth': 4330, '3hrs': 4331, 'stoptxtstop': 4332, 'feelin': 4333, 'managed': 4334, 'capital': 4335, 'acted': 4336, 'mis': 4337, 'prabha': 4338, 'loyal': 4339, 'customers': 4340, '09066380611': 4341, 'print': 4342, 'dokey': 4343, 'error': 4344, 'sleepin': 4345, 'minor': 4346, 'ni8swt': 4347, 'denis': 4348, 'woulda': 4349, 'miserable': 4350, 'shoppin': 4351, 'toopray': 4352, '08718726270': 4353, 'celebration': 4354, 'nuther': 4355, 'infections': 4356, 'henry': 4357, 'select': 4358, 'woot': 4359, 'donate': 4360, 'cme': 4361, 'sarasota': 4362, 'nat': 4363, 'cherish': 4364, 'wallpaper': 4365, 'dearslp': 4366, 'welltake': 4367, 'careswt': 4368, 'dreamsmuah': 4369, '4eva': 4370, 'garden': 4371, 'bulbs': 4372, 'seeds': 4373, '£3350': 4374, 'scotsman': 4375, 'go2': 4376, 'notxtcouk': 4377, 'gastroenteritis': 4378, 'replace': 4379, 'reduce': 4380, 'limiting': 4381, 'illness': 4382, '09061213237': 4383, '177': 4384, 'm227xy': 4385, 'favorite': 4386, 'eggs': 4387, 'amused': 4388, 'mega': 4389, 'shu': 4390, 'island': 4391, '2p': 4392, 'jurong': 4393, 'amore': 4394, 'chgs': 4395, 'aids': 4396, 'patent': 4397, 'cried': 4398, 'breather': 4399, 'granted': 4400, 'fulfil': 4401, 'xxxmobilemovieclub': 4402, 'httpwap': 4403, 'xxxmobilemovieclubcomnqjkgighjjgcbl': 4404, 'kim': 4405, 'gota': 4406, 'macedonia': 4407, 'goalsteam': 4408, 'trywales': 4409, '4txtú120': 4410, 'poboxox36504w45wq': 4411, 'ffffffffff': 4412, 'forced': 4413, 'convincing': 4414, 'packing': 4415, 'ahhh': 4416, 'vaguely': 4417, 'apologetic': 4418, 'fallen': 4419, 'actin': 4420, 'spoilt': 4421, 'badly': 4422, 'fainting': 4423, 'housework': 4424, 'cuppa': 4425, '£5month': 4426, 'timings': 4427, 'watts': 4428, 'arabian': 4429, 'steed': 4430, '07732584351': 4431, 'rodger': 4432, 'endowed': 4433, 'hep': 4434, 'immunisation': 4435, 'stubborn': 4436, 'sucker': 4437, 'suckers': 4438, 'thinked': 4439, 'smarter': 4440, 'crashing': 4441, 'accomodations': 4442, 'cave': 4443, 'offered': 4444, 'embarassing': 4445, 'jersey': 4446, 'devils': 4447, 'wings': 4448, 'incorrect': 4449, 'mallika': 4450, 'sherawat': 4451, 'yesgauti': 4452, 'sehwag': 4453, 'seekers': 4454, 'barbie': 4455, 'kens': 4456, 'youhow': 4457, 'performed': 4458, 'peoples': 4459, 'operate': 4460, 'tas': 4461, 'multis': 4462, 'factory': 4463, 'kanoil': 4464, 'you‘ll': 4465, 'casualty': 4466, 'stuff42moro': 4467, 'includes': 4468, 'telugu': 4469, 'moviewat': 4470, 'hairdressers': 4471, 'beforehand': 4472, 'ams': 4473, '4the': 4474, 'signin': 4475, 'memorable': 4476, 'ip': 4477, 'minecraft': 4478, 'server': 4479, 'grumpy': 4480, 'lying': 4481, 'plural': 4482, 'dinnermsg': 4483, 'openin': 4484, 'formal': 4485, 'weighthaha': 4486, '0871277810910pmin': 4487, 'eggpotato': 4488, 'ratio': 4489, 'hmmmy': 4490, '5903': 4491, '09064019788': 4492, 'box42wr29c': 4493, 'applespairsall': 4494, 'malarky': 4495, '7548': 4496, '4041': 4497, 'sao': 4498, 'predict': 4499, 'knowyetunde': 4500, 'involve': 4501, 'imposed': 4502, 'lucyxx': 4503, 'tmorrowpls': 4504, 'accomodate': 4505, 'gravel': 4506, 'yijuehotmailcom': 4507, 'svc': 4508, '69988': 4509, 'nver': 4510, 'cozsomtimes': 4511, 'hearts': 4512, 'ummmawill': 4513, 'inour': 4514, 'sindu': 4515, 'nevering': 4516, 'typical': 4517, 'dirt': 4518, 'chores': 4519, 'exist': 4520, 'hail': 4521, 'mist': 4522, 'aaooooright': 4523, 'meare': 4524, 'annoncement': 4525, '07046744435': 4526, 'envy': 4527, 'sees': 4528, 'parentsi': 4529, 'excited': 4530, 'bootydelious': 4531, '32f': 4532, 'yes434': 4533, 'no434': 4534, 'wwwsmsacubootydelious': 4535, 'bangbabes': 4536, 'bangb': 4537, 'internetservice': 4538, 'cultures': 4539, '09061701939': 4540, 's89': 4541, 'missunderstding': 4542, 'bridge': 4543, 'lager': 4544, 'axis': 4545, 'surname': 4546, 'clue': 4547, 'begins': 4548, 'goodfine': 4549, 'lifted': 4550, 'hopes': 4551, 'approaches': 4552, 'greatbye': 4553, 'handsome': 4554, 'finding': 4555, '30th': 4556, 'wwwareyouuniquecouk': 4557, 'league': 4558, 'ors': 4559, 'stool': 4560, '1pm': 4561, 'babyjontet': 4562, 'enc': 4563, 'ga': 4564, 'alter': 4565, 'dogg': 4566, 'refund': 4567, 'kkgoodstudy': 4568, 'prediction': 4569, 'ubandu': 4570, 'diskyou': 4571, 'scenery': 4572, 'flyng': 4573, 'aries': 4574, 'elama': 4575, 'mudyadhu': 4576, 'strict': 4577, 'gandhipuram': 4578, 'rubber': 4579, 'recdthirtyeight': 4580, 'youwhen': 4581, 'hearing': 4582, 'pleassssssseeeeee': 4583, 'sportsx': 4584, 'baig': 4585, 'watches': 4586, 'ups': 4587, '3days': 4588, 'usps': 4589, 'bribe': 4590, 'nipost': 4591, 'luton': 4592, '0125698789': 4593, 'sometme': 4594, 'club4mobilescom': 4595, '87070': 4596, 'club4': 4597, 'box1146': 4598, 'evo': 4599, 'narcotics': 4600, 'objection': 4601, 'rob': 4602, 'mack': 4603, 'theater': 4604, 'celebrations': 4605, 'keepintouch': 4606, 'gdeve': 4607, 'ahold': 4608, 'cruisin': 4609, 'dearshall': 4610, 'tonitebusy': 4611, 'streetshall': 4612, 'tonitethings': 4613, 'okvarunnathu': 4614, 'edukkukayee': 4615, 'raksha': 4616, 'ollubut': 4617, '3680offer': 4618, '28thfebtcs': 4619, 'gurl': 4620, 'appropriate': 4621, 'diesel': 4622, 'fridge': 4623, 'womdarfull': 4624, 'rodds1': 4625, '21m': 4626, 'aberdeen': 4627, 'united': 4628, 'kingdom': 4629, 'httpimg': 4630, 'acwicmb3cktz8r74': 4631, 'remb': 4632, 'jos': 4633, 'bookshelf': 4634, '85222': 4635, 'nowtcs': 4636, 'winnersclub': 4637, '84': 4638, 'gbp150week': 4639, 'waythis': 4640, 'uniquei': 4641, 'mylife': 4642, 'kkadvance': 4643, 'l8': 4644, 'gon': 4645, 'guild': 4646, 'kkapo': 4647, 'kgood': 4648, 'evaporated': 4649, 'stealing': 4650, 'employers': 4651, 'tadaaaaa': 4652, 'wined': 4653, 'dined': 4654, 'hiding': 4655, 'huiming': 4656, 'prestige': 4657, 'shag': 4658, 'dointerested': 4659, 'sextextukcom': 4660, 'xxuk': 4661, '69876': 4662, 'jeremiah': 4663, 'iphone': 4664, 'apeshit': 4665, 'safely': 4666, 'callingforgot': 4667, 'onam': 4668, 'sirjii': 4669, 'personmeet': 4670, 'insha': 4671, 'allahrakhesh': 4672, 'tata': 4673, 'aig': 4674, 'tisscotayseer': 4675, '08708800282': 4676, 'andrewsboy': 4677, 'chikkudb': 4678, 'audreys': 4679, 'dawns': 4680, 'refreshed': 4681, 'z': 4682, 'call2optoutf4q': 4683, 'rp176781': 4684, 'wwwregalportfoliocouk': 4685, '08717205546': 4686, 'uniform': 4687, 'spoil': 4688, 't91': 4689, 'gbp': 4690, '09057039994': 4691, 'lindsay': 4692, 'bars': 4693, 'heron': 4694, 'payasam': 4695, 'rinu': 4696, 'taught': 4697, 'becaus': 4698, 'verifying': 4699, 'prabu': 4700, 'repairs': 4701, 'followin': 4702, 'wallet': 4703, '945': 4704, 'owl': 4705, 'kickboxing': 4706, 'lap': 4707, '730ish': 4708, 'performance': 4709, 'calculated': 4710, 'monthnot': 4711, 'salam': 4712, 'wahleykkumsharing': 4713, 'newsby': 4714, 'tayseertissco': 4715, 'joinedhope': 4716, 'fineinshah': 4717, 'allahmeet': 4718, 'sometimerakheshvisitor': 4719, 'hmmmkbut': 4720, '2814032': 4721, '3x£150pw': 4722, 'e£nd': 4723, 'stoners': 4724, 'disastrous': 4725, 'fav': 4726, 'busetop': 4727, 'iron': 4728, 'okies': 4729, 'wendy': 4730, '09064012103': 4731, 'yesfrom': 4732, '09111032124': 4733, 'pobox12n146tf150p': 4734, 'siva': 4735, '09058094455': 4736, '1childish': 4737, '2naughty': 4738, '3sentiment': 4739, '4rowdy': 4740, '5ful': 4741, 'attitude': 4742, '6romantic': 4743, '7shy': 4744, '8attractive': 4745, '9funny': 4746, 'urination': 4747, 'hillsborough': 4748, 'shoul': 4749, 'txtjourney': 4750, 'gdnow': 4751, 'werethe': 4752, 'monkeespeople': 4753, 'monkeyaround': 4754, 'howdy': 4755, 'howu': 4756, 'foundurself': 4757, 'jobyet': 4758, 'sausagelove': 4759, 'blimey': 4760, 'exercise': 4761, 'concentration': 4762, 'hanks': 4763, 'lotsly': 4764, 'kkwhat': 4765, 'detail': 4766, 'transferacc': 4767, 'optimistic': 4768, 'consistently': 4769, 'practicum': 4770, 'links': 4771, 'ears': 4772, '120': 4773, 'feelingwavering': 4774, 'individualtime': 4775, 'heal': 4776, 'upgrdcentre': 4777, '9153': 4778, 'oral': 4779, 'slippery': 4780, 'bike': 4781, 'okmail': 4782, 'enters': 4783, 'differ': 4784, 'differbe': 4785, '69888nyt': 4786, 'ahwhat': 4787, 'machiany': 4788, 'whenre': 4789, 'mcr': 4790, 'jaykwon': 4791, 'thuglyfe': 4792, 'falconerf': 4793, 'faded': 4794, 'glory': 4795, 'ralphs': 4796, 'reunion': 4797, 'nowcan': 4798, 'accenture': 4799, 'jackson': 4800, 'reache': 4801, 'nuerologist': 4802, 'lolnice': 4803, 'westshore': 4804, 'significance': 4805, 'gs': 4806, 'ammo': 4807, 'ak': 4808, 'nojst': 4809, 'sno': 4810, 'boltblue': 4811, 'poly3': 4812, 'jamz': 4813, 'toxic': 4814, 'topped': 4815, 'httpwwwbubbletextcom': 4816, 'tgxxrz': 4817, 'problematic': 4818, 'unconscious': 4819, 'adults': 4820, 'abnormally': 4821, '08718729755': 4822, 'recieve': 4823, 'teletext': 4824, 'doublefaggot': 4825, '07815296484': 4826, '41782': 4827, '181104': 4828, 'bani': 4829, 'leads': 4830, 'buttons': 4831, 'wwwapplausestorecom': 4832, 'monthlysubscription50pmsg': 4833, 'max6month': 4834, 'tcsc': 4835, '2stop': 4836, 'famous': 4837, 'unconditionally': 4838, 'temper': 4839, 'oclock': 4840, 'bash': 4841, 'cooped': 4842, 'invitation': 4843, 'cali': 4844, 'weddin': 4845, 'alibi': 4846, 'sink': 4847, 'paces': 4848, 'cage': 4849, 'surrounded': 4850, 'cuck': 4851, 'weeddeficient': 4852, 'acknowledgement': 4853, 'astoundingly': 4854, 'tactless': 4855, 'oath': 4856, 'magic': 4857, 'silly': 4858, 'isn‘t': 4859, 'uv': 4860, 'causes': 4861, 'mutations': 4862, 'sunscreen': 4863, 'thesedays': 4864, 'lunchyou': 4865, 'onlinewhy': 4866, 'haven': 4867, 'bao': 4868, 'sugardad': 4869, 'ahgee': 4870, 'meim': 4871, 'brownie': 4872, 'ninish': 4873, 'icky': 4874, 'freek': 4875, 'ridden': 4876, 'missy': 4877, 'goggles': 4878, 'arguing': 4879, '09050005321': 4880, 'arngd': 4881, 'walkin': 4882, 'unfortuntly': 4883, 'bites': 4884, 'frnt': 4885, 'sayin': 4886, 'textand': 4887, '08002988890': 4888, 'exwife': 4889, 'jjc': 4890, 'tendencies': 4891, 'meive': 4892, 'gotany': 4893, 'srsly': 4894, 'yi': 4895, '07753741225': 4896, '08715203677': 4897, '42478': 4898, '241004': 4899, 'prix': 4900, 'stands': 4901, 'nitz': 4902, 'blastin': 4903, 'occur': 4904, 'rajnikant': 4905, 'oceand': 4906, 'xclusiveclubsaisai': 4907, '285': 4908, 'speciale': 4909, 'zouk': 4910, 'parisfree': 4911, 'roses': 4912, '0794674629107880867867': 4913, 'bridgwater': 4914, 'banter': 4915, 'bestrply': 4916, 'dependents': 4917, 'thanx4': 4918, 'cer': 4919, 'soonc': 4920, 'himthen': 4921, 'hundreds': 4922, 'handsomes': 4923, 'beauties': 4924, 'aunties': 4925, 'shock': 4926, 'friendships': 4927, 'grow': 4928, 'dismay': 4929, 'concerned': 4930, 'tootsie': 4931, 'seventeen': 4932, 'hundred': 4933, 'ml': 4934, 'apply2': 4935, 'biola': 4936, 'fetching': 4937, 'restock': 4938, 'brighten': 4939, 'allo': 4940, 'braved': 4941, 'triumphed': 4942, 'b‘ham': 4943, 'uncomfortable': 4944, '08715203694': 4945, 'sonetimes': 4946, 'rough': 4947, 'wesleys': 4948, 'dealers': 4949, 'cloud': 4950, 'wikipediacom': 4951, '88800': 4952, '89034': 4953, '08718711108': 4954, 'repent': 4955, 'positions': 4956, 'kama': 4957, 'sutra': 4958, 'nange': 4959, 'bakra': 4960, 'kalstiyathen': 4961, 'teacoffee': 4962, 'carlosll': 4963, 'lakhs': 4964, 'sun0819': 4965, 'helloyou': 4966, '08452810071': 4967, 'ditto': 4968, 'wetherspoons': 4969, 'piggy': 4970, 'freaky': 4971, 'scrappy': 4972, 'sdryb8i': 4973, 'lapdancer': 4974, 'g2': 4975, '1da': 4976, '150ppmsg': 4977, 'crying': 4978, 'imprtant': 4979, 'tomorw': 4980, 'dearme': 4981, 'cherthalain': 4982, 'bfore': 4983, 'starti': 4984, 'accordinglyor': 4985, 'comingtmorow': 4986, 'engaged': 4987, '448712404000please': 4988, '08712404000': 4989, '1405': 4990, '1680': 4991, '1843': 4992, 'entrepreneurs': 4993, 'alexs': 4994, 'corporation': 4995, 'ku': 4996, 'prevent': 4997, 'dehydration': 4998, 'fluids': 4999, 'soso': 5000, 'smsd': 5001, 'trek': 5002, 'harri': 5003, 'ngage': 5004, 'deck': 5005, 'wwwcnupdatescomnewsletter': 5006, 'alerts': 5007, 'shitstorm': 5008, 'attributed': 5009, '08714712388': 5010, '449071512431': 5011, 'sth': 5012, 'specs': 5013, 'px3748': 5014, '08714712394': 5015, 'macha': 5016, 'upseti': 5017, 'mindsetbelieve': 5018, 'uslet': 5019, 'againcall': 5020, 'sfine': 5021, 'wondar': 5022, 'flim': 5023, 'jelly': 5024, 'stillmaybe': 5025, 'sameso': 5026, 'itor': 5027, 'admiti': 5028, 'madthen': 5029, 'correctionor': 5030, 'lifeand': 5031, 'worldmay': 5032, 'runninglets': 5033, 'scrumptious': 5034, 'dao': 5035, 'jide': 5036, 'visiting': 5037, 'alertfrom': 5038, 'jeri': 5039, 'stewartsize': 5040, '2kbsubject': 5041, 'lowcost': 5042, 'prescripiton': 5043, 'drvgsto': 5044, 'steak': 5045, 'convincingjust': 5046, 'neglect': 5047, 'itjust': 5048, 'opportunityall': 5049, 'fastpls': 5050, 'prayers': 5051, 'dearrakhesh': 5052, 'hadnt': 5053, 'clocks': 5054, 'realised': 5055, 'wahay': 5056, 'gaze': 5057, '82324': 5058, 'tattoos': 5059, 'caveboy': 5060, 'sorryi': 5061, 'faith': 5062, 'possiblehope': 5063, 'worklove': 5064, 'beautifulmay': 5065, 'christmasmerry': 5066, 'youcarlos': 5067, 'isare': 5068, 'vibrate': 5069, '£79': 5070, '08704439680tscs': 5071, 'grandmas': 5072, 'hungover': 5073, 'unclaimed': 5074, '09066368327': 5075, 'closingdate040902': 5076, 'claimcode': 5077, 'm39m51': 5078, '£150pmmorefrommobile2bremovedmobypobox734ls27yf': 5079, 'gua': 5080, 'faber': 5081, 'dramatic': 5082, 'hunting': 5083, 'drunkard': 5084, 'idc': 5085, 'weaseling': 5086, 'trash': 5087, 'punish': 5088, 'beerage': 5089, 'randomlly': 5090, 'fixes': 5091, 'spelling': 5092, '100psms': 5093, '087018728737': 5094, 'toppoly': 5095, 'tune': 5096, '81618': 5097, 'fondly': 5098, 'ywhere': 5099, 'dogbreath': 5100, 'sounding': 5101, 'weighed': 5102, 'woohoo': 5103, 'uncountable': 5104, '9996': 5105, '14thmarch': 5106, 'availa': 5107, 'petey': 5108, 'whereare': 5109, 'friendsare': 5110, 'thekingshead': 5111, 'canlove': 5112, 'rg21': 5113, '4jx': 5114, 'dled': 5115, 'smokin': 5116, 'boooo': 5117, 'ssnervous': 5118, 'costumes': 5119, 'yowifes': 5120, 'outbid': 5121, 'simonwatson5120': 5122, 'shinco': 5123, 'plyr': 5124, 'acsmsrewards': 5125, 'notifications': 5126, 'youi': 5127, 'dobby': 5128, 'yourjob': 5129, 'hunnyhope': 5130, 'i\\x92llspeak': 5131, 'soonlots': 5132, 'starshine': 5133, 'sips': 5134, 'smsservices': 5135, 'yourinclusive': 5136, 'bits': 5137, 'turned': 5138, 'burial': 5139, 'rv': 5140, 'roadsrvx': 5141, 'voucherstext': 5142, 'nowsavamobmember': 5143, 'comprehensive': 5144, 'prashanthettans': 5145, 'samantha': 5146, 'guitar': 5147, 'impress': 5148, 'doug': 5149, 'realizes': 5150, 'trauma': 5151, 'swear': 5152, 'officewhats': 5153, 'mattermsg': 5154, 'inner': 5155, 'tigress': 5156, 'babyhope': 5157, 'urfeeling': 5158, 'bettersn': 5159, 'probthat': 5160, 'overdose': 5161, '83110': 5162, 'ana': 5163, 'sathy': 5164, 'rto': 5165, 'spoons': 5166, 'corvettes': 5167, '09061104283': 5168, '£150pm': 5169, 'bunkers': 5170, '07808': 5171, 'xxxxxx': 5172, '08719899217': 5173, 'posh': 5174, 'chaps': 5175, 'trial': 5176, 'prods': 5177, 'champneys': 5178, 'dob': 5179, '0721072': 5180, 'philosophical': 5181, 'hole': 5182, 'goodno': 5183, 'problembut': 5184, 'atleast': 5185, 'shakespeare': 5186, '09065171142stopsms08': 5187, 'httpdoit': 5188, 'mymoby': 5189, 'woul': 5190, 'curfew': 5191, 'gibe': 5192, 'getsleep': 5193, 'studdying': 5194, 'massages': 5195, 'yoyyooo': 5196, 'permissions': 5197, 'unsoldmike': 5198, 'hussey': 5199, 'faglord': 5200, 'nutter': 5201, 'cutter': 5202, 'ctter': 5203, 'cttergg': 5204, 'cttargg': 5205, 'ctargg': 5206, 'ctagg': 5207, 'thus': 5208, 'grateful': 5209, 'happier': 5210, 'agents': 5211, 'experiment': 5212, 'invoices': 5213, 'smell': 5214, 'tobacco': 5215, 'assumed': 5216, 'lastest': 5217, 'stereophonics': 5218, 'marley': 5219, 'dizzee': 5220, 'racal': 5221, 'libertines': 5222, 'strokes': 5223, 'nookii': 5224, 'bookmark': 5225, 'grinule': 5226, 'fudge': 5227, 'oreos': 5228, 'zahers': 5229, 'nauseous': 5230, 'dieting': 5231, 'ashleys': 5232, 'avalarr': 5233, 'hollalater': 5234, 'rounds': 5235, 'todaybut': 5236, 'websitenow': 5237, 'blogging': 5238, 'magicalsongsblogspotcom': 5239, 'chikkuil': 5240, 'slices': 5241, 'kvb': 5242, '£1million': 5243, 'ppt150x3normal': 5244, 'box403': 5245, 'w1t1jy': 5246, 'fridayhope': 5247, 'alternativehope': 5248, 'ore': 5249, 'owo': 5250, 'fro': 5251, 'samus': 5252, 'shoulders': 5253, 'matthew': 5254, '09063440451': 5255, '4lux': 5256, 'ppm150': 5257, 'box334': 5258, 'vomitin': 5259, 'kkare': 5260, '09061749602': 5261, '528': 5262, 'hp20': 5263, '1yf': 5264, 'stuffed': 5265, 'writhing': 5266, 'paypal': 5267, 'voila': 5268, 'pockets': 5269, 'folks': 5270, '150psms': 5271, 'sorta': 5272, 'blown': 5273, 'sophas': 5274, 'secondary': 5275, 'applying': 5276, 'ogunrinde': 5277, 'lodging': 5278, 'chk': 5279, 'ms': 5280, 'dict': 5281, 'shb': 5282, 'dobbys': 5283, 'stories': 5284, 'retired': 5285, 'natwest': 5286, 'chad': 5287, 'gymnastics': 5288, 'christians': 5289, 'backa': 5290, 'token': 5291, 'youthats': 5292, 'likingbe': 5293, 'seeno': 5294, 'thatdont': 5295, 'aptitude': 5296, '215': 5297, 'horse': 5298, 'wrongly': 5299, 'boggy': 5300, 'biatch': 5301, 'hesitate': 5302, 'weakness': 5303, 'notebook': 5304, 'eightish': 5305, 'carpark': 5306, 'ahthe': 5307, 'tomorrowcall': 5308, '67441233': 5309, 'ireneere': 5310, 'bus822656166382': 5311, 'cresubi': 5312, 'park6ph': 5313, '5wkg': 5314, 'daysèn': 5315, 'relaxing': 5316, '7am': 5317, '5ish': 5318, 'stripes': 5319, 'skirt': 5320, 'escalator': 5321, 'beth': 5322, 'charlie': 5323, 'nobut': 5324, 'syllabus': 5325, 'panasonic': 5326, 'bluetoothhdset': 5327, 'doublemins': 5328, 'doubletxt': 5329, '730pm': 5330, 'poyyarikaturkolathupalayamunjalur': 5331, 'posterode': 5332, 'heroi': 5333, 'apt': 5334, 'opportunitypls': 5335, 'ltemailgt': 5336, 'meat': 5337, 'supreme': 5338, 'toldshe': 5339, 'dearregret': 5340, 'cudnt': 5341, 'calldrove': 5342, 'ctla': 5343, 'homeleft': 5344, 'carente': 5345, 'ishtamayoohappy': 5346, 'bakrid': 5347, 'knowwait': 5348, 'glorious': 5349, 'finds': 5350, 'coaxing': 5351, 'images': 5352, 'fond': 5353, 'souveniers': 5354, 'cougarpen': 5355, '09065394514': 5356, 'scratches': 5357, 'nanny': 5358, 'shitin': 5359, 'defo': 5360, 'hardest': 5361, 'millions': 5362, 'lekdog': 5363, 'blankets': 5364, 'atten': 5365, '09058097218': 5366, 'doesn\\x92t': 5367, 'data': 5368, 'analysis': 5369, 'belligerent': 5370, 'les': 5371, 'rudi': 5372, 'snoringthey': 5373, 'ink': 5374, '515': 5375, 'howre': 5376, 'throwing': 5377, 'processnetworking': 5378, 'daysso': 5379, 'finalise': 5380, 'visitneed': 5381, 'wwwflirtpartyus': 5382, 'replys150': 5383, 'dentist': 5384, 'lul': 5385, 'nurses': 5386, 'obese': 5387, 'oyea': 5388, 'ami': 5389, 'parchi': 5390, 'kicchu': 5391, 'kaaj': 5392, 'korte': 5393, 'iccha': 5394, 'korche': 5395, 'tul': 5396, 'copies': 5397, 'sculpture': 5398, 'surya': 5399, 'pokkiri': 5400, 'attractioni': 5401, 'meshe': 5402, 'thoughtsi': 5403, 'hershe': 5404, 'dreamlove': 5405, 'namemy': 5406, 'hermy': 5407, 'herwill': 5408, 'sorrowsi': 5409, 'proove': 5410, 'planeti': 5411, 'praises': 5412, 'makiing': 5413, 'sambarlife': 5414, 'thenwill': 5415, 'needle': 5416, 'meetitz': 5417, '4few': 5418, 'conected': 5419, 'spatula': 5420, 'calis': 5421, 'complexities': 5422, 'freely': 5423, 'taxes': 5424, 'outrageous': 5425, 'ryder': 5426, 'unsoldnow': 5427, 'elvis': 5428, 'presleys': 5429, 'strips': 5430, 'postal': 5431, 'addressull': 5432, 'alrightokay': 5433, 'gifts': 5434, 'cliff': 5435, 'wrking': 5436, 'sittin': 5437, 'drops': 5438, 'hen': 5439, 'smoked': 5440, 'sfirst': 5441, 'timedhoni': 5442, 'teju': 5443, 'hourish': 5444, 'nothis': 5445, 'groundamla': 5446, 'convenience': 5447, 'evaluation': 5448, '449050000301': 5449, '09050000301': 5450, '80155': 5451, 'swap': 5452, 'chatter': 5453, 'chat80155': 5454, 'rcd': 5455, 'cheyyamoand': 5456, '80160': 5457, 'wwwtxt43com': 5458, 'throws': 5459, 'brothers': 5460, 'gayd': 5461, 'hmv1': 5462, 'errors': 5463, 'correction': 5464, 'painhope': 5465, 'tau': 5466, 'piah': 5467, '1stchoicecouk': 5468, '08707808226': 5469, 'ohas': 5470, 'shades': 5471, 'copied': 5472, 'notified': 5473, 'marketing': 5474, '84122': 5475, '08450542832': 5476, 'virgins': 5477, 'sexual': 5478, 'theirs': 5479, '69911£150p': 5480, 'sitter': 5481, 'kaitlyn': 5482, 'danger': 5483, 'peeps': 5484, 'comment': 5485, 'veggie': 5486, 'neighbors': 5487, 'computerless': 5488, 'balloon': 5489, 'passthey': 5490, 'ntswt': 5491, 'drms': 5492, 'melody': 5493, 'macs': 5494, 'hme': 5495, 'velachery': 5496, 'flippin': 5497, 'breaking': 5498, 'cstore': 5499, 'hangin': 5500, 'alivebetter': 5501, 'lodge': 5502, 'worrying': 5503, 'quizzes': 5504, 'popcorn': 5505, 'celeb': 5506, '087016248': 5507, '08719181503': 5508, 'thin': 5509, 'faultal': 5510, 'arguments': 5511, 'faultfed': 5512, 'himso': 5513, 'thanxxx': 5514, 'semi': 5515, 'exp': 5516, '30apr': 5517, 'maaaan': 5518, 'guessin': 5519, 'ilol': 5520, 'personally': 5521, 'wuldnt': 5522, 'lunchtime': 5523, 'organise': 5524, 'passable': 5525, 'phd': 5526, '5years': 5527, 'prakesh': 5528, 'betta': 5529, 'aging': 5530, 'products': 5531, 'accommodation': 5532, 'global': 5533, 'wwwphb1com': 5534, 'ph08700435505150p': 5535, 'submitting': 5536, 'snatch': 5537, 'hellodrivby0quit': 5538, 'edrunk': 5539, 'iff': 5540, 'pthis': 5541, 'senrddnot': 5542, 'dancce': 5543, 'drum': 5544, 'basqihave': 5545, '2nhite': 5546, 'ros': 5547, 'xxxxxxx': 5548, 'relieved': 5549, 'westonzoyland': 5550, 'greatness': 5551, 'goin2bed': 5552, 'only1more': 5553, 'mc': 5554, '2nitetell': 5555, 'every1': 5556, 'ava': 5557, 'goodtimeoli': 5558, 'melnite': 5559, 'ifink': 5560, 'sortedbut': 5561, 'everythin': 5562, 'monl8rsx': 5563, '08712402779': 5564, 'shun': 5565, 'bian': 5566, 'glass': 5567, 'exhibition': 5568, 'el': 5569, 'nino': 5570, 'himself': 5571, 'chikkugoing': 5572, 'downstem': 5573, '08718730555': 5574, 'wahala': 5575, 'inperialmusic': 5576, 'listening2the': 5577, 'by\\x94leafcutter': 5578, 'john\\x94sounds': 5579, 'insects': 5580, 'molestedsomeone': 5581, 'plumbingremixed': 5582, 'evil': 5583, 'acid': 5584, 'didntgive': 5585, 'bellearlier': 5586, 'hunnyjust': 5587, 'bedbut': 5588, 'thepub': 5589, 'uwana': 5590, 'uploads': 5591, 'jenxxx': 5592, '09096102316': 5593, 'cheery': 5594, '80488biz': 5595, 'weirdo': 5596, 'stalk': 5597, 'profiles': 5598, 'heygreat': 5599, 'dealfarm': 5600, '9am': 5601, '95pax': 5602, 'deposit': 5603, 'jap': 5604, 'disappeared': 5605, 'certificate': 5606, 'publish': 5607, 'wheellock': 5608, 'destination': 5609, 'fifty': 5610, 'settling': 5611, 'happenin': 5612, 'cocksuckers': 5613, 'ipads': 5614, 'worthless': 5615, 'novelty': 5616, 'tshirt': 5617, 'janx': 5618, 'designation': 5619, 'developer': 5620, 'videosound': 5621, 'videosounds2': 5622, 'logosmusicnews': 5623, 'jamstercouk': 5624, '09701213186': 5625, 'spirit': 5626, 'shattered': 5627, 'girlie': 5628, 'darker': 5629, 'styling': 5630, 'gray': 5631, 'remembr': 5632, 'listn': 5633, 'watevr': 5634, 'whileamp': 5635, '“harry': 5636, 'minus': 5637, 'paragraphs': 5638, 'coveragd': 5639, 'vasai': 5640, '4o': 5641, 'retard': 5642, 'bathroom': 5643, 'sang': 5644, 'uptown': 5645, '80s': 5646, 'icic': 5647, 'syria': 5648, 'heartsnot': 5649, 'gauge': 5650, 'pattys': 5651, 'mondaynxt': 5652, 'completing': 5653, 'ax': 5654, 'surgical': 5655, 'emergency': 5656, 'unfolds': 5657, 'korean': 5658, 'leonas': 5659, 'fredericksburg': 5660, 'que': 5661, 'pases': 5662, 'un': 5663, 'buen': 5664, 'tiempo': 5665, 'compass': 5666, 'worldgnun': 5667, 'way2smscom': 5668, 'baaaaabe': 5669, 'misss': 5670, 'youuuuu': 5671, 'convince': 5672, 'witot': 5673, 'buyer': 5674, 'melike': 5675, 'becz': 5676, 'undrstndng': 5677, 'avoids': 5678, 'suffer': 5679, 'steamboat': 5680, 'forgive': 5681, 'tp': 5682, 'bbq': 5683, '6ish': 5684, 'everyso': 5685, 'panicks': 5686, 'outhave': 5687, 'nick': 5688, 'types': 5689, 'auntie': 5690, 'huai': 5691, 'path': 5692, 'appear': 5693, 'paths': 5694, 'reserve': 5695, 'thirunelvali': 5696, 'evei': 5697, 'netno': 5698, 'availablei': 5699, 'tackle': 5700, 'tonght': 5701, 'ploughing': 5702, 'pile': 5703, 'ironing': 5704, 'chinky': 5705, 'wi': 5706, 'nz': 5707, 'geelater': 5708, 'aust': 5709, 'recharged': 5710, 'papa': 5711, 'detailed': 5712, 'losers': 5713, 'beta': 5714, 'kkany': 5715, 'noncomittal': 5716, 'snickering': 5717, 'chords': 5718, 'nofew': 5719, 'beforewent': 5720, 'win150ppmx3age16': 5721, 'boyf': 5722, 'interviw': 5723, 'worriedx': 5724, 'spreadsheet': 5725, 'determine': 5726, 'entire': 5727, 'dartboard': 5728, 'condition': 5729, 'doubles': 5730, 'trebles': 5731, 'recognises': 5732, 'wisheds': 5733, 'intrepid': 5734, 'duo': 5735, 'breeze': 5736, 'fresh': 5737, 'twittering': 5738, 'yagoing': 5739, 'ducking': 5740, 'chinchillas': 5741, 'function': 5742, 'headstart': 5743, '230ish': 5744, 'earlierwe': 5745, 'rummer': 5746, 'flying': 5747, 'optin': 5748, 'bbc': 5749, 'charts': 5750, 'thanks2': 5751, 'rajini': 5752, 'summers': 5753, 'matched': 5754, 'help08714742804': 5755, 'spys': 5756, '09099725823': 5757, 'offering': 5758, 'yalru': 5759, 'astne': 5760, 'innu': 5761, 'mundhe': 5762, 'ali': 5763, 'halla': 5764, 'bilo': 5765, 'marriageprogram': 5766, 'edhae': 5767, 'ovr': 5768, 'chikkuali': 5769, 'vargu': 5770, 'meow': 5771, 'meowd': 5772, 'prone': 5773, '07801543489': 5774, 'latests': 5775, 'wordcollect': 5776, 'no83355': 5777, 'tcllc': 5778, 'nyusa': 5779, '150pmt': 5780, 'msgrcvd18': 5781, 'permission': 5782, 'meetins': 5783, 'cumin': 5784, '09099726395': 5785, 'dose': 5786, 'tablet': 5787, 'incomm': 5788, 'waitshould': 5789, 'maps': 5790, 'tiring': 5791, 'concentrating': 5792, 'browsin': 5793, 'compulsory': 5794, 'investigate': 5795, 'www80488biz': 5796, 'moneyas': 5797, 'youmoney': 5798, 'thinghow': 5799, 'vitamin': 5800, 'crucial': 5801, 'someones': 5802, '2channel': 5803, 'leadership': 5804, 'skills': 5805, 'psychic': 5806, 'wquestion': 5807, 'hostbased': 5808, 'idps': 5809, 'linux': 5810, 'systems': 5811, 'converter': 5812, 'sayy': 5813, 'peteis': 5814, 'leannewhat': 5815, 'disc': 5816, 'champ': 5817, 'glasgow': 5818, 'kall': 5819, 'bestcongrats': 5820, 'lovin': 5821, 'install': 5822, 'browse': 5823, 'artists': 5824, 'corect': 5825, 'speling': 5826, '10803': 5827, '08714719523': 5828, 'hicts': 5829, 'employee': 5830, 'nike': 5831, 'sooo': 5832, 'shouting': 5833, 'dang': 5834, 'earliest': 5835, 'nordstrom': 5836, 'conference': 5837, 'wwworangecoukow': 5838, 'degree': 5839, 'bleak': 5840, 'shant': 5841, 'nearer': 5842, 'raiden': 5843, 'totes': 5844, 'pierre': 5845, 'cardin': 5846, 'establish': 5847, 'truro': 5848, 'ext': 5849, 'worryuse': 5850, 'cloth': 5851, 'packalso': 5852, 'sunroof': 5853, 'blanked': 5854, 'image': 5855, 'kalainar': 5856, 'officethenampet': 5857, 'nosy': 5858, 'reacting': 5859, 'freaked': 5860, 'satanic': 5861, 'imposter': 5862, 'meneed': 5863, 'priceso': 5864, 'itmay': 5865, 'destiny': 5866, 'companion': 5867, 'chef': 5868, 'listener': 5869, 'organizer': 5870, 'sympathetic': 5871, 'athletic': 5872, 'courageous': 5873, 'determined': 5874, 'dependable': 5875, 'psychologist': 5876, 'pest': 5877, 'exterminator': 5878, 'psychiatrist': 5879, 'healer': 5880, 'stylist': 5881, 'aaniye': 5882, 'pudunga': 5883, 'venaam': 5884, 'chez': 5885, 'jules': 5886, 'hhahhaahahah': 5887, 'nig': 5888, 'leonardo': 5889, 'dereks': 5890, '2years': 5891, 'strain': 5892, 'withdraw': 5893, 'anyhow': 5894, 'millers': 5895, 'spark': 5896, 'rawring': 5897, 'xoxo': 5898, 'somewhr': 5899, 'crushes': 5900, 'honeymoon': 5901, 'outfit': 5902, '08719899230': 5903, 'cheque': 5904, 'olympics': 5905, 'leo': 5906, 'patty': 5907, 'donewant': 5908, 'haul': 5909, 'wildlife': 5910, 'want2come': 5911, 'that2worzels': 5912, 'wizzle': 5913, 'shanghai': 5914, 'cya': 5915, '645': 5916, 'rtking': 5917, 'pro': 5918, 'inforingtonekingcouk': 5919, '08701237397': 5920, 'redeemable': 5921, 'wwwringtonekingcouk': 5922, 'thnx': 5923, 'sef': 5924, 'anjie': 5925, 'fring': 5926, 'nte': 5927, 'doesn‘t': 5928, '02072069400': 5929, 'bx': 5930, '526': 5931, 'talents': 5932, 'animal': 5933, 'shiny': 5934, 'warming': 5935, 'french': 5936, 'fooled': 5937, '0anetworks': 5938, 'companies': 5939, 'responsible': 5940, 'suppliers': 5941, 'guarantee': 5942, 'comedycant': 5943, 'freemsgfeelin': 5944, 'lnly': 5945, 'pictxt': 5946, 'keen': 5947, 'dammit': 5948, 'wright': 5949, 'fly': 5950, 'somewhat': 5951, 'laden': 5952, 'wrecked': 5953, 'spontaneously': 5954, 'goodevening': 5955, 'sif': 5956, 'rgent': 5957, 'daytime': 5958, 'busty': 5959, '09099726429': 5960, 'janinexx': 5961, 'spageddies': 5962, 'phasing': 5963, 'fourth': 5964, 'dimension': 5965, 'yesbut': 5966, 'meaningful': 5967, 'lmaonice': 5968, '09050001295': 5969, 'a21': 5970, 'mobsicom': 5971, '391784': 5972, 'dub': 5973, 'je': 5974, 'unspoken': 5975, 'squatting': 5976, '0089my': 5977, 'digits': 5978, '09063442151': 5979, 'sonathaya': 5980, 'soladha': 5981, 'raping': 5982, 'dudes': 5983, 'weightloss': 5984, 'mushy': 5985, 'embarrassed': 5986, 'stash': 5987, 'priya': 5988, 'kilos': 5989, 'accidant': 5990, 'tookplace': 5991, 'ghodbandar': 5992, 'slovely': 5993, 'ahnow': 5994, 'wherebtw': 5995, 'nus': 5996, 'sc': 5997, 'specialise': 5998, 'wad': 5999, 'desparately': 6000, 'stereo': 6001, 'mi': 6002, 'classmates': 6003, 'firesare': 6004, 'prebook': 6005, 'trackmarque': 6006, 'infovipclub4u': 6007, 'missionary': 6008, 'entertaining': 6009, 'hugh': 6010, 'laurie': 6011, 'praps': 6012, 'jon': 6013, 'spain': 6014, 'dinero': 6015, '\\x91rents': 6016, '12000pes': 6017, '£48': 6018, 'hunnywot': 6019, 'bedroomlove': 6020, 'complaining': 6021, 'mandy': 6022, 'sullivan': 6023, 'hotmix': 6024, 'fmyou': 6025, '£500000': 6026, 'drawplease': 6027, '09041940223': 6028, '290305': 6029, 'transferred': 6030, 'finns': 6031, 'downon': 6032, 'theacusations': 6033, 'itxt': 6034, 'iwana': 6035, 'wotu': 6036, 'thewend': 6037, 'haventcn': 6038, 'agesring': 6039, 'nething': 6040, 'satlove': 6041, 'dine': 6042, 'conacted': 6043, 'youto': 6044, '09111030116': 6045, 'pobox12n146tf15': 6046, 'vtired': 6047, 'inspection': 6048, 'nursery': 6049, 'detailsi': 6050, 'youmy': 6051, 'itmail': 6052, 'panren': 6053, 'paru': 6054, 'chuckin': 6055, 'trainners': 6056, 'carryin': 6057, 'bac': 6058, 'gooddhanush': 6059, 'needing': 6060, 'chikkusimple': 6061, 'habbahw': 6062, 'dileepthank': 6063, 'muchand': 6064, 'supportvery': 6065, 'hereremember': 6066, 'venugopal': 6067, 'mentionedtomorrow': 6068, 'latei': 6069, 'theregoodnight': 6070, 'remembrs': 6071, 'everytime': 6072, '3230': 6073, 'textbook': 6074, 'algorithms': 6075, 'edition': 6076, '09064018838': 6077, 'cro1327': 6078, 'recharge': 6079, 'yessura': 6080, 'tvlol': 6081, '4ui': 6082, 'intend': 6083, 'iwasmarinethat\\x92s': 6084, 'itried2tell': 6085, 'urmomi': 6086, 'careabout': 6087, 'learned': 6088, 'fake': 6089, 'iraq': 6090, 'afghanistan': 6091, 'stable': 6092, 'honest': 6093, 'traveling': 6094, 'blessget': 6095, '1225': 6096, '£50award': 6097, 'pai': 6098, 'seh': 6099, 'parts': 6100, 'walsall': 6101, 'tue': 6102, 'terry': 6103, 'ccna': 6104, 'shrek': 6105, '3db': 6106, 'fellow': 6107, 'somethings': 6108, 'dying': 6109, 'lifting': 6110, 'teresa': 6111, 'dec': 6112, 'yould': 6113, 'bam': 6114, 'aid': 6115, 'usmle': 6116, 'squishy': 6117, 'mwahs': 6118, 'hottest': 6119, 'prominent': 6120, 'cheek': 6121, 'september': 6122, 'hack': 6123, 'backdoor': 6124, 'fraction': 6125, 'neo69': 6126, '09050280520': 6127, 'subscribe': 6128, 'dps': 6129, 'bcm': 6130, '8027': 6131, '415': 6132, 'comingdown': 6133, 'dagood': 6134, 'murali': 6135, 'playerwhy': 6136, 'sts': 6137, 'engalnd': 6138, 'mia': 6139, 'elliot': 6140, 'kissing': 6141, '12price': 6142, 'xnet': 6143, 'mins100txtmth': 6144, '2optoutd3wv': 6145, 'wiproyou': 6146, 'matric': 6147, '850': 6148, '650': 6149, '08718726970': 6150, 'payments': 6151, 'fedex': 6152, 'kyou': 6153, 'reception': 6154, 'consensus': 6155, 'entertain': 6156, 'tag': 6157, 'bras': 6158, 'strewn': 6159, 'pillows': 6160, 'weaknesses': 6161, 'exposes': 6162, 'pulls': 6163, 'wicked': 6164, 'sh': 6165, 'readyall': 6166, 'supports': 6167, 'srt': 6168, 'ps3': 6169, 'jontin': 6170, 'prizeto': 6171, 'banned': 6172, 'pen': 6173, 'biro': 6174, '09058094594': 6175, 'unconsciously': 6176, 'unhappy': 6177, 'jog': 6178, '09061743811': 6179, 'lark': 6180, 'stations': 6181, '09090900040': 6182, 'extreme': 6183, 'sic': 6184, '60p': 6185, '247mp': 6186, '0870753331018': 6187, 'videopic': 6188, 'fones': 6189, 'wild': 6190, '150prcvd': 6191, 'stop2stop': 6192, 'lim': 6193, 'parachute': 6194, 'placed': 6195, 'lambda': 6196, 'angels': 6197, 'snowball': 6198, 'ello': 6199, 'ofice': 6200, 'oficegot': 6201, 'duffer': 6202, 'grr': 6203, 'pharmacy': 6204, 'cook': 6205, '08715500022': 6206, 'rpl': 6207, 'cnl': 6208, 'nor': 6209, 'fffff': 6210, 'lifebook': 6211, 'zhong': 6212, 'qing': 6213, 'act': 6214, '46': 6215, 'hypertension': 6216, 'mineall': 6217, 'annoyin': 6218, '08702490080': 6219, 'vpod': 6220, 'nigro': 6221, 'scratching': 6222, 'anyplaces': 6223, 'priority': 6224, 'ecstasy': 6225, '09090204448': 6226, 'minded': 6227, 'a£150': 6228, 'minapn': 6229, 'ls278bb': 6230, 'hittng': 6231, 'reflex': 6232, '1010': 6233, 'adewale': 6234, 'egbon': 6235, 'minstand': 6236, 'mary': 6237, 'deduct': 6238, 'wrks': 6239, 'monkey': 6240, 'asshole': 6241, 'grab': 6242, 'sliding': 6243, '09065394973': 6244, 'payback': 6245, '31': 6246, 'tescos': 6247, 'feathery': 6248, 'bowa': 6249, 'infra': 6250, 'gep': 6251, '2006': 6252, 'fifa': 6253, 'shhhhh': 6254, 'related': 6255, 'arul': 6256, 'amk': 6257, '09061743810': 6258, 'length': 6259, 'santha': 6260, 'corrct': 6261, 'dane': 6262, 'baskets': 6263, 'rupaul': 6264, 'practising': 6265, 'curtsey': 6266, 'satjust': 6267, 'payed2day': 6268, 'havbeen': 6269, 'a£50': 6270, 'rise': 6271, '4my': 6272, 'havebeen': 6273, 'preschoolcoordinator': 6274, '2i': 6275, 'feelingood': 6276, 'memory': 6277, 'converted': 6278, 'themobyo': 6279, 'yohere': 6280, 'ssindia': 6281, 'african': 6282, 'soil': 6283, 'roles': 6284, 'outreach': 6285, '8lb': 6286, '7oz': 6287, 'brilliantly': 6288, 'forwarding': 6289, 'intention': 6290, 'visitors': 6291, 'rules': 6292, 'bend': 6293, 'thia': 6294, 'inlude': 6295, 'previews': 6296, 'ambrithmaduraimet': 6297, 'dha': 6298, 'marrgeremembr': 6299, 'kitty': 6300, 'shaved': 6301, 'anybodys': 6302, 'tactful': 6303, 'skillgame1winaweek': 6304, 'age16150ppermesssubscription': 6305, 'eggspert': 6306, 'potato': 6307, 'head…': 6308, 'crammed': 6309, 'satsgettin': 6310, '447per': 6311, 'apologize': 6312, 'admit': 6313, 'pei': 6314, 'subtoitles': 6315, 'jot': 6316, 'storelike': 6317, 'cereals': 6318, 'gari': 6319, 'bold2': 6320, '09094100151': 6321, 'cast': 6322, 'gbp5month': 6323, 'box61m60': 6324, '1er': 6325, 'thkin': 6326, 'resubbing': 6327, 'shadow': 6328, 'breadstick': 6329, 'saeed': 6330, '09066362220': 6331, 'redim': 6332, 'blueu': 6333, 'purpleu': 6334, 'pinku': 6335, 'orangei': 6336, 'lyk': 6337, 'greeni': 6338, 'yelowi': 6339, 'blackim': 6340, 'browni': 6341, 'arranging': 6342, 'eldest': 6343, 'drugdealer': 6344, 'wither': 6345, 'eg23f': 6346, 'eg23g': 6347, 'wondarfull': 6348, 'messagestext': 6349, 'nowuse': 6350, 'web2mobile': 6351, 'txt250com': 6352, 'box139': 6353, 'la32wu': 6354, 'txtx': 6355, 'hunonbus': 6356, 'donyt': 6357, 'homebut': 6358, 'latelyxxx': 6359, '85233': 6360, 'freeringtonereply': 6361, 'justthought': 6362, 'sayhey': 6363, 'doinnearly': 6364, 'endof': 6365, 'offdam': 6366, 'nevamindwe': 6367, '2hook': 6368, 'uwant': 6369, 'ownyouve': 6370, 'stressed': 6371, 'skallis': 6372, 'soooo': 6373, 'provider': 6374, 'cutest': 6375, 'dice': 6376, 'help08700469649': 6377, 'box420': 6378, 'howda': 6379, 'mathe': 6380, 'samachara': 6381, 'audrie': 6382, 'autocorrect': 6383, 'simulate': 6384, 'readiness': 6385, 'andor': 6386, 'lara': 6387, 'supplies': 6388, 'guesses': 6389, 'attach': 6390, '087123002209am7pm': 6391, 'washob': 6392, 'nobbing': 6393, 'nickey': 6394, 'platt': 6395, 'ryan': 6396, 'spotty': 6397, 'province': 6398, 'sterling': 6399, 'problemfree': 6400, 'hall': 6401, 'hesitation': 6402, 'intha': 6403, 'ponnungale': 6404, 'ipaditan': 6405, 'rejected': 6406, 'noisy': 6407, 'needa': 6408, 'sfrom': 6409, 'manual': 6410, 'processits': 6411, 'reset': 6412, 'troubleshooting': 6413, 'b4u': 6414, 'wc': 6415, '2703': 6416, 'marsms': 6417, 'wwwb4utelecom': 6418, '08717168528': 6419, 'strongly': 6420, 'creativity': 6421, 'stifled': 6422, 'requirements': 6423, 'strangersaw': 6424, 'he\\x92s': 6425, 'nowstill': 6426, 'mrur': 6427, '2getha': 6428, 'buffy': 6429, 'qlynnbv': 6430, 'help08700621170150p': 6431, '8830': 6432, 'nosh': 6433, 'waaaat': 6434, 'lololo': 6435, 'tables': 6436, 'occupied': 6437, 'comei': 6438, 'documents': 6439, 'submitted': 6440, 'stapati': 6441, 'cutie': 6442, 'hills': 6443, 'honesty': 6444, 'specialisation': 6445, 'labor': 6446, 'shakara': 6447, 'beggar': 6448, 'dent': 6449, 'crickiting': 6450, 'imin': 6451, 'towndontmatter': 6452, 'urgoin': 6453, 'outl8rjust': 6454, 'reallyneed': 6455, '2docdplease': 6456, 'dontplease': 6457, 'dontignore': 6458, 'mycallsu': 6459, 'thecd': 6460, 'isvimportant': 6461, 'tome': 6462, 'yavnt': 6463, 'popping': 6464, 'ibuprofens': 6465, 'sip': 6466, 'grown': 6467, 'chinatown': 6468, 'porridge': 6469, 'claypot': 6470, 'yam': 6471, 'fishhead': 6472, 'beehoon': 6473, 'jaklin': 6474, 'nearby': 6475, 'cliffs': 6476, '449month': 6477, 'bundle': 6478, 'deals': 6479, 'avble': 6480, 'call2optoutj': 6481, 'mf': 6482, 'ooh': 6483, '4got': 6484, 'moseley': 6485, 'weds': 6486, 'thankyou': 6487, 'pendingi': 6488, 'dayswill': 6489, 'thrurespect': 6490, 'homecheck': 6491, 'loveable': 6492, 'eternal': 6493, 'noble': 6494, 'truthful': 6495, 'intimate': 6496, 'enamous': 6497, 'textin': 6498, 'amigos': 6499, 'burn': 6500, 'progress': 6501, 'werent': 6502, 'arty': 6503, 'collages': 6504, 'tryin': 6505, '2hrs': 6506, 'waliking': 6507, 'cartons': 6508, 'shelves': 6509, '08714712379': 6510, 'mirror': 6511, 'k718': 6512, '09065069120': 6513, 'jod': 6514, 'keris': 6515, 'smidgin': 6516, 'collegexx': 6517, 'intentions': 6518, 'accordin': 6519, 'knocking': 6520, 'sicomo': 6521, 'nolistened2the': 6522, 'plaid': 6523, 'albumquite': 6524, 'gdthe': 6525, 'air1': 6526, 'hilariousalso': 6527, 'bought\\x94braindance\\x94a': 6528, 'compofstuff': 6529, 'aphex\\x92s': 6530, 'abelu': 6531, 'hav2hear': 6532, 'itc': 6533, 'nelson': 6534, 'bbs': 6535, 'unmits': 6536, 'newspapers': 6537, 'yummmm': 6538, 'puzzeles': 6539, '4goten': 6540, 'scammers': 6541, 'smartthough': 6542, 'msgsubscription': 6543, 'passion': 6544, '09099726481': 6545, 'dena': 6546, '£1minmobsmorelkpobox177hp51fl': 6547, 'r836': 6548, '09065069154': 6549, 'threats': 6550, 'sales': 6551, 'shifad': 6552, 'raised': 6553, 'doctors': 6554, 'reminds': 6555, '2godid': 6556, 'mindi': 6557, 'toleratbcs': 6558, 'splashmobile': 6559, 'subscrition': 6560, 'dust': 6561, '88877free': 6562, '88877': 6563, '3pound': 6564, 'watchin': 6565, 'meaningless': 6566, 'alls': 6567, 'brdget': 6568, 'jones': 6569, 'inever': 6570, 'hmmbad': 6571, 'newshype': 6572, '700': 6573, 'studio': 6574, 'takenonly': 6575, 'bedrm900': 6576, 'velly': 6577, 'marking': 6578, '2stoptx': 6579, '08718738034': 6580, 'vai': 6581, 'hanger': 6582, 'arrow': 6583, 'blanket': 6584, '08718726971': 6585, 'tddnewsletteremc1couk': 6586, 'thedailydraw': 6587, 'dozens': 6588, 'prizeswith': 6589, 'significant': 6590, 'waqt': 6591, 'pehle': 6592, 'naseeb': 6593, 'zyada': 6594, 'kisi': 6595, 'ko': 6596, 'kuch': 6597, 'miltazindgi': 6598, 'hum': 6599, 'sochte': 6600, 'zindgi': 6601, 'ham': 6602, 'jeetey': 6603, 'stalking': 6604, 'reminded': 6605, 'varaya': 6606, 'elaya': 6607, '100603': 6608, '09066368753': 6609, '97n7qp': 6610, 'anand': 6611, 'beach': 6612, 'expected': 6613, 'deadwell': 6614, 'jez': 6615, 'todo': 6616, 'workand': 6617, 'whilltake': 6618, 'zogtorius': 6619, 'i\\x92ve': 6620, 'financial': 6621, 'problemi': 6622, 'alian': 6623, 'freenokia': 6624, 'or2optouthv9d': 6625, 'posible': 6626, 'century': 6627, 'frwd': 6628, 'sorts': 6629, 'restrictions': 6630, 'buddys': 6631, '08712402902': 6632, 'owned': 6633, 'possessive': 6634, 'nohe': 6635, 'clarification': 6636, 'coimbatore': 6637, 'expired': 6638, 'resub': 6639, 'monoc': 6640, 'monos': 6641, 'polyc': 6642, 'stream': 6643, '0871212025016': 6644, 'categories': 6645, 'ethnicity': 6646, 'census': 6647, 'transcribing': 6648, 'cakes': 6649, 'draws': 6650, 'goodmate': 6651, 'asusual1': 6652, 'cheered': 6653, 'franyxxxxx': 6654, 'batt': 6655, 'becausethey': 6656, '09058098002': 6657, 'pobox1': 6658, 'w14rg': 6659, 'gained': 6660, 'pressure': 6661, 'limits': 6662, 'doke': 6663, 'laying': 6664, 'neshanthtel': 6665, 'byatch': 6666, 'whassup': 6667, 'cl': 6668, 'filthyguys': 6669, 'slo': 6670, 'slo4msgs': 6671, 'chiong': 6672, 'dialogue': 6673, 'reltnship': 6674, 'wipe': 6675, 'timegud': 6676, 'pose': 6677, 'comb': 6678, 'dryer': 6679, 'fps': 6680, 'computational': 6681, 'madamregret': 6682, 'disturbancemight': 6683, 'dlf': 6684, 'premaricakindly': 6685, 'informedrgdsrakheshkerala': 6686, 'gotto': 6687, '08702840625': 6688, 'comuk220cm2': 6689, 'err': 6690, 'kbut': 6691, 'hitteranyway': 6692, 'offline': 6693, 'anjolas': 6694, 'ithis': 6695, 'wwwasjesuscom': 6696, 'directors': 6697, 'lac': 6698, 'deposited': 6699, 'taxless': 6700, 'suply': 6701, 'projects': 6702, 'imf': 6703, 'blocked': 6704, 'corrupt': 6705, 'itna': 6706, 'karo': 6707, 'pura': 6708, 'padhegm': 6709, 'torrents': 6710, 'particularly': 6711, 'slowing': 6712, 'commit': 6713, '83370': 6714, 'wwwmusictrivianet': 6715, 'rightio': 6716, '1148': 6717, 'brum': 6718, 'scorable': 6719, 'paranoid': 6720, 'brin': 6721, 'sheet': 6722, 'kgive': 6723, 'complain': 6724, 'onlybettr': 6725, 'bsnl': 6726, 'offc': 6727, 'payed': 6728, 'suganya': 6729, 'dessert': 6730, 'abeg': 6731, 'sponsors': 6732, 'onum': 6733, 'candont': 6734, 'poet': 6735, 'imaginationmy': 6736, 'carso': 6737, 'rr': 6738, 'famamus': 6739, 'locks': 6740, 'jenne': 6741, 'easiest': 6742, 'barcelona': 6743, 'sppok': 6744, 'complementary': 6745, 'wa14': 6746, '2px': 6747, 'sender': 6748, 'kdo': 6749, 'daurgent': 6750, 'pansy': 6751, 'jungle': 6752, 'kanji': 6753, 'drinkpa': 6754, 'srs': 6755, 'drizzling': 6756, 'appointments': 6757, 'excused': 6758, 'drama': 6759, 'plsi': 6760, 'struggling': 6761, 'placeno': 6762, 'ego': 6763, 'necessity': 6764, 'gowait': 6765, 'reppurcussions': 6766, 'cosign': 6767, 'hvae': 6768, '09061701444': 6769, 'hcl': 6770, 'requires': 6771, 'freshers': 6772, 'processexcellent': 6773, 'neededsalary': 6774, 'mssuman': 6775, 'telephonic': 6776, 'restuwud': 6777, 'reliant': 6778, 'fwiw': 6779, 'afford': 6780, 'kanowhr': 6781, 'sq825': 6782, 'arrival': 6783, 'citylink': 6784, 'props': 6785, 'pleasant': 6786, 'statements': 6787, '6230': 6788, 'pobox11414tcrw1': 6789, 'bognor': 6790, 'splendid': 6791, 'yesim': 6792, 'ktv': 6793, 'misplaced': 6794, 'computers': 6795, 'begun': 6796, 'registration': 6797, 'permanent': 6798, 'residency': 6799, 'risks': 6800, 'hmmmhow': 6801, 'predicting': 6802, 'accumulation': 6803, 'programs': 6804, 'belongs': 6805, 'herwho': 6806, 'fated': 6807, 'shoranur': 6808, 'fuelled': 6809, 'concern': 6810, 'prior': 6811, 'grief': 6812, 'text82228': 6813, 'logos': 6814, 'wwwtxt82228com': 6815, 'infotxt82228couk': 6816, 'honestly': 6817, 'promptly': 6818, 'burnt': 6819, 'snap': 6820, 'quizclub': 6821, '80122300pwk': 6822, 'sprwm': 6823, 'ph08704050406': 6824, 'gmw': 6825, 'connected': 6826, 'someplace': 6827, 'goods': 6828, 'pressies': 6829, 'ultimately': 6830, 'tor': 6831, 'motive': 6832, 'tui': 6833, 'achieve': 6834, 'korli': 6835, 'we‘ll': 6836, 'dock': 6837, 'rolled': 6838, 'newscaster': 6839, 'dabbles': 6840, 'flute': 6841, 'wheel': 6842, 'vid': 6843, 'keyword': 6844, 'the4th': 6845, 'october': 6846, '83435': 6847, 'elaborating': 6848, 'safety': 6849, 'aspects': 6850, 'tarot': 6851, '85555': 6852, 'oursso': 6853, 'youany': 6854, 'horniest': 6855, 'nytec2a3lpmsg150p': 6856, 'flow': 6857, 'developed': 6858, 'ovarian': 6859, 'cysts': 6860, 'shrink': 6861, 'onit': 6862, 'upping': 6863, 'grams': 6864, 'timin': 6865, 'apes': 6866, 'ibm': 6867, 'hp': 6868, 'gosh': 6869, 'spose': 6870, 'rimac': 6871, 'arestaurant': 6872, 'squid': 6873, 'dosomething': 6874, 'ucall': 6875, 'wrki': 6876, 'dabooks': 6877, 'nite2': 6878, 'eachother': 6879, 'luckily': 6880, 'starring': 6881, 'restocked': 6882, 'wwwtklscom': 6883, 'stoptxtstop£150week': 6884, 'smoothly': 6885, 'challenging': 6886, 'pple700': 6887, 'nightsexcellent': 6888, 'breakfast': 6889, 'hamper': 6890, 'cc100pmin': 6891, 'daal': 6892, 'above': 6893, '0870737910216yrs': 6894, '£150wk': 6895, 'unni': 6896, 'rechargerakhesh': 6897, 'lacking': 6898, 'particular': 6899, 'dramastorms': 6900, 'forfeit': 6901, 'digi': 6902, 'coupla': 6903, '077xxx': 6904, '09066362206': 6905, 'sundayish': 6906, 'prasad': 6907, 'rcbbattle': 6908, 'kochi': 6909, 'checkup': 6910, 'smear': 6911, 'gobi': 6912, 'pandy': 6913, '4w': 6914, 'technologies': 6915, 'todayhe': 6916, 'olowoyey': 6917, 'uscedu': 6918, 'argentina': 6919, 'taxt': 6920, 'massagetiepos': 6921, 'lool': 6922, 'taylors': 6923, 'shaking': 6924, 'timeslil': 6925, 'busyi': 6926, 'scarcasim': 6927, 'naal': 6928, 'eruku': 6929, 'chikkuwat': 6930, 'w4': 6931, '5wq': 6932, 'impressively': 6933, 'sensible': 6934, 'alsoor': 6935, 'danalla': 6936, 'obedient': 6937, 'ft': 6938, 'combination': 6939, 'needy': 6940, 'playng': 6941, '1mcflyall': 6942, 'ab': 6943, 'sara': 6944, 'jorgeshock': 6945, 'smithswitch': 6946, 'yupz': 6947, 'modelsony': 6948, 'ericson': 6949, 'der': 6950, 'luks': 6951, 'modl': 6952, 'cheesy': 6953, 'frosty': 6954, 'witin': 6955, 'fans': 6956, '0870141701216': 6957, '4txt120p': 6958, '10th': 6959, '09050000555': 6960, 'ba128nnfwfly150ppm': 6961, 'nudist': 6962, 'themed': 6963, 'pump': 6964, '£12': 6965, 'signal': 6966, 'unusual': 6967, 'palm': 6968, 'printing': 6969, 'handing': 6970, '83021': 6971, 'stated': 6972, 'perpetual': 6973, 'dd': 6974, 'pract': 6975, 'flung': 6976, 'justbeen': 6977, 'overa': 6978, 'brains': 6979, 'mush': 6980, 'tunde': 6981, 'missions': 6982, '20m12aq': 6983, '“': 6984, 'lux': 6985, 'eh74rr': 6986, 'avo': 6987, 'crashed': 6988, 'cuddled': 6989, 'chachi': 6990, 'pl': 6991, 'tiz': 6992, 'kanagu': 6993, 'prices': 6994, 'ringing': 6995, 'houseful': 6996, 'brats': 6997, 'pulling': 6998, 'nowonion': 6999, 'derp': 7000, 'abusers': 7001, 'lipo': 7002, 'netflix': 7003, 'clash': 7004, 'arr': 7005, 'oscar': 7006, 'rebtel': 7007, 'firefox': 7008, '69969': 7009, 'bcmsfwc1n3xx': 7010, 'impressed': 7011, 'funs': 7012, 'footy': 7013, 'stadium': 7014, 'large': 7015, 'cocacola': 7016, 'teenager': 7017, 'teluguthts': 7018, 'replacing': 7019, 'mittelschmertz': 7020, 'paracetamol': 7021, 'salespee': 7022, 'arrived': 7023, 'cthen': 7024, 'conclusion': 7025, 'references': 7026, 'atyour': 7027, 'u’ve': 7028, '£50': 7029, 'instant': 7030, '08715203028': 7031, '9th': 7032, '£50£500': 7033, 'rugby': 7034, 'affidavit': 7035, 'twiggs': 7036, 'courtroom': 7037, 'freemsgfav': 7038, 'tonesreply': 7039, 'showers': 7040, 'possessiveness': 7041, 'poured': 7042, 'golden': 7043, 'lasting': 7044, 'mobs': 7045, 'breathe1': 7046, 'crazyin': 7047, 'sleepingwith': 7048, 'finest': 7049, 'ymca': 7050, 'getzedcouk': 7051, 'pobox365o4w45wq': 7052, 'wtc': 7053, 'weiyi': 7054, '\\x93its': 7055, 'flowers': 7056, '505060': 7057, 'godtaken': 7058, 'teethis': 7059, 'paining': 7060, 'romcapspam': 7061, 'presence': 7062, 'outgoing': 7063, 'maggi': 7064, 'mee': 7065, '08712103738': 7066, 'cough': 7067, 'com': 7068, 'bbdpooja': 7069, 'pimpleseven': 7070, 'blackand': 7071, 'sweatter': 7072, 'ambitious': 7073, 'miiiiiiissssssssss': 7074, 'tunji': 7075, 'misscall': 7076, 'frndz': 7077, '6missed': 7078, 'freemessage': 7079, 'jamsterget': 7080, 'frog': 7081, 'mad1': 7082, 'mad2': 7083, 'gbpweek': 7084, 'wipro': 7085, 'tall': 7086, 'robs': 7087, 'avenge': 7088, 'choices': 7089, 'toss': 7090, 'gudni8': 7091, 'dancin': 7092, 'explicitly': 7093, 'nora': 7094, 'smith': 7095, 'gayle': 7096, 'crucify': 7097, 'butting': 7098, 'vs': 7099, 'cedar': 7100, 'durham': 7101, 'reserved': 7102, '69855': 7103, 'stopbcm': 7104, 'sf': 7105, 'wall': 7106, 'printer': 7107, 'groovy': 7108, 'groovying': 7109, 'harishs': 7110, 'transfred': 7111, 'acnt': 7112, 'nowadayslot': 7113, 'showroomscity': 7114, 'shaping': 7115, 'attending': 7116, 'doinat': 7117, 'callon': 7118, 'rons': 7119, 'kkyesterday': 7120, 'pdatenow': 7121, 'call2optoutyhl': 7122, 'configure': 7123, 'i’m': 7124, 'isn’t': 7125, 'anal': 7126, 'pears': 7127, 'such': 7128, 'oooooh': 7129, '09058094454': 7130, 'thatnow': 7131, '54': 7132, 'resubmit': 7133, 'expiry': 7134, 'we\\x92ve': 7135, 'mint': 7136, 'uxxxx': 7137, 'humans': 7138, 'studyn': 7139, 'everyboy': 7140, 'xxxxxxxx': 7141, '532': 7142, '924': 7143, '863': 7144, '725': 7145, 'brilliant1thingi': 7146, 'answr': 7147, 'liquor': 7148, 'loko': 7149, 'lined': 7150, 'laughs': 7151, 'fireplace': 7152, 'icon': 7153, '08712400200': 7154, 'fifth': 7155, 'woozles': 7156, 'weasels': 7157, '08718723815': 7158, 'machines': 7159, 'ignorant': 7160, 'mys': 7161, 'downs': 7162, 'fletcher': 7163, '27603': 7164, '08714714011': 7165, 'teaching': 7166, 'bowls': 7167, 'cozy': 7168, 'nightnobody': 7169, 'buzzzz': 7170, 'vibrator': 7171, 'shake': 7172, 'trends': 7173, 'pros': 7174, 'cons': 7175, 'description': 7176, 'nuclear': 7177, 'fusion': 7178, 'iter': 7179, 'jet': 7180, 'nonenowhere': 7181, 'ikno': 7182, 'doesdiscountshitinnit': 7183, 'jabo': 7184, 'slower': 7185, 'maniac': 7186, 'hadya': 7187, 'sapna': 7188, 'manege': 7189, 'yday': 7190, 'hogidhechinnu': 7191, 'swalpa': 7192, 'agidhane': 7193, 'typelyk': 7194, 'footblcrckt': 7195, 'swell': 7196, 'tim': 7197, 'bollox': 7198, 'tol': 7199, 'ingredients': 7200, 'pocy': 7201, 'non': 7202, 'call2optout4qf2': 7203, 'senor': 7204, 'giggle': 7205, 'possibly': 7206, 'person2die': 7207, 'nvq': 7208, 'professional': 7209, 'tiger': 7210, 'woods': 7211, 'grinder': 7212, 'youkwhere': 7213, 'buyers': 7214, 'figuring': 7215, 'entirely': 7216, 'knowhe': 7217, 'disconnected': 7218, 'onluy': 7219, 'matters': 7220, 'offcampus': 7221, 'rileys': 7222, 'ew': 7223, 'wesley': 7224, 'howve': 7225, 'lingo': 7226, '400minscall': 7227, 'call2optoutj5q': 7228, 'medont': 7229, 'lm': 7230, '69200': 7231, 'chrgd50p': 7232, '2exit': 7233, 'approaching': 7234, 'sankranti': 7235, 'republic': 7236, 'shivratri': 7237, 'ugadi': 7238, 'fools': 7239, 'independence': 7240, 'friendshipmotherfatherteacherschildrens': 7241, 'festival': 7242, 'dasara': 7243, 'mornings': 7244, 'afternoons': 7245, 'rememberi': 7246, 'theseyours': 7247, 'lifeis': 7248, 'daywith': 7249, 'thoughts': 7250, 'somewheresomeone': 7251, 'tosend': 7252, 'greeting': 7253, 'selflessness': 7254, 'initiate': 7255, 'tallent': 7256, 'wasting': 7257, 'portal': 7258, 'dont4get2text': 7259, 'lennon': 7260, 'bothering': 7261, 'shorethe': 7262, 'fox': 7263, 'frndsship': 7264, 'dwn': 7265, 'slaaaaave': 7266, 'summon': 7267, '£3365': 7268, 'appendix': 7269, 'slob': 7270, 'gudnite': 7271, 'topicsorry': 7272, 'webpage': 7273, 'yeesh': 7274, 'unsubscribed': 7275, 'hunks': 7276, 'httpgotbabescouk': 7277, 'subscriptions': 7278, 'gopalettan': 7279, 'participate': 7280, 'kkfrom': 7281, 'abroad': 7282, 'xxsp': 7283, 'stopcost': 7284, '08712400603': 7285, 'agent': 7286, 'goodies': 7287, 'mat': 7288, 'ay': 7289, 'satü': 7290, 'steal': 7291, 'isaiahd': 7292, 'expert': 7293, 'ssi': 7294, 'thinl': 7295, 'sachinjust': 7296, 'importantly': 7297, 'tightly': 7298, 'wnevr': 7299, 'fal': 7300, 'fals': 7301, 'yen': 7302, 'madodu': 7303, 'nav': 7304, 'pretsorginta': 7305, 'nammanna': 7306, 'pretsovru': 7307, 'alwa': 7308, 'lord': 7309, 'ringsreturn': 7310, 'nowreply': 7311, 'soundtrack': 7312, 'stdtxtrate': 7313, 'homelove': 7314, 'staffsciencenusedusgphyhcmkteachingpc1323': 7315, 'emigrated': 7316, 'hopeful': 7317, 'olol': 7318, 'stagwood': 7319, 'winterstone': 7320, 'victors': 7321, 'jp': 7322, 'mofo': 7323, 'pathaya': 7324, 'enketa': 7325, 'maraikara': 7326, 'priest': 7327, 'reserves': 7328, 'intrude': 7329, 'walkabout': 7330, 'cashed': 7331, 'announced': 7332, 'blog': 7333, '28th': 7334, '06': 7335, 'footie': 7336, 'phil': 7337, 'neville': 7338, 'abbey': 7339, 'returning': 7340, 'auctionpunj': 7341, 'str8': 7342, 'classic': 7343, 'nokia150p': 7344, 'poly200p': 7345, 'pre': 7346, 'sacked': 7347, 'clip': 7348, '35p': 7349, 'mmsto': 7350, '32323': 7351, 'barred': 7352, 'lifethis': 7353, 'twat': 7354, 'dungerees': 7355, 'decking': 7356, 'punch': 7357, 'mentionned': 7358, 'vat': 7359, 'onlydon': 7360, 'hogolo': 7361, 'kodstini': 7362, 'madstini': 7363, 'hogli': 7364, 'mutai': 7365, 'eerulli': 7366, 'kodthini': 7367, 'thasa': 7368, 'messed': 7369, 'upyeh': 7370, 'shudvetold': 7371, 'urgran': 7372, 'knowneway': 7373, 'illspeak': 7374, 'u2moro': 7375, 'tex': 7376, 'mecause': 7377, 'werebored': 7378, 'okden': 7379, 'uin': 7380, 'satsound\\x92s': 7381, 'likeyour': 7382, 'gr8fun': 7383, 'updat': 7384, 'countinlots': 7385, 'l': 7386, 'tagged': 7387, 'hdd': 7388, 'casing': 7389, 'opened': 7390, 'describe': 7391, '09053750005': 7392, '310303': 7393, '08718725756': 7394, '140ppm': 7395, 'asus': 7396, 'reformat': 7397, 'leu': 7398, 'plumbers': 7399, 'wrench': 7400, 'httpwwwetlpcoukreward': 7401, 'bcum': 7402, 'appeal': 7403, 'thriller': 7404, 'director': 7405, 'elephant': 7406, 'shove': 7407, 'um': 7408, 'cr': 7409, 'pookie': 7410, 'youdearwith': 7411, 'loverakhesh': 7412, 'nri': 7413, 'x2': 7414, 'deserve': 7415, '88039skilgmetscs087147403231winawkage16£150perwksub': 7416, 'diddy': 7417, 'neighbor': 7418, 'toothpaste': 7419, 'oneta': 7420, 'poking': 7421, 'deam': 7422, 'coccooning': 7423, 'mus': 7424, 'yeahand': 7425, 'newquaysend': 7426, 'goneu': 7427, '1im': 7428, 'talkin': 7429, 'boutxx': 7430, 'windy': 7431, '09066358361': 7432, 'y87': 7433, 'knowthis': 7434, 'tirunelvai': 7435, 'dusk': 7436, 'puzzles': 7437, 'x29': 7438, '09065989180': 7439, 'stairs': 7440, 'phews': 7441, 'thangamits': 7442, 'recycling': 7443, 'earning': 7444, 'toledo': 7445, 'tai': 7446, 'feng': 7447, 'reservations': 7448, 'swimsuit': 7449, 'squeeeeeze': 7450, 'frndshp': 7451, 'luvd': 7452, 'themp': 7453, 'volcanoes': 7454, 'erupt': 7455, 'arise': 7456, 'hurricanes': 7457, 'sway': 7458, 'aroundn': 7459, 'disasters': 7460, 'lighters': 7461, '7pm': 7462, 'kkits': 7463, 'goodwhen': 7464, 'lasagna': 7465, 'chickened': 7466, 'woould': 7467, '08718726978': 7468, 'drove': 7469, 'shore': 7470, '44': 7471, '7732584351': 7472, 'onedge': 7473, 'raviyog': 7474, 'peripherals': 7475, 'bhayandar': 7476, 'sunoco': 7477, 'musical': 7478, 'plate': 7479, 'leftovers': 7480, 'starving': 7481, 'fatty': 7482, 'badrith': 7483, 'chennaii': 7484, 'usno': 7485, 'owe': 7486, 'checkin': 7487, 'numberso': 7488, 'ittb': 7489, 'armenia': 7490, 'swann': 7491, '09058097189': 7492, '330': 7493, '1120': 7494, '1205': 7495, 'justify': 7496, 'hunt': 7497, '5226': 7498, 'hava': 7499, '1131': 7500, 'rct': 7501, 'thnq': 7502, 'adrian': 7503, 'rgds': 7504, 'vatian': 7505, 'everyones': 7506, 'babysitting': 7507, 'itll': 7508, 'gonnamissu': 7509, 'buttheres': 7510, 'aboutas': 7511, 'merememberin': 7512, 'asthere': 7513, 'ofsi': 7514, 'breakin': 7515, 'yaxx': 7516, 'poortiyagi': 7517, 'odalebeku': 7518, 'hanumanji': 7519, '1hanuman': 7520, '2bajarangabali': 7521, '3maruti': 7522, '4pavanaputra': 7523, '5sankatmochan': 7524, '6ramaduth': 7525, '7mahaveer': 7526, 'janarige': 7527, 'ivatte': 7528, 'kalisidare': 7529, 'olage': 7530, 'ondu': 7531, 'keluviri': 7532, 'maretare': 7533, 'inde': 7534, 'dodda': 7535, 'problum': 7536, 'nalli': 7537, 'siguviri': 7538, 'idu': 7539, 'matra': 7540, 'neglet': 7541, 'ijust': 7542, 'talked': 7543, 'opps': 7544, 'tts': 7545, 'gei': 7546, 'tron': 7547, 'dl': 7548, 'selfish': 7549, 'spiffing': 7550, 'workage': 7551, 'craving': 7552, 'supose': 7553, 'babysit': 7554, 'therexx': 7555, 'spaces': 7556, 'embassy': 7557, 'lightly': 7558, 'checkboxes': 7559, 'hundredhe': 7560, 'batsman': 7561, 'yettys': 7562, '09050000928': 7563, 'emailed': 7564, 'yifeng': 7565, 'theyll': 7566, 'slurp': 7567, '3miles': 7568, 'ing': 7569, 'brainless': 7570, 'dolld': 7571, 'vehicle': 7572, 'sariyag': 7573, 'madoke': 7574, 'barolla': 7575, '07090201529': 7576, 'postponed': 7577, 'stocked': 7578, 'tiime': 7579, 'afternon': 7580, 'interviews': 7581, 'resizing': 7582, '09066364349': 7583, 'box434sk38wp150ppm18': 7584, 'opposed': 7585, 'msgwe': 7586, 'shortcode': 7587, '83332please': 7588, '08081263000': 7589, 'refundedthis': 7590, 'somerset': 7591, 'overtime': 7592, 'nigpun': 7593, 'dismissial': 7594, 'screwd': 7595, '08712402972': 7596, 'bull': 7597, 'floating': 7598, '09058095201': 7599, 'heehee': 7600, 'arithmetic': 7601, 'percentages': 7602, 'chillaxin': 7603, 'das': 7604, 'iknow': 7605, 'wellda': 7606, 'peril': 7607, 'studentfinancial': 7608, 'crisisspk': 7609, 'monster': 7610, 'obey': 7611, 'uhhhhrmm': 7612, 'gbpsms': 7613, '600': 7614, '400': 7615, 'deltomorrow': 7616, '09066368470': 7617, '24m': 7618, '1month': 7619, 'smartcall': 7620, '68866': 7621, 'subscriptn3gbpwk': 7622, '08448714184': 7623, 'stoptxt': 7624, 'landlineonly': 7625, '£s': 7626, 'textsweekend': 7627, 'orno': 7628, 'fink': 7629, '09099726553': 7630, 'promised': 7631, 'carlie': 7632, 'calls£1minmobsmore': 7633, 'lkpobox177hp51fl': 7634, 'youphone': 7635, 'athome': 7636, 'youwanna': 7637, 'jack': 7638, 'sayask': 7639, 'helpful': 7640, 'pretend': 7641, 'hypotheticalhuagauahahuagahyuhagga': 7642, 'brainy': 7643, 'occasion': 7644, 'celebrated': 7645, 'reflection': 7646, 'values': 7647, 'affectionsamp': 7648, 'traditions': 7649, 'cantdo': 7650, 'anythingtomorrow': 7651, 'myparents': 7652, 'aretaking': 7653, 'outfor': 7654, 'katexxx': 7655, 'level': 7656, 'gate': 7657, '89105': 7658, 'lingerie': 7659, 'wwwbridalpetticoatdreamscouk': 7660, 'weddingfriend': 7661, 'board': 7662, 'overheating': 7663, 'reslove': 7664, 'inst': 7665, '8o': 7666, 'western': 7667, 'nowadays': 7668, 'notixiquating': 7669, 'laxinorficated': 7670, 'bambling': 7671, 'entropication': 7672, 'oblisingately': 7673, 'opted': 7674, 'masteriastering': 7675, 'amplikater': 7676, 'fidalfication': 7677, 'champlaxigating': 7678, 'atrocious': 7679, 'wotz': 7680, 'junna': 7681, 'knickers': 7682, '01223585236': 7683, 'nikiyu4net': 7684, 'a30': 7685, 'divert': 7686, 'wadebridgei': 7687, 'vill': 7688, 'orc': 7689, 'seeking': 7690, 'dayexcept': 7691, 'wherres': 7692, 'phone750': 7693, 'resolution': 7694, 'replybe': 7695, 'frankgood': 7696, 'logoff': 7697, 'parkin': 7698, 'asa': 7699, '09050000878': 7700, 'prince': 7701, 'charming': 7702, 'mention': 7703, 'served': 7704, 'arnt': 7705, 'xxxxxxxxxxxxxx': 7706, 'dorothykiefercom': 7707, 'alle': 7708, 'moneeppolum': 7709, 'allalo': 7710, 'fundamentals': 7711, 'carewhoever': 7712, '101mega': 7713, 'pixels': 7714, '3optical': 7715, '5digital': 7716, 'dooms': 7717, 'peteynoi\\x92m': 7718, 'timehope': 7719, 'alritehave': 7720, 'js': 7721, 'amx': 7722, 'burgundy': 7723, 'captaining': 7724, 'amrita': 7725, 'profile': 7726, 'bpo': 7727, 'nighters': 7728, 'persevered': 7729, 'regretted': 7730, 'wasn\\x92t': 7731, 'spouse': 7732, 'pmt': 7733, 'sumthin': 7734, '4give': 7735, 'shldxxxx': 7736, 'thatd': 7737, 'scenario': 7738, 'spunout': 7739, 'wrld': 7740, 'nytho': 7741, 'tx': 7742, 'fonin': 7743, '2mwen': 7744, 'frmcloud': 7745, '09071517866': 7746, '150ppmpobox10183bhamb64xe': 7747, '10am': 7748, 'pounded': 7749, 'broadband': 7750, 'installation': 7751, 'tensed': 7752, 'coughing': 7753, 'warned': 7754, 'sprint': 7755, 'gower': 7756, '\\x91morrow': 7757, 'chik': 7758, '100s': 7759, 'filth': 7760, 'saristar': 7761, 'e14': 7762, '9yt': 7763, '08701752560': 7764, '450p': 7765, 'stop2': 7766, '420': 7767, '9061100010': 7768, 'wire3net': 7769, '1st4terms': 7770, 'mobcudb': 7771, 'alreadysabarish': 7772, '09050000460': 7773, 'j89': 7774, 'box245c2150pm': 7775, 'inpersonation': 7776, 'flea': 7777, 'banneduk': 7778, 'highest': 7779, '£54': 7780, 'maximum': 7781, '£71': 7782, 'nys': 7783, 'taj': 7784, 'lesser': 7785, 'known': 7786, 'facts': 7787, 'shahjahans': 7788, 'wifes': 7789, 'shahjahan': 7790, 'arises': 7791, 'hari': 7792, 'okcome': 7793, '69101': 7794, 'wwwrtfsphostingcom': 7795, 'webadres': 7796, 'geting': 7797, 'passport': 7798, 'multiply': 7799, 'independently': 7800, 'showed': 7801, 'twins': 7802, 'strt': 7803, 'ltdhelpdesk': 7804, '02085076972': 7805, 'equally': 7806, 'uneventful': 7807, 'pesky': 7808, 'cyclists': 7809, 'wereare': 7810, 'nalla': 7811, 'adi': 7812, 'entey': 7813, 'nattil': 7814, 'kittum': 7815, 'hire': 7816, 'hitman': 7817, '09066660100': 7818, '2309': 7819, 'cps': 7820, 'outages': 7821, 'conserve': 7822, 'voted': 7823, 'epi': 7824, 'bare': 7825, 'bhaskar': 7826, 'individual': 7827, 'gong': 7828, 'kaypoh': 7829, 'basketball': 7830, 'outdoors': 7831, 'interfued': 7832, 'listed': 7833, 'apology': 7834, 'hustle': 7835, 'forth': 7836, 'harlem': 7837, 'workout': 7838, 'fats': 7839, 'zac': 7840, 'hui': 7841, 'xin': 7842, 'versus': 7843, 'edge': 7844, 'underdtand': 7845, 'itboth': 7846, 'upnot': 7847, 'muchxxlove': 7848, 'locaxx': 7849, '07090298926': 7850, 'ref9307622': 7851, 'skateboarding': 7852, 'thrown': 7853, 'winds': 7854, 'bandages': 7855, 'mytonecomenjoy': 7856, 'html': 7857, 'gbp450week': 7858, 'mfl': 7859, '1146': 7860, '23': 7861, 'hectic': 7862, 'wamma': 7863, 'laidwant': 7864, 'doggin': 7865, 'dogs': 7866, 'nownyt': 7867, 'virtual': 7868, 'apnt': 7869, 'pants': 7870, 'waiti': 7871, 'go2sri': 7872, 'lanka': 7873, 'wordnot': 7874, 'merely': 7875, 'relationshipits': 7876, 'wherevr': 7877, 'gudnyt': 7878, 'plum': 7879, 'smacks': 7880, '50s': 7881, 'alot': 7882, 'formatting': 7883, 'attracts': 7884, 'promotion': 7885, '8714714': 7886, 'lancaster': 7887, 'neway': 7888, 'couldn\\x92t': 7889, 'soc': 7890, 'bsn': 7891, 'advising': 7892, 'lobby': 7893, 'showered': 7894, 'erything': 7895, 'lubly': 7896, 'rs5': 7897, '087147123779am7pm': 7898, 'sbut': 7899, 'luck2': 7900, 'catches': 7901, 'specify': 7902, 'domain': 7903, 'nusstu': 7904, 'ohi': 7905, 'hahatake': 7906, 'bari': 7907, 'hudgi': 7908, 'yorge': 7909, 'pataistha': 7910, 'ertini': 7911, 'hasbroin': 7912, 'jump': 7913, 'hoops': 7914, 'lateso': 7915, 'morningtake': 7916, 'dreamsu': 7917, 'meummifyingbye': 7918, 'associate': 7919, 'rip': 7920, 'uterus': 7921, 'jacuzzi': 7922, 'x49': 7923, 'colourredtextcolourtxtstar': 7924, '2nights': 7925, 'wildest': 7926, 'splwat': 7927, 'whr': 7928, 'aldrine': 7929, 'rakhesh': 7930, 'rtm': 7931, 'herepls': 7932, 'callurgent': 7933, 'sources': 7934, 'unhappiness': 7935, 'necesity': 7936, 'witout': 7937, 'hwd': 7938, 'colleg': 7939, 'watll': 7940, 'wth': 7941, 'functions': 7942, 'events': 7943, 'espell': 7944, 'irritated': 7945, '4wrd': 7946, 'dearloving': 7947, 'wthout': 7948, 'takecare': 7949, 'univ': 7950, 'rajas': 7951, 'burrito': 7952, 'stitch': 7953, 'trouser': 7954, '146tf150p': 7955, 'cheetos': 7956, 'synced': 7957, 'shangela': 7958, 'passes': 7959, '08704439680': 7960, 'againloving': 7961, 'poo': 7962, 'gloucesterroad': 7963, 'uup': 7964, 'ouch': 7965, 'forgiveness': 7966, 'fruit': 7967, 'glo': 7968, '09058095107': 7969, 's3xy': 7970, 'yesmum': 7971, 'wlcome': 7972, 'timi': 7973, 'fishrman': 7974, 'sack': 7975, 'strtd': 7976, 'throwin': 7977, '1stone': 7978, 'moraldont': 7979, '08717895698': 7980, 'mobstorequiz10ppm': 7981, 'physics': 7982, 'arpraveesh': 7983, 'delicious': 7984, 'salad': 7985, 'beers': 7986, 'whore': 7987, 'twinks': 7988, 'scallies': 7989, 'skins': 7990, 'jocks': 7991, '08712466669': 7992, '08712460324nat': 7993, 'flood': 7994, 'beads': 7995, 'wishlist': 7996, 'section': 7997, 'nitro': 7998, 'sold': 7999, 'onionrs': 8000, 'petrolrs': 8001, 'beerrs': 8002, 'armands': 8003, 'creative': 8004, 'fakemy': 8005, 'reffering': 8006, 'uif': 8007, 'getiing': 8008, 'rsi': 8009, 'weirdy': 8010, 'brownies': 8011, '09061701851': 8012, 'k61': 8013, '12hours': 8014, 'restrict': 8015, 'audrey': 8016, 'godnot': 8017, 'chikkuk': 8018, 'vivek': 8019, '74355': 8020, 'outif': 8021, 'greece': 8022, 'recorded': 8023, 'someday': 8024, 'goodmorningmy': 8025, 'grandfather': 8026, 'expiredso': 8027, 'november': 8028, '09061104276': 8029, 'cost£375max': 8030, 'yuou': 8031, 'spot': 8032, 'bunch': 8033, 'lotto': 8034, 'purchases': 8035, 'authorise': 8036, '645pm': 8037, 'honeydid': 8038, 'gimmi': 8039, 'gossx': 8040, 'painit': 8041, 'todaydo': 8042, 'ystrdayice': 8043, 'chile': 8044, 'subletting': 8045, 'febapril': 8046, 'ammaelife': 8047, 'steering': 8048, 'anythings': 8049, 'sleeps': 8050, 'rounderso': 8051, 'required': 8052, 'truekdo': 8053, 'lambu': 8054, 'ji': 8055, 'cometil': 8056, 'batchlor': 8057, 'zoom': 8058, 'nowsend': 8059, '62220cncl': 8060, 'stopcs': 8061, '08717890890£150': 8062, '\\x93harry': 8063, 'ringtonefrom': 8064, 'wmlid1b6a5ecef91ff937819firsttrue180430jul05': 8065, 'xafter': 8066, 'cst': 8067, 'chg': 8068, 'pure': 8069, 'hearted': 8070, 'hisher': 8071, 'enemies': 8072, 'smiley': 8073, 'gail': 8074, 'wrongtake': 8075, 'worryc': 8076, 'hunlove': 8077, 'yaxxx': 8078, 'theoretically': 8079, 'hooked': 8080, 'formallypls': 8081, 'prayingwill': 8082, 'multimedia': 8083, 'senthilhsbc': 8084, 'vague': 8085, 'accounting': 8086, 'delayed': 8087, 'housing': 8088, 'agency': 8089, 'renting': 8090, 'presents': 8091, 'nicky': 8092, 'gumbys': 8093, 'httpalto18coukwavewaveaspo44345': 8094, 'sized': 8095, 'tarpon': 8096, 'springs': 8097, 'cab': 8098, 'availablethey': 8099, 'steps': 8100, 'careumma': 8101, 'limited': 8102, 'call2optouthf8': 8103, '08719181259': 8104, '260305': 8105, 'deartake': 8106, 'radiator': 8107, 'proper': 8108, 'tongued': 8109, 'shorts': 8110, 'qi': 8111, 'suddenly': 8112, 'flurries': 8113, 'freeringtone': 8114, 'real1': 8115, 'pushbutton': 8116, 'dontcha': 8117, 'babygoodbye': 8118, 'golddigger': 8119, 'webeburnin': 8120, 'perform': 8121, 'cards': 8122, 'rebooting': 8123, 'nigh': 8124, 'nooooooo': 8125, 'cable': 8126, 'outage': 8127, 'sos': 8128, 'playin': 8129, 'guoyang': 8130, 'rahul': 8131, 'dengra': 8132, 'antelope': 8133, 'toplay': 8134, 'fieldof': 8135, 'selfindependence': 8136, 'contention': 8137, 'growrandom': 8138, 'gnarls': 8139, 'barkleys': 8140, 'borderline': 8141, '545': 8142, 'nightnight': 8143, 'possibility': 8144, 'grooved': 8145, 'mising': 8146, 'secured': 8147, 'unsecured': 8148, '195': 8149, '6669': 8150, 'lanre': 8151, 'fakeyes': 8152, 'eckankar': 8153, 'ph': 8154, '3000': 8155, 'degrees': 8156, 'dodgey': 8157, 'seing': 8158, 'faceasssssholeeee': 8159, 'ceri': 8160, 'rebel': 8161, 'dreamz': 8162, 'buddy': 8163, 'ringtoneking': 8164, '84484': 8165, 'nationwide': 8166, 'newport': 8167, 'juliana': 8168, 'nachos': 8169, 'dizzamn': 8170, 'suitemates': 8171, 'nimbomsons': 8172, 'continent': 8173, '087104711148': 8174, 'emerging': 8175, 'fiendmake': 8176, 'muchimpede': 8177, 'hesitant': 8178, 'ow': 8179, 'deyi': 8180, '60400thousadi': 8181, 'sumthinxx': 8182, 'nose': 8183, 'essay': 8184, 'tram': 8185, 'vic': 8186, 'coherently': 8187, 'triple': 8188, 'echo': 8189, 'gran': 8190, 'onlyfound': 8191, 'afew': 8192, 'agocusoon': 8193, 'honi': 8194, 'bx526': 8195, 'southern': 8196, 'rayan': 8197, 'macleran': 8198, 'balls': 8199, 'olave': 8200, 'mandara': 8201, 'trishul': 8202, 'woo': 8203, 'hoo': 8204, 'panties': 8205, 'thout': 8206, 'flatter': 8207, 'pints': 8208, 'carlin': 8209, 'ciao': 8210, 'x49your': 8211, 'starve': 8212, 'impression': 8213, 'motivate': 8214, 'darkness': 8215, 'timeyou': 8216, 'wknd': 8217, 'yalrigu': 8218, 'heltiniiyo': 8219, 'meso': 8220, 'uttered': 8221, 'trusting': 8222, 'meok': 8223, 'chikkub': 8224, 'noice': 8225, 'esaplanade': 8226, 'accessible': 8227, '08709501522': 8228, '139': 8229, 'la3': 8230, '2wu': 8231, '£150week': 8232, 'occurs': 8233, 'enna': 8234, 'kalaachutaarama': 8235, 'coco': 8236, 'sporadically': 8237, '09064017305': 8238, 'pobox75ldns7': 8239, 'tbspersolvo': 8240, 'for£38': 8241, 'kath': 8242, 'manchester': 8243, 'you\\x92re': 8244, 'burden': 8245, 'noworriesloanscom': 8246, '08717111821': 8247, 'harder': 8248, 'nbme': 8249, 'sickness': 8250, 'goals': 8251, 'villa': 8252, 'gam': 8253, 'smash': 8254, 'religiously': 8255, 'heroes': 8256, 'tips': 8257, '07973788240': 8258, '08715203649': 8259, 'muhommad': 8260, 'penny': 8261, 'fiting': 8262, 'load': 8263, 'hwkeep': 8264, 'mj': 8265, 'unconvinced': 8266, 'elaborate': 8267, 'willpower': 8268, 'absence': 8269, 'answerin': 8270, '»10': 8271, 'evey': 8272, 'mnth': 8273, 'prin': 8274, '…thanks': 8275, 'gsoh': 8276, 'spam': 8277, 'ladiesu': 8278, 'gigolo': 8279, 'mens': 8280, 'oncall': 8281, 'mjzgroup': 8282, '087143423992stop': 8283, 'msg£150rcvd': 8284, 'ashwini': 8285, '08707500020': 8286, 'tomorrowtoday': 8287, 'ukp2000': 8288, '09061790125': 8289, 'jokethet': 8290, 'skinny': 8291, 'lineyou': 8292, 'casting': 8293, 'elections': 8294, 'shouldn‘t': 8295, '116': 8296, 'hlday': 8297, 'camp': 8298, 'amrca': 8299, 'serena': 8300, 'prescribed': 8301, 'meatballs': 8302, 'approve': 8303, 'panalambut': 8304, 'spjanuary': 8305, 'fortune': 8306, 'allday': 8307, 'perf': 8308, 'outsider': 8309, 'receipts—well': 8310, 'what‘s': 8311, '98321561': 8312, 'familiar': 8313, 'depression': 8314, 'infact': 8315, 'simpsons': 8316, 'band': 8317, 'agreen': 8318, 'bblue': 8319, 'cred': 8320, 'can\\x92t': 8321, 'isn\\x92t': 8322, 'shite': 8323, 'kip': 8324, 'hont': 8325, 'amanda': 8326, 'regard': 8327, 'renewing': 8328, 'upgrading': 8329, '3680': 8330, 'subject': 8331, 'nannys': 8332, 'puts': 8333, 'perspective': 8334, 'sonot': 8335, 'conveying': 8336, 'debating': 8337, 'httpwwwwtlpcouktext': 8338, 'jb': 8339, 'youso': 8340, 'florida': 8341, 'hidden': 8342, 'teams': 8343, 'swhrt': 8344, 'deyhope': 8345, '2daylove': 8346, 'misstake': 8347, '0906346330': 8348, '47': 8349, 'po19': 8350, '2ez': 8351, 'general': 8352, 'ifwhenhow': 8353, 'dayhas': 8354, 'valuemorning': 8355, 'hopeafternoon': 8356, 'faithevening': 8357, 'luvnight': 8358, 'restwish': 8359, 'todaygood': 8360, 'jetton': 8361, 'friendofafriend': 8362, 'cmon': 8363, 'replies': 8364, 'dealer': 8365, 'lunsford': 8366, 'enjoying': 8367, '0796xxxxxx': 8368, 'day2': 8369, 'prizeawaiting': 8370, 'kfc': 8371, 'meals': 8372, 'gravy': 8373, 'dahe': 8374, 'daalways': 8375, 'thisdon': 8376, 'messagepandy': 8377, '07008009200': 8378, 'attended': 8379, 'mw': 8380, 'tuth': 8381, 'mines': 8382, 'eviction': 8383, 'spiral': 8384, 'michael': 8385, 'riddance': 8386, 'suffers': 8387, 'raglan': 8388, 'edward': 8389, 'cricket': 8390, 'closeby': 8391, 'daplease': 8392, 'skye': 8393, 'bookedthe': 8394, 'hut': 8395, 'drastic': 8396, '3750': 8397, 'garments': 8398, 'sez': 8399, 'arab': 8400, 'evry1': 8401, 'eshxxxxxxxxxxx': 8402, 'lay': 8403, 'bimbo': 8404, 'ugos': 8405, '241': 8406, '3lions': 8407, 'portege': 8408, 'm100': 8409, 'semiobscure': 8410, 'gprs': 8411, 'loosu': 8412, 'careless': 8413, 'freaking': 8414, 'myspace': 8415, 'logged': 8416, 'partners': 8417, 'method': 8418, 'jewelry': 8419, 'breaker': 8420, 'deluxe': 8421, 'features': 8422, 'graphics': 8423, '£5': 8424, 'bbdeluxe': 8425, 'fumbling': 8426, 'weekdays': 8427, 'nails': 8428, 'nobodys': 8429, 'asia': 8430, 'stil': 8431, 'tobed': 8432, 'pimples': 8433, 'asthma': 8434, 'attack': 8435, 'ball': 8436, 'spin': 8437, 'haiyoh': 8438, 'million': 8439, 'auntys': 8440, '02': 8441, 'prsn': 8442, 'somtimes': 8443, 'saves': 8444, 'bcozi': 8445, 'audiitions': 8446, 'relocate': 8447, 'pocked': 8448, 'motivating': 8449, 'sharing': 8450, 'brison': 8451, 'spelled': 8452, 'caps': 8453, 'bullshit': 8454, 'gwr': 8455, 'motherfucker': 8456, 'kit': 8457, 'strip': 8458, '1013': 8459, 'ig11': 8460, 'oja': 8461, '08712402578': 8462, 'thesmszonecom': 8463, 'anonymous': 8464, 'masked': 8465, 'messagesim': 8466, 'theredo': 8467, 'abuse': 8468, 'woodland': 8469, 'avenue': 8470, 'parish': 8471, 'magazine': 8472, 'billy': 8473, 'awww': 8474, 'useless': 8475, 'loo': 8476, 'helloed': 8477, 'swollen': 8478, 'glands': 8479, 'bcaz': 8480, 'stu': 8481, '2im': 8482, 'truble': 8483, 'evone': 8484, 'hates': 8485, 'view': 8486, 'gays': 8487, 'dual': 8488, 'hostile': 8489, 'haircut': 8490, 'breezy': 8491, '1appledayno': 8492, '1tulsi': 8493, 'leafdayno': 8494, '1lemondayno': 8495, '1cup': 8496, 'milkdayno': 8497, 'problms': 8498, 'litres': 8499, 'watrdayno': 8500, 'diseases': 8501, 'snd': 8502, 'lavender': 8503, 'manky': 8504, 'scouse': 8505, 'stevelike': 8506, 'travelling': 8507, 'homewot': 8508, 'inmind': 8509, 'recreation': 8510, 'judgementali': 8511, 'fridays': 8512, 'hidid': 8513, 'waheeda': 8514, 'bot': 8515, 'notes': 8516, 'deary': 8517, 'eventually': 8518, 'tolerance': 8519, 'hits': 8520, '0789xxxxxxx': 8521, 'hellogorgeous': 8522, 'nitw': 8523, 'texd': 8524, 'hopeu': 8525, '4ward': 8526, 'cin': 8527, 'jaz': 8528, '09058091870': 8529, 'exorcism': 8530, 'emily': 8531, 'evry': 8532, 'emotion': 8533, 'wordsevry': 8534, 'prayrs': 8535, 'uothrwise': 8536, 'uso': 8537, 'ujhhhhhhh': 8538, 'sandiago': 8539, 'parantella': 8540, 'hugging': 8541, 'sweater': 8542, 'mango': 8543, 'involved': 8544, '£600': 8545, 'landmark': 8546, 'bob': 8547, 'barry': 8548, '83738': 8549, 'consent': 8550, 'forms': 8551, 'tonexs': 8552, 'renewed': 8553, 'wwwclubzedcouk': 8554, 'billing': 8555, 'can‘t': 8556, 'mathews': 8557, 'tait': 8558, 'edwards': 8559, 'anderson': 8560, 'haunt': 8561, 'promoting': 8562, 'crowd': 8563, '8000930705': 8564, 'snowboarding': 8565, 'goa': 8566, 'christmassy': 8567, 'recpt': 8568, '13': 8569, 'baaaaaaaabe': 8570, 'ignoring': 8571, 'shola': 8572, 'sagamu': 8573, 'lautech': 8574, 'vital': 8575, 'completes': 8576, 'education': 8577, 'zealand': 8578, 'qet': 8579, 'browser': 8580, 'surf': 8581, 'subscribers': 8582, 'gb': 8583, 'wellyou': 8584, 'lifeyou': 8585, 'thati': 8586, 'conversations': 8587, 'usget': 8588, 'timeyour': 8589, 'sensesrespect': 8590, 'overemphasiseor': 8591, 'headset': 8592, 'adp': 8593, 'internal': 8594, 'extract': 8595, 'godyou': 8596, 'immed': 8597, 'skint': 8598, 'fancied': 8599, 'bevieswaz': 8600, 'othrs': 8601, 'spoon': 8602, 'watchng': 8603, 'planet': 8604, 'earthsofa': 8605, 'comfey': 8606, 'quitting': 8607, 'least5times': 8608, 'wudnt': 8609, 'ima': 8610, 'frequently': 8611, 'messageit': 8612, 'cupboard': 8613, 'route': 8614, '2mro': 8615, 'floppy': 8616, 'snappy': 8617, 'risk': 8618, 'grasp': 8619, 'flavour': 8620, 'laready': 8621, 'denying': 8622, 'dom': 8623, 'ffffuuuuuuu': 8624, 'julianaland': 8625, 'oblivious': 8626, 'upsetits': 8627, 'dehydrated': 8628, 'mapquest': 8629, 'dogwood': 8630, 'tiny': 8631, 'archive': 8632, 'ukmobiledate': 8633, '08719839835': 8634, 'mgs': 8635, '89123': 8636, 'lengths': 8637, 'behalf': 8638, 'stunning': 8639, 'visa': 8640, 'gucci': 8641, 'shits': 8642, 'babesozi': 8643, 'culdnt': 8644, 'talkbut': 8645, 'wannatell': 8646, 'wenwecan': 8647, 'smsing': 8648, 'efficient': 8649, '515pm': 8650, 'erutupalam': 8651, 'thandiyachu': 8652, 'invention': 8653, 'flyim': 8654, 'noits': 8655, 'lyrics': 8656, 'nevr': 8657, 'unrecognized': 8658, 'somone': 8659, 'valuing': 8660, 'definitly': 8661, 'undrstnd': 8662, 'ger': 8663, 'toking': 8664, 'syd': 8665, 'lehhaha': 8666, 'khelate': 8667, 'kintu': 8668, 'opponenter': 8669, 'dhorte': 8670, 'lage': 8671, 'fried': 8672, 'spares': 8673, 'looovvve': 8674, 'warwick': 8675, 'tmw': 8676, 'canceled': 8677, 'tops': 8678, 'grandma': 8679, 'parade': 8680, 'proze': 8681, 'norcorp': 8682, 'ltd£150mtmsgrcvd18': 8683, 'posting': 8684, 'chennaibecause': 8685, '7cfca1a': 8686, 'grumble': 8687, 'linear': 8688, 'algebra': 8689, 'decorating': 8690, 'wining': 8691, '946': 8692, 'roomate': 8693, 'graduated': 8694, 'adjustable': 8695, 'cooperative': 8696, 'allows': 8697, 'nottingham': 8698, '63miles': 8699, '40mph': 8700, 'thanku': 8701, 'guessed': 8702, 'hubbys': 8703, '89938': 8704, 'strings': 8705, '£150ea': 8706, 'otbox': 8707, '731': 8708, 'la1': 8709, '7ws': 8710, 'itxx': 8711, 'beside': 8712, 'brisk': 8713, 'walks': 8714, 'sexiest': 8715, 'dirtiest': 8716, 'steve': 8717, 'tellmiss': 8718, 'partys': 8719, 'contribute': 8720, 'greatly': 8721, 'urgh': 8722, 'coach': 8723, 'smells': 8724, 'duvet': 8725, 'predictive': 8726, 'chatim': 8727, 'w8in': 8728, '4utxt': 8729, 'url': 8730, '24th': 8731, 'beverage': 8732, 'vpist': 8733, 'surrender': 8734, 'symptoms': 8735, 'rdy': 8736, 'itnow': 8737, 'backwards': 8738, 'abstract': 8739, 'vikkyim': 8740, 'africa': 8741, 'avin': 8742, 'chitchat': 8743, 'logon': 8744, '8883': 8745, '4217': 8746, 'w1a': 8747, '6zf': 8748, '118pmsg': 8749, 'quiteamuzing': 8750, 'that\\x92scool': 8751, 'babeprobpop': 8752, 'cu': 8753, 'satthen': 8754, '4brekkie': 8755, 'psxtra': 8756, 'lrg': 8757, 'portions': 8758, '£1000call': 8759, '09071512432': 8760, '300603tcsbcm4235wc1n3xxcallcost150ppmmobilesvary': 8761, 'rows': 8762, 'engagement': 8763, 'fixd': 8764, 'bthmm': 8765, 'njan': 8766, 'vilikkamt': 8767, 'sudn': 8768, 'maths': 8769, 'chapter': 8770, 'chop': 8771, 'noooooooo': 8772, '09065171142stopsms08718727870150ppm': 8773, 'firsg': 8774, 'split': 8775, 'heat': 8776, 'applyed': 8777, 'sumfing': 8778, 'hopeso': 8779, 'amnow': 8780, 'ithink': 8781, 'tonsolitusaswell': 8782, 'layin': 8783, 'bedreal': 8784, 'lotsof': 8785, 'hiphop': 8786, 'oxygen': 8787, 'resort': 8788, 'roller': 8789, 'recorder': 8790, 'canname': 8791, 'australia': 8792, 'mquiz': 8793, 'showr': 8794, 'upon': 8795, 'ceiling': 8796, 'presnts': 8797, 'bcz': 8798, 'jeevithathile': 8799, 'irulinae': 8800, 'neekunna': 8801, 'prakasamanu': 8802, 'sneham': 8803, 'prakasam': 8804, 'ennal': 8805, 'mns': 8806, 'islove': 8807, 'blowing': 8808, '7634': 8809, '7684': 8810, 'firmware': 8811, 'vijaykanth': 8812, 'tvhe': 8813, 'anythiing': 8814, 'ripped': 8815, 'wwwclubmobycom': 8816, '08717509990': 8817, 'polytruepixringtonesgames': 8818, 'keypad': 8819, 'btwn': 8820, 'decades': 8821, 'goverment': 8822, 'expects': 8823, 'spice': 8824, 'prasanth': 8825, 'ettans': 8826, '08718738002': 8827, '48922': 8828, '211104': 8829, 'appy': 8830, 'fizz': 8831, 'contains': 8832, 'genus': 8833, 'robinson': 8834, 'nottel': 8835, 'outs': 8836, 'soz': 8837, 'imat': 8838, 'freinds': 8839, 'msgsometext': 8840, '07099833605': 8841, 'ref9280114': 8842, 'chloe': 8843, '150ptext': 8844, 'wewa': 8845, '130': 8846, 'iriver': 8847, '255': 8848, '128': 8849, 'bw': 8850, 'dajst': 8851, 'hmmmbut': 8852, 'surly': 8853, '07808726822': 8854, '08718729758': 8855, 'mmmmmmm': 8856, 'snuggles': 8857, 'contented': 8858, 'whispers': 8859, 'healthy': 8860, '2bold': 8861, 'givits': 8862, 'kanoanyway': 8863, 'brother‘s': 8864, 'scraped': 8865, 'barrel': 8866, 'misfits': 8867, 's8': 8868, 'sections': 8869, 'clearer': 8870, 'peach': 8871, 'tasts': 8872, 'rayman': 8873, 'golf': 8874, 'activ8': 8875, 'termsapply': 8876, 'therell': 8877, 'shindig': 8878, 'minstexts': 8879, 'phonebook': 8880, 'keng': 8881, 'rocking': 8882, 'ashes': 8883, 'xins': 8884, 'shijutta': 8885, 'kafter': 8886, 'offense': 8887, 'bbdthts': 8888, 'dvg': 8889, 'coldheard': 8890, 'vinobanagar': 8891, 'conditionand': 8892, 'ovulatewhen': 8893, '3wks': 8894, 'woah': 8895, 'realising': 8896, 'orh': 8897, 'hides': 8898, 'secrets': 8899, 'n8': 8900, 'darlinim': 8901, 'soonxxx': 8902, 'coolmob': 8903, 'frogaxel': 8904, 'akonlonely': 8905, 'eyeddont': 8906, 'cashbincouk': 8907, 'wwwcashbincouk': 8908, 'canteen': 8909, 'stressfull': 8910, 'adds': 8911, 'continued': 8912, 'president': 8913, '140': 8914, 'ardé': 8915, '180': 8916, 'leastwhich': 8917, 'bedrm': 8918, 'pleasured': 8919, 'hitechnical': 8920, 'supportproviding': 8921, 'assistance': 8922, '1172': 8923, 'built': 8924, 'lonlines': 8925, 'lotz': 8926, 'memories': 8927, 'gailxx': 8928, 'hii': 8929, 'complacent': 8930, 'mina': 8931, 'miwa': 8932, 'hsbc': 8933, '09066649731from': 8934, 'mth': 8935, 'opposite': 8936, 'heavily': 8937, 'dolls': 8938, 'patrick': 8939, 'swayze': 8940, '09077818151': 8941, 'calls150ppm': 8942, '30s': 8943, 'wwwsantacallingcom': 8944, 'quarter': 8945, 'nervous': 8946, 'fired': 8947, 'limping': 8948, 'aa': 8949, '0784987': 8950, '08719180219': 8951, '060505': 8952, 'oga': 8953, 'poorly': 8954, 'punishment': 8955, 'brb': 8956, 'kill': 8957, 'predicte': 8958, 'situations': 8959, 'loosing': 8960, 'smaller': 8961, 'capacity': 8962, 'videos': 8963, 'smsshsexnetun': 8964, 'fgkslpopw': 8965, 'fgkslpo': 8966, '0871277810710pmin': 8967, 'defer': 8968, 'admission': 8969, 'checkmate': 8970, 'chess': 8971, 'persian': 8972, 'phrase': 8973, 'shah': 8974, 'maat': 8975, 'rats': 8976, 'themes': 8977, 'pee': 8978, 'photoshop': 8979, 'manageable': 8980, '08715203652': 8981, '42810': 8982, '29100': 8983, 'inshah': 8984, 'ashley': 8985, 'sthis': 8986, 'increase': 8987, 'wifedont': 8988, 'iti': 8989, 'toolets': 8990, 'north': 8991, 'carolina': 8992, 'texas': 8993, 'gre': 8994, 'bomb': 8995, 'breathing': 8996, 'powerful': 8997, 'weapon': 8998, 'nightswt': 8999, 'dreamstake': 9000, 'lovly': 9001, 'messagethanks': 9002, '150pmsgrcvd': 9003, 'customercare': 9004, 'playi': 9005, 'clas': 9006, 'lit': 9007, 'loooooool': 9008, 'couch': 9009, 'rents': 9010, 'swashbuckling': 9011, '5terror': 9012, '6cruel': 9013, '7romantic': 9014, '8lovable': 9015, '9decent': 9016, 'joker': 9017, 'dips': 9018, 'gek1510': 9019, 'lyricalladie21f': 9020, 'yes910': 9021, 'no910': 9022, 'wwwsmsacuhmmross': 9023, 'happiest': 9024, 'characters': 9025, 'differences': 9026, 'lists': 9027, 'tylers': 9028, 'crisis': 9029, 'whenwhere': 9030, 'antibiotic': 9031, 'abdomen': 9032, 'gynae': 9033, '6times': 9034, 'exposed': 9035, 'chastity': 9036, 'device': 9037, 'beatings': 9038, 'uses': 9039, 'gut': 9040, 'wrenching': 9041, 'tallahassee': 9042, 'ou': 9043, 'taka': 9044, 'pobox202': 9045, 'nr31': 9046, '7zs': 9047, '450pw': 9048, 'ritten': 9049, 'fold': 9050, '83118': 9051, 'colin': 9052, 'farrell': 9053, 'swat': 9054, 'popcornjust': 9055, 'msgticketkioskvalid': 9056, '4712': 9057, 'kiosk': 9058, 'mre': 9059, 'solihull': 9060, 'nhs': 9061, 'mistakeu': 9062, 'bornplease': 9063, '2b': 9064, 'terminatedwe': 9065, 'inconvenience': 9066, 'dentists': 9067, 'yards': 9068, 'bergkamp': 9069, 'margin': 9070, '78': 9071, 'parent': 9072, 'itsnot': 9073, 'childs': 9074, 'parentnot': 9075, 'unintentional': 9076, 'nonetheless': 9077, 'hooch': 9078, 'toaday': 9079, 'splat': 9080, 'grazed': 9081, 'confirmdeny': 9082, 'hearin': 9083, 'yah': 9084, 'torture': 9085, 'hopeing': 9086, 'wasn‘t': 9087, 'sisters': 9088, 'sexychat': 9089, 'lips': 9090, 'startedindia': 9091, 'kkcongratulation': 9092, 'court': 9093, 'chapel': 9094, 'frontierville': 9095, 'mountain': 9096, 'deer': 9097, 'maili': 9098, 'mailed': 9099, 'varma': 9100, 'membershiptake': 9101, 'careinsha': 9102, 'secure': 9103, 'parties': 9104, 'farting': 9105, 'ortxt': 9106, 'trained': 9107, 'advisors': 9108, 'dialling': 9109, '402': 9110, 'stuffing': 9111, 'ahhhhjust': 9112, 'uphad': 9113, 'thoso': 9114, 'viveki': 9115, '96': 9116, 'dado': 9117, 'dining': 9118, 'experiencehttpwwwvouch4mecometlpdiningasp': 9119, 'kaila': 9120, '09058094507': 9121, 'unicefs': 9122, 'asian': 9123, 'tsunami': 9124, 'disaster': 9125, 'fund': 9126, '864233': 9127, 'hos': 9128, 'collapsed': 9129, 'cumming': 9130, 'jade': 9131, 'paul': 9132, 'barmed': 9133, 'thinkthis': 9134, 'dangerous': 9135, 'goldviking': 9136, '29m': 9137, 'yes762': 9138, 'no762': 9139, 'wwwsmsacugoldviking': 9140, 'rushing': 9141, 'coulda': 9142, 'phony': 9143, '1230': 9144, 'okday': 9145, 'buz': 9146, 'wedlunch': 9147, 'outsomewhere': 9148, 'adrink': 9149, 'towncud': 9150, '2watershd': 9151, 'fromwrk': 9152, 'bthere': 9153, 'petexxx': 9154, 'hmph': 9155, 'baller': 9156, 'punto': 9157, 'ayo': 9158, 'travelled': 9159, '£125': 9160, 'freeentry': 9161, 'xt': 9162, 'toyota': 9163, 'camry': 9164, 'olayiwolas': 9165, 'mileage': 9166, 'kits': 9167, 'landing': 9168, 'clover': 9169, 'numberpls': 9170, 'idconvey': 9171, 'achanammarakheshqatar': 9172, 'rencontre': 9173, 'mountains': 9174, '08714712412': 9175, 'galsu': 9176, 'nìte': 9177, 'puppy': 9178, 'noise': 9179, '150pmeg': 9180, '08715203685': 9181, 'code4xx26': 9182, '131004': 9183, 'crossing': 9184, 'deepest': 9185, 'darkest': 9186, '09094646631': 9187, 'inconvenient': 9188, 'vldo': 9189, 'adsense': 9190, 'approved': 9191, 'dudette': 9192, 'perumbavoor': 9193, 'stage': 9194, 'clarify': 9195, 'preponed': 9196, 'natalie': 9197, '20f': 9198, 'yes165': 9199, 'no165': 9200, 'wwwsmsacunatalie2k9': 9201, 'younger': 9202, '08701213186': 9203, 'liver': 9204, 'hmmmstill': 9205, 'opener': 9206, 'guides': 9207, 'watched': 9208, 'loneliness': 9209, 'skyving': 9210, 'onwords': 9211, 'mtnl': 9212, 'mumbai': 9213, '83039': 9214, '62735£450': 9215, 'accommodationvouchers': 9216, 'mustprovide': 9217, '15541': 9218, 'rajitha': 9219, 'ranju': 9220, '5p': 9221, 'styles': 9222, 'tscs08714740323': 9223, '1winawk': 9224, '£150perweeksub': 9225, '09066361921': 9226, 'disagreeable': 9227, 'afterwards': 9228, 'battle': 9229, 'vivekanand': 9230, 'uawakefeellikw': 9231, 'shitjustfound': 9232, 'aletter': 9233, 'thatmum': 9234, 'gotmarried': 9235, '4thnovbehind': 9236, 'ourbacks': 9237, 'fuckinniceselfishdeviousbitchanywayi\\x92l': 9238, 'rearrange': 9239, 'dormitory': 9240, 'astronomer': 9241, 'starer': 9242, 'election': 9243, 'recount': 9244, 'motherinlaw': 9245, 'hitler': 9246, 'eleven': 9247, 'worms': 9248, 'suffering': 9249, 'dysentry': 9250, 'andre': 9251, 'virgils': 9252, 'lorgoin': 9253, 'gokila': 9254, 'shanilrakhesh': 9255, 'herethanksi': 9256, 'exchanged': 9257, 'uncut': 9258, 'diamond': 9259, 'stuffleaving': 9260, 'dino': 9261, 'kkthis': 9262, 'kotees': 9263, 'themobhit': 9264, 'panther': 9265, 'sugababes': 9266, 'zebra': 9267, 'badass': 9268, 'hoody': 9269, 'wallpaperall': 9270, 'resent': 9271, 'queries': 9272, 'customersqueriesnetvisionukcom': 9273, 'hassling': 9274, 'andres': 9275, 'haughaighgtujhyguj': 9276, 'fassyole': 9277, 'blacko': 9278, 'londn': 9279, 'responsibilities': 9280, '08715205273': 9281, 'vco': 9282, 'humanities': 9283, 'reassurance': 9284, 'aslamalaikkuminsha': 9285, 'tohar': 9286, 'beeen': 9287, 'muht': 9288, 'albi': 9289, 'mufti': 9290, 'mahfuuzmeaning': 9291, '078': 9292, 'enufcredeit': 9293, 'tocallshall': 9294, 'ileave': 9295, 'treats': 9296, 'okors': 9297, 'ibored': 9298, 'adding': 9299, 'zeros': 9300, 'savings': 9301, 'goigng': 9302, 'perfume': 9303, 'sday': 9304, 'joinedso': 9305, 'grocers': 9306, 'pubs': 9307, 'frankie': 9308, 'bennys': 9309, 'changing': 9310, 'diapers': 9311, 'owed': 9312, 'unlike': 9313, 'patients': 9314, 'turkeys': 9315, 'helens': 9316, 'princes': 9317, 'dawhere': 9318, 'unintentionally': 9319, 'wenever': 9320, 'familymay': 9321, 'stability': 9322, 'tranquility': 9323, 'vibrant': 9324, 'colourful': 9325, 'bawling': 9326, 'failure': 9327, 'failing': 9328, 'velusamy': 9329, 'sirs': 9330, 'facilities': 9331, 'karnan': 9332, 'bluray': 9333, 'i‘ve': 9334, 'salt': 9335, 'wounds': 9336, 'logging': 9337, 'geoenvironmental': 9338, 'implications': 9339, 'gently': 9340, 'fuuuuck': 9341, 'salmon': 9342, 'uploaded': 9343, 'wrkin': 9344, 'ree': 9345, 'compensation': 9346, 'awkward': 9347, 'splash': 9348, 'leg': 9349, 'musta': 9350, 'overdid': 9351, 'wwwtelediscountcouk': 9352, 'hiwhat': 9353, 'foned': 9354, 'chuck': 9355, 'nightswe': 9356, 'port': 9357, 'liaotoo': 9358, 'stuffs': 9359, 'juswoke': 9360, 'boatin': 9361, 'docks': 9362, 'spinout': 9363, 'remet': 9364, '08715203656': 9365, '42049': 9366, '261004': 9367, 'uworld': 9368, 'qbank': 9369, 'assessment': 9370, 'someonone': 9371, '09064015307': 9372, 'tke': 9373, 'temales': 9374, 'vidnot': 9375, 'finishd': 9376, 'dull': 9377, 'studies': 9378, 'anyones': 9379, 'treadmill': 9380, 'craigslist': 9381, 'absolutely': 9382, 'drmstake': 9383, 'swan': 9384, 'moyep': 9385, 'sall': 9386, 'hehe': 9387, 'shexy': 9388, 'teethif': 9389, 'asapok': 9390, 'hellohow': 9391, 'doingwhat': 9392, '2when': 9393, 'lamp': 9394, 'latebut': 9395, 'kwish': 9396, 'foward': 9397, '09061790126': 9398, 'misundrstud': 9399, '2u2': 9400, 'genes': 9401, 'wwwldewcom1win150ppmx3age16subscription': 9402, 'resuming': 9403, 'reapply': 9404, 'treatin': 9405, 'treacle': 9406, 'mumhas': 9407, 'beendropping': 9408, 'theplace': 9409, 'adress': 9410, 'moneyi': 9411, 'oyster': 9412, 'sashimi': 9413, 'rumbling': 9414, 'marandratha': 9415, 'topic': 9416, 'correctly': 9417, 'sirsalam': 9418, 'alaikkumpride': 9419, 'shopwe': 9420, 'qatarrakhesh': 9421, 'indianpls': 9422, 'numberrespectful': 9423, 'galcan': 9424, 'boyy': 9425, 'galno': 9426, 'heaven': 9427, 'princegn': 9428, 'pisces': 9429, 'aquarius': 9430, '2yrs': 9431, 'steyn': 9432, 'wicket': 9433, 'sterm': 9434, 'resolved': 9435, 'jam': 9436, 'hannaford': 9437, 'wheat': 9438, 'chex': 9439, 'pride': 9440, 'grownup': 9441, 'stuffwhy': 9442, 'costume': 9443, 'jerk': 9444, 'stink': 9445, 'textcomp': 9446, 'follows': 9447, 'subsequent': 9448, 'charged150pmsg2': 9449, '84128custcare': 9450, 'openings': 9451, 'upcharge': 9452, '8hr': 9453, 'guai': 9454, 'astrology': 9455, 'ryans': 9456, 'program': 9457, 'slacking': 9458, 'officestill': 9459, 'formsdon': 9460, 'mentor': 9461, 'percent': 9462, '09095350301': 9463, 'erotic': 9464, 'ecstacy': 9465, 'dept': 9466, '13404': 9467, '08717507382': 9468, 'datingi': 9469, 'coincidence': 9470, 'sane': 9471, 'helping': 9472, 'leading': 9473, '151': 9474, 'pause': 9475, 'gr8prizes': 9476, '8800': 9477, 'psp': 9478, 'wktxt': 9479, 'httpwwwgr8prizescom': 9480, 'spacebucks': 9481, 'weathers': 9482, '02070836089': 9483, 'squeezed': 9484, 'meremove': 9485, 'maintaining': 9486, '5i\\x92m': 9487, 'dreading': 9488, 'thou': 9489, 'suggestion': 9490, 'lands': 9491, 'helps': 9492, 'forgt': 9493, 'ajith': 9494, 'ooooooh': 9495, 'yoville': 9496, 'asda': 9497, 'counts': 9498, 'officer': 9499, 'respectful': 9500, 'bffs': 9501, 'carly': 9502, 'someonethat': 9503, 'seperated鈥┾〨ud': 9504, 'brolly': 9505, 'franxx': 9506, 'welli': 9507, 'prometazine': 9508, 'syrup': 9509, '5mls': 9510, 'feed': 9511, 'singapore': 9512, 'victoria': 9513, 'pocay': 9514, 'wocay': 9515, '2morrowxxxx': 9516, 'broth': 9517, 'ramen': 9518, 'fowler': 9519, 'ksry': 9520, 'sivatats': 9521, 'flew': 9522, '09058094583': 9523, '1526': 9524, 'pubcafe': 9525, 'attention': 9526, 'tix': 9527, 'biolas': 9528, 'fne': 9529, 'youdoing': 9530, 'worc': 9531, 'foregate': 9532, 'shrub': 9533, 'get4an18th': 9534, '32000': 9535, 'legitimat': 9536, 'efreefone': 9537, 'shopthe': 9538, 'receipts': 9539, 'pendent': 9540, 'toilet': 9541, 'stolen': 9542, 'cops': 9543, 'hu': 9544, 'navigate': 9545, 'choosing': 9546, 'require': 9547, 'guidance': 9548, 'chick': 9549, 'boobs': 9550, 'revealing': 9551, 'sparkling': 9552, 'breaks': 9553, '45': 9554, '0121': 9555, '2025050': 9556, 'wwwshortbreaksorguk': 9557, 'gyno': 9558, 'belong': 9559, 'wwwgambtv': 9560, 'treasure': 9561, 'wmlid820554ad0a1705572711firsttrue¡c': 9562, 'ringtone¡': 9563, '09050000332': 9564, 'mummys': 9565, 'positive': 9566, 'negative': 9567, 'hmmmm': 9568, 'dhoni': 9569, 'titleso': 9570, 'command': 9571, 'stressful': 9572, 'holby': 9573, '09064017295': 9574, 'li': 9575, 'lecturer': 9576, 'repeating': 9577, 'yeovil': 9578, 'motor': 9579, 'max': 9580, 'rhode': 9581, 'bong': 9582, 'ofcourse': 9583, '08448350055': 9584, 'planettalkinstantcom': 9585, 'loti': 9586, 'marvel': 9587, 'ultimate': 9588, 'spiderman': 9589, 'spider': 9590, '83338': 9591, '8ball': 9592, 'tamilnaduthen': 9593, 'tip': 9594, '07808247860': 9595, '08719899229': 9596, '40411': 9597, '061104': 9598, 'apo': 9599, 'identification': 9600, 'limit': 9601, 'boundaries': 9602, 'endless': 9603, 'reassuring': 9604, 'lorwe': 9605, 'young': 9606, 'referin': 9607, 'meis': 9608, 'liaoso': 9609, 'saibaba': 9610, 'colany': 9611, 'chic': 9612, 'declare': 9613, '49557': 9614, '261104': 9615, 'disappointment': 9616, 'irritation': 9617, 'tantrums': 9618, 'compliments': 9619, 'adventuring': 9620, 'chief': 9621, 'gsex': 9622, '2667': 9623, 'wc1n': 9624, '3xx': 9625, '3mobile': 9626, 'chatlines': 9627, 'inclu': 9628, 'servs': 9629, 'l8er': 9630, 'bailiff': 9631, 'mouse': 9632, 'desk': 9633, 'childporn': 9634, 'jumpers': 9635, 'hat': 9636, 'belt': 9637, 'cribbs': 9638, 'spiritual': 9639, 'barring': 9640, 'sudden': 9641, 'influx': 9642, 'kane': 9643, 'shud': 9644, 'pshewmissing': 9645, 'units': 9646, 'accent': 9647, '4years': 9648, 'dental': 9649, 'nmde': 9650, 'dump': 9651, 'heap': 9652, 'lowes': 9653, 'salesman': 9654, '£750': 9655, '087187272008': 9656, 'now1': 9657, 'pity': 9658, 'soany': 9659, 'suggestions': 9660, 'bitching': 9661}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWf_12uAPTHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466141d5-5f70-49fa-d554-71336d53681c"
      },
      "source": [
        "# Encode review in to list of Integer by using above dictionary\n",
        "\n",
        "encoded_msgs = list()\n",
        "for sms in all_sms:\n",
        "  encoded_msg = list()\n",
        "  for word in sms.split():\n",
        "    if word not in vocab_to_int.keys():\n",
        "      #if word is not available in vocab_to_int put 0 in that place\n",
        "      encoded_msg.append(0)\n",
        "    else:\n",
        "      encoded_msg.append(vocab_to_int[word])\n",
        "  encoded_msgs.append(encoded_msg)\n",
        "\n",
        "print(encoded_msgs[:3])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[46, 441, 4393, 796, 713, 679, 64, 9, 1251, 90, 121, 355, 1252, 153, 2908, 1253, 68, 57, 4394, 137], [47, 311, 1406, 442, 6, 1842], [50, 460, 9, 21, 4, 751, 904, 1, 179, 1843, 1043, 622, 1844, 2229, 256, 2230, 71, 1843, 1, 1845, 1, 312, 460, 2909, 80, 2910, 380, 2911]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsQjoQVvQEfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5464eaae-e2f5-493c-fdac-7f2e66a34d1c"
      },
      "source": [
        "# fix length and pad with 0s\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "sequence_length = 35\n",
        "features = np.zeros((len(encoded_msgs), sequence_length), dtype=int)\n",
        "all_lens = []\n",
        "for i, sms in enumerate(encoded_msgs):\n",
        "  sms_len = len(sms)\n",
        "  all_lens.append(sms_len)\n",
        "  if (sms_len <= sequence_length):\n",
        "    if (sequence_length - sms_len) < 0:\n",
        "      raise ValueError\n",
        "    zeros = list(np.zeros(sequence_length - sms_len))\n",
        "    new = zeros + sms\n",
        "  else:\n",
        "    new = sms[:sequence_length]\n",
        "  features[i,:] = np.array(new)\n",
        "\n",
        "print(features[10]) # padded to 171 words with 0s from left"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   23  222   33   81  214    7    2   44   69    1  266   79   40  280\n",
            " 1142  209  181  173 4398  415   92]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrwRD2_oR_R-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a80460-4bd8-48d6-b151-1fa85c8ec469"
      },
      "source": [
        "# split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
        "\n",
        "train_x = features[:int(0.8*len(features))]\n",
        "train_y = labels[:int(0.8*len(features))]\n",
        "valid_x = features[int(0.8*len(features)):int(0.9*len(features))]\n",
        "valid_y = labels[int(0.8*len(features)):int(0.9*len(features))]\n",
        "test_x = features[int(0.9*len(features)):]\n",
        "test_y = labels[int(0.9*len(features)):]\n",
        "\n",
        "print(\"Train data:\", len(train_y), \"Validation data:\", len(valid_y), \"Test data:\", len(test_y))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data: 4459 Validation data: 557 Test data: 558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-zxvXzFTRo3",
        "outputId": "cb78e7f6-1474-40c4-9678-2c8f2c76a8a3"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#create Tensor Dataset\n",
        "# antes estaba todo con torch.FloatTensor()\n",
        "train_data = TensorDataset(torch.tensor(train_x, dtype=torch.int), torch.tensor(train_y, dtype=torch.int))\n",
        "valid_data = TensorDataset(torch.tensor(valid_x, dtype=torch.int), torch.tensor(valid_y, dtype=torch.int))\n",
        "test_data = TensorDataset(torch.tensor(test_x, dtype=torch.int), torch.tensor(test_y, dtype=torch.int))\n",
        "\n",
        "#dataloader\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([4, 35])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,  428,    3,  681, 5473,   74,  291,   59,\n",
            "          900,   39, 1212, 5474,   91,   88,    1, 5475,  221,  630, 5476],\n",
            "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0, 5808, 5809,   12, 5810, 5811],\n",
            "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           38, 1689,    1,   32, 1152, 1944,    7,   34,   46,   87,  146],\n",
            "        [1301,    3,  726,   32,    1, 4847,  333,   19,  924,  146,    2,   17,\n",
            "          424,    3,  890,   13, 4848,  385,  200,  297,    3,  313,   10,   12,\n",
            "            4,  458,  198,    2,  383,   26,  184, 1301,    5,  203,   15]],\n",
            "       dtype=torch.int32)\n",
            "Sample label size:  torch.Size([4])\n",
            "Sample label: \n",
            " tensor([1, 0, 0, 0], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOR3sqIJUmHY"
      },
      "source": [
        "import torch.nn as nn\n",
        " \n",
        "class SentimentalLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.output_size=output_size\n",
        "        self.n_layers=n_layers\n",
        "        self.hidden_dim=hidden_dim\n",
        "        \n",
        "        #Embedding and LSTM layers\n",
        "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        #dropout layer\n",
        "        self.dropout=nn.Dropout(0.3)\n",
        "        \n",
        "        #Linear and sigmoid layer\n",
        "        self.fc1=nn.Linear(hidden_dim, 64)\n",
        "        self.fc2=nn.Linear(64, 16)\n",
        "        self.fc3=nn.Linear(16,output_size)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size=x.size()\n",
        "        \n",
        "        #Embadding and LSTM output\n",
        "        embedd=self.embedding(x)\n",
        "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
        "        \n",
        "        #stack up the lstm output\n",
        "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        #dropout and fully connected layers\n",
        "        out=self.dropout(lstm_out)\n",
        "        out=self.fc1(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc2(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc3(out)\n",
        "        sig_out=self.sigmoid(out)\n",
        "        \n",
        "        sig_out=sig_out.view(batch_size, -1)\n",
        "        sig_out=sig_out[:, -1]\n",
        "        \n",
        "        return sig_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"Initialize Hidden STATE\"\"\"\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMCoc8IHVhBg",
        "outputId": "5de7e99c-3ef9-4694-d746-0f11fc0c3291"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 100\n",
        "hidden_dim = 80\n",
        "n_layers = 1\n",
        "dropout = 0\n",
        "\n",
        "net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=dropout)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentalLSTM(\n",
            "  (embedding): Embedding(9662, 100)\n",
            "  (lstm): LSTM(100, 80, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=80, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MWiqgc8VtOH",
        "outputId": "5962f62b-8177-44eb-fdaf-c489514336c3"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "# check if CUDA is available\n",
        "# train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip = 5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "#if (train_on_gpu):\n",
        "net.to(device)\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        #print(inputs) # parecieran estar todos en 0?\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)  \n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.105927... Val Loss: 0.236621\n",
            "Epoch: 1/4... Step: 200... Loss: 0.049968... Val Loss: 0.223414\n",
            "Epoch: 1/4... Step: 300... Loss: 0.087935... Val Loss: 0.195832\n",
            "Epoch: 1/4... Step: 400... Loss: 0.008274... Val Loss: 0.159777\n",
            "Epoch: 1/4... Step: 500... Loss: 0.064948... Val Loss: 0.137865\n",
            "Epoch: 1/4... Step: 600... Loss: 0.144568... Val Loss: 0.117165\n",
            "Epoch: 1/4... Step: 700... Loss: 0.018751... Val Loss: 0.116349\n",
            "Epoch: 1/4... Step: 800... Loss: 0.019414... Val Loss: 0.136215\n",
            "Epoch: 1/4... Step: 900... Loss: 0.026344... Val Loss: 0.116002\n",
            "Epoch: 1/4... Step: 1000... Loss: 0.229046... Val Loss: 0.109625\n",
            "Epoch: 1/4... Step: 1100... Loss: 0.008675... Val Loss: 0.100539\n",
            "Epoch: 2/4... Step: 1200... Loss: 0.041344... Val Loss: 0.105088\n",
            "Epoch: 2/4... Step: 1300... Loss: 0.016091... Val Loss: 0.104330\n",
            "Epoch: 2/4... Step: 1400... Loss: 0.005142... Val Loss: 0.106314\n",
            "Epoch: 2/4... Step: 1500... Loss: 0.001370... Val Loss: 0.115582\n",
            "Epoch: 2/4... Step: 1600... Loss: 0.004258... Val Loss: 0.111469\n",
            "Epoch: 2/4... Step: 1700... Loss: 0.001389... Val Loss: 0.121364\n",
            "Epoch: 2/4... Step: 1800... Loss: 0.007879... Val Loss: 0.109602\n",
            "Epoch: 2/4... Step: 1900... Loss: 0.000385... Val Loss: 0.097817\n",
            "Epoch: 2/4... Step: 2000... Loss: 0.000176... Val Loss: 0.120921\n",
            "Epoch: 2/4... Step: 2100... Loss: 0.023867... Val Loss: 0.123950\n",
            "Epoch: 2/4... Step: 2200... Loss: 0.004277... Val Loss: 0.099938\n",
            "Epoch: 3/4... Step: 2300... Loss: 0.008408... Val Loss: 0.118028\n",
            "Epoch: 3/4... Step: 2400... Loss: 0.005476... Val Loss: 0.136428\n",
            "Epoch: 3/4... Step: 2500... Loss: 0.000739... Val Loss: 0.145692\n",
            "Epoch: 3/4... Step: 2600... Loss: 0.000030... Val Loss: 0.144864\n",
            "Epoch: 3/4... Step: 2700... Loss: 0.000015... Val Loss: 0.155867\n",
            "Epoch: 3/4... Step: 2800... Loss: 0.000328... Val Loss: 0.179234\n",
            "Epoch: 3/4... Step: 2900... Loss: 0.000000... Val Loss: 0.193874\n",
            "Epoch: 3/4... Step: 3000... Loss: 0.000020... Val Loss: 0.132864\n",
            "Epoch: 3/4... Step: 3100... Loss: 0.000014... Val Loss: 0.148481\n",
            "Epoch: 3/4... Step: 3200... Loss: 0.015988... Val Loss: 0.125806\n",
            "Epoch: 3/4... Step: 3300... Loss: 0.000532... Val Loss: 0.150683\n",
            "Epoch: 4/4... Step: 3400... Loss: 0.000001... Val Loss: 0.154599\n",
            "Epoch: 4/4... Step: 3500... Loss: 0.000004... Val Loss: 0.171552\n",
            "Epoch: 4/4... Step: 3600... Loss: 0.000012... Val Loss: 0.169445\n",
            "Epoch: 4/4... Step: 3700... Loss: 0.000173... Val Loss: 0.166615\n",
            "Epoch: 4/4... Step: 3800... Loss: 0.000040... Val Loss: 0.159785\n",
            "Epoch: 4/4... Step: 3900... Loss: 0.000000... Val Loss: 0.204730\n",
            "Epoch: 4/4... Step: 4000... Loss: 0.000002... Val Loss: 0.182226\n",
            "Epoch: 4/4... Step: 4100... Loss: 0.000260... Val Loss: 0.187934\n",
            "Epoch: 4/4... Step: 4200... Loss: 0.000013... Val Loss: 0.198183\n",
            "Epoch: 4/4... Step: 4300... Loss: 0.000771... Val Loss: 0.209343\n",
            "Epoch: 4/4... Step: 4400... Loss: 0.000001... Val Loss: 0.173117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xwUYMbsYdE"
      },
      "source": [
        "#NUEVO INTENTO 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLP7v9Mru79G"
      },
      "source": [
        "# data.py\n",
        "\n",
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "        return ids"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sea7NJIlxHif"
      },
      "source": [
        "# model.py\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        # Optionally tie weights as in:\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        # and\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
        "        # https://arxiv.org/abs/1611.01462\n",
        "        if tie_weights:\n",
        "            if nhid != ninp:\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1, self.ntoken)\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)\n",
        "\n",
        "# Temporarily leave PositionalEncoding module here. Will be moved somewhere else.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, has_mask=True):\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return F.log_softmax(output, dim=-1)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6ThVL7xTRd"
      },
      "source": [
        "# main.py\n",
        "import argparse\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "#import data\n",
        "#import model\n",
        "\n",
        "import sys\n",
        "sys.argv=[\"\", \"--cuda\", \"--epochs\", \"5\", \"--model\", \"RNN_RELU\", \"--data\", wikitext_data_path, \"--lr\", \"0.5\"]\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 RNN/LSTM/GRU/Transformer Language Model')\n",
        "parser.add_argument('--data', type=str, default='./data/wikitext-2',\n",
        "                    help='location of the data corpus')\n",
        "parser.add_argument('--model', type=str, default='LSTM',\n",
        "                    help='type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU, Transformer)')\n",
        "parser.add_argument('--emsize', type=int, default=200,\n",
        "                    help='size of word embeddings')\n",
        "parser.add_argument('--nhid', type=int, default=200,\n",
        "                    help='number of hidden units per layer')\n",
        "parser.add_argument('--nlayers', type=int, default=2,\n",
        "                    help='number of layers')\n",
        "parser.add_argument('--lr', type=float, default=20,\n",
        "                    help='initial learning rate')\n",
        "parser.add_argument('--clip', type=float, default=0.25,\n",
        "                    help='gradient clipping')\n",
        "parser.add_argument('--epochs', type=int, default=40,\n",
        "                    help='upper epoch limit')\n",
        "parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
        "                    help='batch size')\n",
        "parser.add_argument('--bptt', type=int, default=35,\n",
        "                    help='sequence length')\n",
        "parser.add_argument('--dropout', type=float, default=0.2,\n",
        "                    help='dropout applied to layers (0 = no dropout)')\n",
        "parser.add_argument('--tied', action='store_true',\n",
        "                    help='tie the word embedding and softmax weights')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--cuda', action='store_true',\n",
        "                    help='use CUDA')\n",
        "parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
        "                    help='report interval')\n",
        "parser.add_argument('--save', type=str, default='model.pt',\n",
        "                    help='path to save the final model')\n",
        "parser.add_argument('--onnx-export', type=str, default='',\n",
        "                    help='path to export the final model in onnx format')\n",
        "\n",
        "parser.add_argument('--nhead', type=int, default=2,\n",
        "                    help='the number of heads in the encoder/decoder of the transformer model')\n",
        "parser.add_argument('--dry-run', action='store_true',\n",
        "                    help='verify the code and the model')\n",
        "\n",
        "args = parser.parse_args()\n",
        "print(\"Running with args:\", args)\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "corpus = Corpus(args.data)\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, args.batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)\n",
        "\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "if args.model == 'Transformer':\n",
        "    model = TransformerModel(ntokens, args.emsize, args.nhead, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "else:\n",
        "    model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    print(\"Data-target:\", data, target)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if args.model == 'Transformer':\n",
        "                output = model(data)\n",
        "                output = output.view(-1, ntokens)\n",
        "            else:\n",
        "                output, hidden = model(data, hidden)\n",
        "                hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(args.batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        model.zero_grad()\n",
        "        if args.model == 'Transformer':\n",
        "            output = model(data)\n",
        "            output = output.view(-1, ntokens)\n",
        "        else:\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output, hidden = model(data, hidden)\n",
        "        #print(\"Output:\", output.shape)\n",
        "        #print(\"Targets:\", targets.shape)\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "        for p in model.parameters():\n",
        "            p.data.add_(p.grad, alpha=-lr)\n",
        "\n",
        "        value = loss.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % args.log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / args.log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {} | ppl {}'.format(\n",
        "                epoch, batch, len(train_data) // args.bptt, lr,\n",
        "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        if args.dry_run:\n",
        "            break\n",
        "\n",
        "\n",
        "def export_onnx(path, batch_size, seq_len):\n",
        "    print('The model is also exported in ONNX format at {}'.\n",
        "          format(os.path.realpath(args.onnx_export)))\n",
        "    model.eval()\n",
        "    dummy_input = torch.LongTensor(seq_len * batch_size).zero_().view(-1, batch_size).to(device)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    torch.onnx.export(model, (dummy_input, hidden), path)\n",
        "\n",
        "\n",
        "# Loop over epochs.\n",
        "lr = args.lr\n",
        "best_val_loss = None\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "    # after load the rnn params are not a continuous chunk of memory\n",
        "    # this makes them a continuous chunk, and will speed up forward pass\n",
        "    # Currently, only rnn model supports flatten_parameters function.\n",
        "    if args.model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
        "        model.rnn.flatten_parameters()\n",
        "\n",
        "# Run on test data.\n",
        "test_loss = evaluate(test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)\n",
        "\n",
        "if len(args.onnx_export) > 0:\n",
        "    # Export the model in ONNX format.\n",
        "    export_onnx(args.onnx_export, batch_size=1, seq_len=args.bptt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv6FbmnfIZti"
      },
      "source": [
        "#NUEVO INTENTO 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-ZdjbzuIY-i"
      },
      "source": [
        "#deal with tensors\n",
        "import torch   \n",
        "\n",
        "#handling text data\n",
        "from torchtext.legacy import data\n",
        "\n",
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufaf_fNBIn1C"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
        "\n",
        "fields = [(None, None), ('text',TEXT),('label', LABEL)]\n",
        "\n",
        "#loading custom dataset\n",
        "print(quora_data_path)\n",
        "training_data = data.TabularDataset(path = \"/content/drive/MyDrive/DL/T2/quora - Copy.csv\" ,format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X47Pow-lRBp0",
        "outputId": "f0259c74-d1ea-422e-da9f-235cd3ca0379"
      },
      "source": [
        "\n",
        "#print preprocessed text\n",
        "print(vars(training_data.examples[0]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Why', 'are', 'most', 'indian', 'parents', 'against', 'even', 'liking', 'someone', '?'], 'label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL4znI0KRR0k"
      },
      "source": [
        "import random\n",
        "train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si23136ERoQk",
        "outputId": "cd923b97-30c8-4bb8-ff56-33a5bbcc5d6e"
      },
      "source": [
        "#initialize glove embeddings\n",
        "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))  \n",
        "\n",
        "#Word dictionary\n",
        "print(TEXT.vocab.stoi)   "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            " 99%|█████████▉| 397765/400000 [00:13<00:00, 28519.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT vocabulary: 1948\n",
            "Size of LABEL vocabulary: 2\n",
            "[('?', 3023), ('the', 1614), ('to', 1061), ('a', 968), ('of', 776), ('in', 771), (',', 741), ('is', 709), ('and', 679), ('Why', 676)]\n",
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fa581bd5150>>, {'<unk>': 0, '<pad>': 1, '?': 2, 'the': 3, 'to': 4, 'a': 5, 'of': 6, 'in': 7, ',': 8, 'is': 9, 'and': 10, 'Why': 11, 'do': 12, 'What': 13, 'are': 14, 'I': 15, 'for': 16, 'How': 17, 'that': 18, 'you': 19, 'it': 20, 'people': 21, '.': 22, 'Is': 23, 'with': 24, 'be': 25, 'they': 26, 'have': 27, 'can': 28, 'on': 29, 'as': 30, 'or': 31, '\"': 32, '-': 33, \"n't\": 34, 'not': 35, 'their': 36, 'my': 37, 'from': 38, 'so': 39, \"'s\": 40, 'when': 41, 'like': 42, 'does': 43, 'Do': 44, 'get': 45, ')': 46, 'an': 47, 'about': 48, 'your': 49, '(': 50, 'if': 51, 'by': 52, 'Trump': 53, 'Are': 54, 'did': 55, 'there': 56, 'women': 57, 'who': 58, 'more': 59, 'at': 60, 'some': 61, 'If': 62, 'Can': 63, 'India': 64, 'we': 65, 'why': 66, 'what': 67, 'would': 68, 'all': 69, 'best': 70, 'but': 71, 'than': 72, 'this': 73, 'has': 74, 'most': 75, 'them': 76, 'will': 77, 'should': 78, 'being': 79, 'think': 80, 'me': 81, 'Quora': 82, 'other': 83, 'was': 84, 'men': 85, 'any': 86, 'good': 87, 'white': 88, '/': 89, 'Which': 90, 'many': 91, 'Indian': 92, 'one': 93, 'Muslims': 94, 'after': 95, 'he': 96, 'make': 97, 'up': 98, \"'\": 99, 'just': 100, 'Does': 101, 'Americans': 102, 'because': 103, 'want': 104, 'Should': 105, 'against': 106, 'how': 107, 'out': 108, 'much': 109, 'sex': 110, 'his': 111, 'were': 112, 'black': 113, 'hate': 114, 'world': 115, 'know': 116, 'time': 117, 'American': 118, 'Indians': 119, 'US': 120, 'into': 121, 'only': 122, 'which': 123, 'Will': 124, 'country': 125, 'ever': 126, 'her': 127, 'Chinese': 128, 'girls': 129, 'see': 130, 'way': 131, 'When': 132, 'ca': 133, 'use': 134, 'feel': 135, 'become': 136, 'say': 137, 'still': 138, 'liberals': 139, 'over': 140, 'then': 141, 'no': 142, '’s': 143, 'work': 144, 'am': 145, 'man': 146, 'been': 147, 'better': 148, 'Who': 149, 'take': 150, 'Did': 151, 'countries': 152, 'even': 153, 'government': 154, 'need': 155, 'n’t': 156, 'really': 157, 'same': 158, 'true': 159, 'without': 160, 'years': 161, 'between': 162, 'girl': 163, 'life': 164, 'our': 165, 'she': 166, 'such': 167, 'God': 168, 'find': 169, 'questions': 170, 'while': 171, 'Would': 172, 'possible': 173, 'start': 174, 'stop': 175, 'Where': 176, 'right': 177, 'America': 178, 'China': 179, 'before': 180, 'going': 181, 'him': 182, 'old': 183, 'person': 184, 'school': 185, 'someone': 186, 'things': 187, 'woman': 188, '2': 189, 'Islam': 190, 'go': 191, 'had': 192, 'having': 193, 'where': 194, 'Muslim': 195, 'different': 196, 'during': 197, 'gay': 198, 'own': 199, \"'m\": 200, 'Obama': 201, 'always': 202, 'believe': 203, 'children': 204, 'could': 205, 'free': 206, 'give': 207, 'money': 208, 'Christians': 209, 'Jews': 210, 'President': 211, 'USA': 212, 'getting': 213, 'racist': 214, 'year': 215, 'Hindus': 216, 'The': 217, 'its': 218, 'mean': 219, 'real': 220, 'themselves': 221, '1': 222, 'bad': 223, 'learn': 224, 'British': 225, 'Donald': 226, 'In': 227, 'Pakistan': 228, 'UK': 229, 'Was': 230, 'anyone': 231, 'child': 232, 'come': 233, 'high': 234, 'human': 235, 'look': 236, 'new': 237, 'non': 238, 'now': 239, 'off': 240, 'through': 241, 'war': 242, 'North': 243, 'down': 244, 'every': 245, 'love': 246, 'mother': 247, '“': 248, '”': 249, '&': 250, '4': 251, 'actually': 252, 'around': 253, 'company': 254, 'end': 255, 'guy': 256, 'job': 257, 'live': 258, 'made': 259, 'towards': 260, 'used': 261, 'Clinton': 262, 'Israel': 263, 'Russian': 264, 'back': 265, 'culture': 266, 'first': 267, 'question': 268, 'religion': 269, 'students': 270, 'stupid': 271, 'under': 272, 'using': 273, 'very': 274, 'English': 275, 'Europe': 276, 'Hillary': 277, 'Russia': 278, 'South': 279, 'another': 280, 'consider': 281, 'day': 282, 'engineering': 283, 'science': 284, 'seem': 285, 'small': 286, 'state': 287, 'wrong': 288, 'Have': 289, 'Hindu': 290, 'It': 291, 'anything': 292, 'buy': 293, 'care': 294, 'guys': 295, 'help': 296, 'language': 297, 'long': 298, 'supporters': 299, 'tell': 300, 'thing': 301, 'United': 302, 'able': 303, 'allowed': 304, 'anti': 305, 'book': 306, 'business': 307, 'claim': 308, 'everyone': 309, 'fact': 310, 'full': 311, 'great': 312, 'gun': 313, 'killed': 314, 'less': 315, 'liberal': 316, 'name': 317, 'never': 318, 'normal': 319, 'president': 320, 'self': 321, 'show': 322, 'support': 323, 'water': 324, 'working': 325, \"'re\": 326, '2017': 327, 'African': 328, 'Christian': 329, 'Could': 330, 'New': 331, 'We': 332, 'age': 333, 'along': 334, 'already': 335, 'answers': 336, 'away': 337, 'blame': 338, 'both': 339, 'called': 340, 'college': 341, 'compared': 342, 'deal': 343, 'doing': 344, 'eat': 345, 'female': 346, 'happen': 347, 'happens': 348, 'health': 349, 'keep': 350, 'kids': 351, 'lot': 352, 'marry': 353, 'politics': 354, 'population': 355, 'problems': 356, 'race': 357, 'rape': 358, 'said': 359, 'sexual': 360, 'something': 361, 'system': 362, '%': 363, 'A': 364, 'And': 365, 'European': 366, 'Japanese': 367, 'Jewish': 368, 'Korea': 369, 'States': 370, 'accept': 371, 'again': 372, 'average': 373, 'big': 374, 'call': 375, 'considered': 376, 'difference': 377, 'done': 378, 'each': 379, 'exam': 380, 'feminists': 381, 'friend': 382, 'given': 383, 'got': 384, 'hard': 385, 'likely': 386, 'living': 387, 'makes': 388, 'married': 389, 'mass': 390, 'million': 391, 'realize': 392, 'rights': 393, 'student': 394, 'turn': 395, 'understand': 396, 'us': 397, '3': 398, 'Asians': 399, 'Canada': 400, 'Europeans': 401, 'Germany': 402, 'computer': 403, 'date': 404, 'days': 405, 'easy': 406, 'etc': 407, 'father': 408, 'food': 409, 'future': 410, 'history': 411, 'international': 412, 'kill': 413, 'kind': 414, 'making': 415, 'others': 416, 'point': 417, 'post': 418, 'pregnant': 419, 'says': 420, 'speak': 421, 'study': 422, 'these': 423, 'those': 424, 'today': 425, 'trying': 426, 'two': 427, 'ways': 428, 'yet': 429, '10': 430, '2018': 431, 'As': 432, 'BJP': 433, 'Britain': 434, 'Has': 435, 'This': 436, 'Western': 437, 'ask': 438, 'asking': 439, 'atheists': 440, 'books': 441, 'boys': 442, 'change': 443, 'comes': 444, 'force': 445, 'issue': 446, 'left': 447, 'marriage': 448, 'matter': 449, 'media': 450, 'move': 451, 'once': 452, 'open': 453, 'pay': 454, 'phone': 455, 'power': 456, 'since': 457, 'sister': 458, 'social': 459, 'though': 460, 'times': 461, 'wants': 462, '’m': 463, ':': 464, 'Arabs': 465, 'Democrats': 466, 'He': 467, 'Hitler': 468, 'Islamic': 469, 'My': 470, 'Syria': 471, 'act': 472, 'allow': 473, 'based': 474, 'control': 475, 'daughter': 476, 'election': 477, 'enough': 478, 'experience': 479, 'few': 480, 'here': 481, 'illegal': 482, 'instead': 483, 'law': 484, 'legal': 485, 'list': 486, 'lost': 487, 'male': 488, 'mobile': 489, 'number': 490, 'okay': 491, 'ones': 492, 'rank': 493, 'society': 494, 'son': 495, 'speech': 496, 'term': 497, 'treat': 498, 'whites': 499, 'young': 500, '’': 501, '12': 502, 'Asian': 503, 'Christianity': 504, 'Iran': 505, 'Koreans': 506, 'Liberals': 507, 'Pakistani': 508, 'They': 509, 'University': 510, 'White': 511, 'affect': 512, 'app': 513, 'atheist': 514, 'beautiful': 515, 'blacks': 516, 'causes': 517, 'choose': 518, 'conservative': 519, 'cultural': 520, 'death': 521, 'due': 522, 'education': 523, 'else': 524, 'equal': 525, 'fake': 526, 'foreign': 527, 'form': 528, 'game': 529, 'general': 530, 'gets': 531, 'group': 532, 'immigrants': 533, 'jobs': 534, 'let': 535, 'level': 536, 'little': 537, 'meaning': 538, 'might': 539, 'military': 540, 'modern': 541, 'nt': 542, 'online': 543, 'part': 544, 'penis': 545, 'play': 546, 'political': 547, 'popular': 548, 'prefer': 549, 'propaganda': 550, 'put': 551, 'raped': 552, 'reason': 553, 'skin': 554, 'software': 555, 'story': 556, 'superior': 557, 'terrorists': 558, 'thoughts': 559, 'watch': 560, 'well': 561, 'words': 562, 'worst': 563, \"'ve\": 564, '*': 565, '5': 566, 'Android': 567, 'Hindi': 568, 'IQ': 569, 'IT': 570, 'Japan': 571, 'Nobel': 572, 'Since': 573, 'West': 574, 'You': 575, 'also': 576, 'among': 577, 'answer': 578, 'asked': 579, 'available': 580, 'banned': 581, 'birth': 582, 'cat': 583, 'citizens': 584, 'class': 585, 'clothing': 586, 'create': 587, 'despite': 588, 'difficult': 589, 'dogs': 590, 'dream': 591, 'engineer': 592, 'equality': 593, 'everything': 594, 'example': 595, 'face': 596, 'family': 597, 'favorite': 598, 'feeling': 599, 'fight': 600, 'gender': 601, 'guns': 602, 'husband': 603, 'important': 604, 'information': 605, 'intelligent': 606, 'join': 607, 'line': 608, 'low': 609, 'mom': 610, 'office': 611, 'officers': 612, 'often': 613, 'order': 614, 'party': 615, 'past': 616, 'poor': 617, 'problem': 618, 'rate': 619, 'rather': 620, 'read': 621, 'relationship': 622, 'religious': 623, 'rude': 624, 'schools': 625, 'seen': 626, 'set': 627, 'side': 628, 'speaking': 629, 'sports': 630, 'started': 631, 'taking': 632, 'talk': 633, 'teach': 634, 'terrorist': 635, 'told': 636, 'too': 637, 'top': 638, 'try': 639, 'type': 640, 'universe': 641, 'vote': 642, 'wear': 643, 'whole': 644, 'win': 645, 'word': 646, '!': 647, '$': 648, '100': 649, '6': 650, 'After': 651, 'Bengali': 652, 'Black': 653, 'Earth': 654, 'French': 655, 'German': 656, 'Google': 657, 'Modi': 658, 'Or': 659, 'TV': 660, 'Turkish': 661, 'U.S.': 662, 'With': 663, 'agree': 664, 'ashamed': 665, 'blue': 666, 'bring': 667, 'car': 668, 'caused': 669, 'common': 670, 'companies': 671, 'conservatives': 672, 'course': 673, 'creating': 674, 'data': 675, 'dog': 676, 'explain': 677, 'flat': 678, 'follow': 679, 'freedom': 680, 'goes': 681, 'happy': 682, 'home': 683, 'humans': 684, 'ignore': 685, 'immigration': 686, 'large': 687, 'leaders': 688, 'light': 689, 'looking': 690, 'lower': 691, 'market': 692, 'members': 693, 'mental': 694, 'myself': 695, 'names': 696, 'nation': 697, 'night': 698, 'nuclear': 699, 'original': 700, 'parents': 701, 'police': 702, 'porn': 703, 'process': 704, 'proof': 705, 'public': 706, 'racial': 707, 'respect': 708, 'rest': 709, 'run': 710, 'score': 711, 'separate': 712, 'service': 713, 'startup': 714, 'states': 715, 'stay': 716, 'studying': 717, 'sugar': 718, 'talking': 719, 'terrorism': 720, 'theory': 721, 'university': 722, 'usually': 723, 'view': 724, 'views': 725, 'wearing': 726, 'website': 727, 'western': 728, 'wo': 729, 'won': 730, 'worth': 731, 'write': 732, 'writing': 733, '+': 734, '7': 735, 'Arab': 736, 'Bible': 737, 'FBI': 738, 'France': 739, 'Greece': 740, 'ISIS': 741, 'Ireland': 742, 'JEE': 743, 'Mueller': 744, 'Mumbai': 745, 'NIT': 746, 'Nazi': 747, 'PM': 748, 'Paul': 749, 'PhD': 750, 'RSS': 751, 'Republicans': 752, 'Tamil': 753, 'Tamils': 754, 'War': 755, 'York': 756, 'YouTube': 757, 'advice': 758, 'afraid': 759, 'anxiety': 760, 'anybody': 761, 'application': 762, 'attacks': 763, 'attracted': 764, 'attractive': 765, 'autism': 766, 'avoid': 767, 'behave': 768, 'behavior': 769, 'brought': 770, 'card': 771, 'case': 772, 'chances': 773, 'comments': 774, 'convert': 775, 'cost': 776, 'crazy': 777, 'crush': 778, 'current': 779, 'cut': 780, 'dating': 781, 'defense': 782, 'die': 783, 'easily': 784, 'enjoy': 785, 'fall': 786, 'feminist': 787, 'finally': 788, 'flight': 789, 'fuck': 790, 'gives': 791, 'god': 792, 'golf': 793, 'graduate': 794, 'groups': 795, 'grow': 796, 'guilty': 797, 'happened': 798, 'hatred': 799, 'higher': 800, 'hire': 801, 'hot': 802, 'improve': 803, 'intelligence': 804, 'interesting': 805, 'jail': 806, 'judge': 807, 'killing': 808, 'knowing': 809, 'knowledge': 810, 'laws': 811, 'lead': 812, 'lives': 813, 'machine': 814, 'mainstream': 815, 'majority': 816, 'means': 817, 'medical': 818, 'mind': 819, 'minimum': 820, 'month': 821, 'months': 822, 'mostly': 823, 'movie': 824, 'movies': 825, 'near': 826, 'next': 827, 'obsessed': 828, 'offended': 829, 'ok': 830, 'outside': 831, 'pain': 832, 'places': 833, 'plants': 834, 'playing': 835, 'politicians': 836, 'prepare': 837, 'punished': 838, 'quality': 839, 'related': 840, 'remove': 841, 'respond': 842, 'result': 843, 'results': 844, 'room': 845, 'safe': 846, 'salary': 847, 'scared': 848, 'seems': 849, 'sell': 850, 'services': 851, 'shit': 852, 'similar': 853, 'single': 854, 'site': 855, 'size': 856, 'slavery': 857, 'slaves': 858, 'smart': 859, 'smell': 860, 'sort': 861, 'standard': 862, 'straight': 863, 'strategy': 864, 'style': 865, 'suddenly': 866, 'supporting': 867, 'terms': 868, 'thought': 869, 'tried': 870, 'trump': 871, 'types': 872, 'ugly': 873, 'violent': 874, 'watching': 875, 'week': 876, 'works': 877, '..': 878, '2016': 879, '30': 880, '8': 881, 'Am': 882, 'Amendment': 883, 'Apple': 884, 'Asia': 885, 'Australia': 886, 'Bangladesh': 887, 'Bangladeshis': 888, 'CBSE': 889, 'California': 890, 'Congress': 891, 'Delhi': 892, 'Democratic': 893, 'EU': 894, 'Gandhi': 895, 'Greeks': 896, 'House': 897, 'Hyderabad': 898, 'Indonesians': 899, 'Israeli': 900, 'Italians': 901, 'Jew': 902, 'Korean': 903, 'Mexico': 904, 'Minister': 905, 'Pakistanis': 906, 'Russians': 907, 'Spanish': 908, 'Sri': 909, 'Star': 910, 'Were': 911, 'WhatsApp': 912, 'Zealand': 913, 'abuse': 914, 'accepting': 915, 'access': 916, 'actresses': 917, 'administration': 918, 'advantages': 919, 'alive': 920, 'allies': 921, 'alone': 922, 'ancient': 923, 'animals': 924, 'apart': 925, 'assault': 926, 'attack': 927, 'attention': 928, 'baby': 929, 'background': 930, 'benefits': 931, 'block': 932, 'boards': 933, 'body': 934, 'born': 935, 'boy': 936, 'boyfriend': 937, 'build': 938, 'career': 939, 'cause': 940, 'certain': 941, 'cheap': 942, 'chemical': 943, 'church': 944, 'civil': 945, 'claiming': 946, 'close': 947, 'collusion': 948, 'coming': 949, 'complete': 950, 'corrupt': 951, 'dark': 952, 'dead': 953, 'depression': 954, 'describe': 955, 'development': 956, 'dick': 957, 'discriminate': 958, 'discrimination': 959, 'distance': 960, 'double': 961, 'download': 962, 'drink': 963, 'early': 964, 'elections': 965, 'enemies': 966, 'evidence': 967, 'exist': 968, 'expect': 969, 'experienced': 970, 'eyes': 971, 'facts': 972, 'far': 973, 'fat': 974, 'females': 975, 'fighting': 976, 'financial': 977, 'flag': 978, 'following': 979, 'football': 980, 'foreigners': 981, 'found': 982, 'friends': 983, 'girlfriend': 984, 'healthy': 985, 'hiring': 986, 'idea': 987, 'ignorant': 988, 'impact': 989, 'income': 990, 'industry': 991, 'inferior': 992, 'innocent': 993, 'inside': 994, 'invest': 995, 'justice': 996, 'kid': 997, 'laptop': 998, 'last': 999, 'lazy': 1000, 'least': 1001, 'leave': 1002, 'leaves': 1003, 'leftists': 1004, 'lose': 1005, 'males': 1006, 'manage': 1007, 'marks': 1008, 'material': 1009, 'math': 1010, 'mathematics': 1011, 'may': 1012, 'meet': 1013, 'milk': 1014, 'murder': 1015, 'nature': 1016, 'news': 1017, 'nice': 1018, 'normally': 1019, 'north': 1020, 'nothing': 1021, 'object': 1022, 'opinion': 1023, 'opportunities': 1024, 'paid': 1025, 'paper': 1026, 'personality': 1027, 'pig': 1028, 'place': 1029, 'policy': 1030, 'position': 1031, 'prevalent': 1032, 'prevent': 1033, 'price': 1034, 'privilege': 1035, 'program': 1036, 'property': 1037, 'psychopath': 1038, 'pushing': 1039, 'putting': 1040, 'racism': 1041, 'random': 1042, 'red': 1043, 'reduce': 1044, 'refer': 1045, 'referred': 1046, 'rid': 1047, 'save': 1048, 'saw': 1049, 'saying': 1050, 'scientific': 1051, 'second': 1052, 'secret': 1053, 'selected': 1054, 'sexually': 1055, 'share': 1056, 'shootings': 1057, 'sign': 1058, 'skills': 1059, 'sleep': 1060, 'sound': 1061, 'special': 1062, 'sport': 1063, 'starting': 1064, 'stopped': 1065, 'summer': 1066, 'survive': 1067, 'tax': 1068, 'teacher': 1069, 'team': 1070, 'thinking': 1071, 'third': 1072, 'trade': 1073, 'transgender': 1074, 'tree': 1075, 'truly': 1076, 'turning': 1077, 'until': 1078, 'various': 1079, 'whether': 1080, 'within': 1081, 'worse': 1082, 'worship': 1083, 'yourself': 1084, \"'ll\": 1085, '12th': 1086, '20': 1087, '40': 1088, 'Africa': 1089, 'Africans': 1090, 'Army': 1091, 'Australian': 1092, 'B': 1093, 'Bangalore': 1094, 'Brahmins': 1095, 'Canadians': 1096, 'Court': 1097, 'DNA': 1098, 'Democrat': 1099, 'East': 1100, 'Facebook': 1101, 'For': 1102, 'From': 1103, 'G': 1104, 'Germans': 1105, 'Hinduism': 1106, 'Hollywood': 1107, 'Indonesia': 1108, 'Iraq': 1109, 'Jesus': 1110, 'Jinping': 1111, 'Khan': 1112, 'Kim': 1113, 'Latin': 1114, 'Lord': 1115, 'MBA': 1116, 'Malaysia': 1117, 'NRA': 1118, 'Nadu': 1119, 'National': 1120, 'Native': 1121, 'Nepal': 1122, 'Netherlands': 1123, 'OBC': 1124, 'On': 1125, 'Palestinians': 1126, 'Party': 1127, 'Prime': 1128, 'Putin': 1129, 'Quorans': 1130, 'Satan': 1131, 'Second': 1132, 'Stalin': 1133, 'Then': 1134, 'There': 1135, 'Turks': 1136, 'UP': 1137, 'Women': 1138, 'World': 1139, 'Xi': 1140, ']': 1141, 'above': 1142, 'accepted': 1143, 'according': 1144, 'across': 1145, 'actions': 1146, 'acts': 1147, 'actual': 1148, 'admission': 1149, 'ago': 1150, 'alcohol': 1151, 'almost': 1152, 'animal': 1153, 'appear': 1154, 'area': 1155, 'areas': 1156, 'aroused': 1157, 'arrested': 1158, 'babies': 1159, 'became': 1160, 'believing': 1161, 'biggest': 1162, 'biography': 1163, 'blind': 1164, 'blog': 1165, 'branch': 1166, 'breasts': 1167, 'brother': 1168, 'buildings': 1169, 'bumps': 1170, 'burned': 1171, 'candidates': 1172, 'cast': 1173, 'check': 1174, 'citizen': 1175, 'clean': 1176, 'cleavage': 1177, 'climate': 1178, 'closer': 1179, 'coaching': 1180, 'combat': 1181, 'communist': 1182, 'completely': 1183, 'consent': 1184, 'conspiracy': 1185, 'contribution': 1186, 'cop': 1187, 'correct': 1188, 'corruption': 1189, 'council': 1190, 'counter': 1191, 'couple': 1192, 'cow': 1193, 'created': 1194, 'crime': 1195, 'criminal': 1196, 'criticism': 1197, 'criticize': 1198, 'cruel': 1199, 'cult': 1200, 'dad': 1201, 'damage': 1202, 'dangerous': 1203, 'declared': 1204, 'demand': 1205, 'design': 1206, 'died': 1207, 'dislike': 1208, 'disorder': 1209, 'divide': 1210, 'doctors': 1211, 'documents': 1212, 'dollars': 1213, 'drop': 1214, 'eating': 1215, 'economy': 1216, 'educated': 1217, 'effect': 1218, 'effects': 1219, 'emotions': 1220, 'ensure': 1221, 'environment': 1222, 'especially': 1223, 'event': 1224, 'evil': 1225, 'exactly': 1226, 'false': 1227, 'famous': 1228, 'fear': 1229, 'fiction': 1230, 'followers': 1231, 'foot': 1232, 'forgive': 1233, 'fun': 1234, 'games': 1235, 'gave': 1236, 'generally': 1237, 'genocide': 1238, 'gift': 1239, 'global': 1240, 'grades': 1241, 'growing': 1242, 'guitar': 1243, 'hair': 1244, 'hands': 1245, 'hated': 1246, 'hates': 1247, 'heritage': 1248, 'highest': 1249, 'hold': 1250, 'hole': 1251, 'huge': 1252, 'humanity': 1253, 'iPhone': 1254, 'ideas': 1255, 'ideology': 1256, 'imagine': 1257, 'including': 1258, 'increasing': 1259, 'independence': 1260, 'insane': 1261, 'insurance': 1262, 'interview': 1263, 'investigation': 1264, 'investment': 1265, 'kick': 1266, 'known': 1267, 'length': 1268, 'lethal': 1269, 'lie': 1270, 'location': 1271, 'loved': 1272, 'mad': 1273, 'main': 1274, 'major': 1275, 'marketing': 1276, 'massacre': 1277, 'masturbate': 1278, 'mentality': 1279, 'mentally': 1280, 'missing': 1281, 'music': 1282, 'national': 1283, 'natural': 1284, 'negative': 1285, 'numbers': 1286, 'older': 1287, 'opposed': 1288, 'opposite': 1289, 'origin': 1290, 'owners': 1291, 'particular': 1292, 'parties': 1293, 'parts': 1294, 'pass': 1295, 'passport': 1296, 'per': 1297, 'pet': 1298, 'planet': 1299, 'policies': 1300, 'possibly': 1301, 'potential': 1302, 'poverty': 1303, 'powerful': 1304, 'preparation': 1305, 'presidency': 1306, 'pretend': 1307, 'pretty': 1308, 'pro': 1309, 'product': 1310, 'products': 1311, 'profit': 1312, 'proper': 1313, 'prove': 1314, 'providing': 1315, 'purpose': 1316, 'qualities': 1317, 'quote': 1318, 'raised': 1319, 'rapist': 1320, 'react': 1321, 'ready': 1322, 'recognize': 1323, 'reconcile': 1324, 'registration': 1325, 'replace': 1326, 'required': 1327, 'resistance': 1328, 'responsible': 1329, 'return': 1330, 'rich': 1331, 'round': 1332, 's': 1333, 'screw': 1334, 'selfish': 1335, 'sensitive': 1336, 'series': 1337, 'sexist': 1338, 'shooting': 1339, 'short': 1340, 'simply': 1341, 'sins': 1342, 'slang': 1343, 'smarter': 1344, 'soft': 1345, 'song': 1346, 'soon': 1347, 'space': 1348, 'species': 1349, 'speed': 1350, 'status': 1351, 'stories': 1352, 'suffer': 1353, 'suffering': 1354, 'supply': 1355, 'technology': 1356, 'theories': 1357, 'thousands': 1358, 'tips': 1359, 'tired': 1360, 'together': 1361, 'toilet': 1362, 'total': 1363, 'touch': 1364, 'town': 1365, 'toxic': 1366, 'traffic': 1367, 'train': 1368, 'training': 1369, 'universities': 1370, 'upon': 1371, 'valid': 1372, 'value': 1373, 'values': 1374, 'vegan': 1375, 'version': 1376, 'video': 1377, 'voice': 1378, 'weed': 1379, 'wish': 1380, 'wives': 1381, 'worry': 1382, 'writers': 1383, 'yellow': 1384, 'younger': 1385, 'zero': 1386, '‘': 1387, '…': 1388, \"'d\": 1389, '0': 1390, '13': 1391, '14': 1392, '17': 1393, '18': 1394, '200': 1395, '25': 1396, '2nd': 1397, '3D': 1398, '9/11': 1399, '99': 1400, '=': 1401, 'All': 1402, 'Any': 1403, 'Asperger': 1404, 'BBC': 1405, 'BS': 1406, 'Bengal': 1407, 'Bengalis': 1408, 'Benjamin': 1409, 'Bill': 1410, 'Blacks': 1411, 'Brazil': 1412, 'Bush': 1413, 'CFA': 1414, 'CM': 1415, 'Ca': 1416, 'Catholic': 1417, 'Chennai': 1418, 'Civil': 1419, 'College': 1420, 'Conservatives': 1421, 'Considering': 1422, 'County': 1423, 'Cricket': 1424, 'DC': 1425, 'DOJ': 1426, 'Dalits': 1427, 'Denmark': 1428, 'E': 1429, 'Emperor': 1430, 'England': 1431, 'Even': 1432, 'Fuck': 1433, 'General': 1434, 'Given': 1435, 'Gordon': 1436, 'Great': 1437, 'Greek': 1438, 'Harry': 1439, 'Harvard': 1440, 'Harvey': 1441, 'Hawking': 1442, 'Holocaust': 1443, 'Holy': 1444, 'IISc': 1445, 'Iranians': 1446, 'Irish': 1447, 'Java': 1448, 'Jio': 1449, 'John': 1450, 'Jong': 1451, 'Just': 1452, 'Justice': 1453, 'KVPY': 1454, 'Kashmir': 1455, 'Kashmiri': 1456, 'Krishna': 1457, 'L': 1458, 'London': 1459, 'MIT': 1460, 'MP': 1461, 'Macedonia': 1462, 'Martin': 1463, 'Men': 1464, 'Middle': 1465, 'Miller': 1466, 'Mormon': 1467, 'Most': 1468, 'Mother': 1469, 'Muhammad': 1470, 'NYC': 1471, 'Nehru': 1472, 'Not': 1473, 'Nothing': 1474, 'ONGC': 1475, 'Obamacare': 1476, 'PS4': 1477, 'Princess': 1478, 'Quran': 1479, 'R': 1480, 'Rahul': 1481, 'Republican': 1482, 'Robert': 1483, 'Roman': 1484, 'Romans': 1485, 'San': 1486, 'Service': 1487, 'Singapore': 1488, 'Singh': 1489, 'So': 1490, 'State': 1491, 'Supreme': 1492, 'Swedes': 1493, 'Swedish': 1494, 'TO': 1495, 'Texas': 1496, 'Theory': 1497, 'To': 1498, 'Turkey': 1499, 'Vegas': 1500, 'Vietnam': 1501, 'WW2': 1502, 'Wars': 1503, 'Westerners': 1504, 'Worlds': 1505, 'Your': 1506, '[': 1507, 'aboriginal': 1508, 'abortion': 1509, 'abroad': 1510, 'abusive': 1511, 'account': 1512, 'acid': 1513, 'added': 1514, 'adult': 1515, 'affairs': 1516, 'agendas': 1517, 'aliens': 1518, 'alternative': 1519, 'ancestors': 1520, 'angry': 1521, 'answering': 1522, 'anthropology': 1523, 'anywhere': 1524, 'applying': 1525, 'appropriate': 1526, 'appropriation': 1527, 'argument': 1528, 'army': 1529, 'artificial': 1530, 'assume': 1531, 'atheism': 1532, 'autistic': 1533, 'aware': 1534, 'bacteria': 1535, 'balance': 1536, 'base': 1537, 'basis': 1538, 'beat': 1539, 'becomes': 1540, 'begin': 1541, 'below': 1542, 'bio': 1543, 'bipolar': 1544, 'bisexual': 1545, 'blood': 1546, 'bombing': 1547, 'borders': 1548, 'box': 1549, 'brain': 1550, 'brainwashed': 1551, 'break': 1552, 'browser': 1553, 'built': 1554, 'butt': 1555, 'cake': 1556, 'campaign': 1557, 'camps': 1558, 'campus': 1559, 'cancer': 1560, 'cards': 1561, 'careers': 1562, 'careless': 1563, 'carry': 1564, 'cases': 1565, 'cash': 1566, 'caste': 1567, 'castrated': 1568, 'category': 1569, 'celebrities': 1570, 'cell': 1571, 'chance': 1572, 'changing': 1573, 'characters': 1574, 'chemistry': 1575, 'chicks': 1576, 'choice': 1577, 'circumcision': 1578, 'cities': 1579, 'city': 1580, 'claims': 1581, 'clear': 1582, 'clearly': 1583, 'cm': 1584, 'code': 1585, 'color': 1586, 'community': 1587, 'compare': 1588, 'compete': 1589, 'computing': 1590, 'concentration': 1591, 'congress': 1592, 'connected': 1593, 'considering': 1594, 'contact': 1595, 'content': 1596, 'convince': 1597, 'courses': 1598, 'court': 1599, 'creatures': 1600, 'credit': 1601, 'crimes': 1602, 'cross': 1603, 'crying': 1604, 'currency': 1605, 'customers': 1606, 'daily': 1607, 'decisions': 1608, 'declare': 1609, 'deleted': 1610, 'deny': 1611, 'depressed': 1612, 'deserve': 1613, 'desire': 1614, 'destroy': 1615, 'destroyed': 1616, 'device': 1617, 'dies': 1618, 'differences': 1619, 'differently': 1620, 'digital': 1621, 'disease': 1622, 'doctor': 1623, 'dumb': 1624, 'earn': 1625, 'economically': 1626, 'effective': 1627, 'eligible': 1628, 'engineers': 1629, 'entire': 1630, 'entrance': 1631, 'entry': 1632, 'envious': 1633, 'ethnic': 1634, 'everybody': 1635, 'everyday': 1636, 'exams': 1637, 'expected': 1638, 'expense': 1639, 'express': 1640, 'extent': 1641, 'extinct': 1642, 'extra': 1643, 'faces': 1644, 'fair': 1645, 'families': 1646, 'fast': 1647, 'feminism': 1648, 'film': 1649, 'final': 1650, 'fire': 1651, 'five': 1652, 'fixed': 1653, 'forever': 1654, 'forms': 1655, 'forward': 1656, 'funny': 1657, 'gain': 1658, 'gays': 1659, 'genuine': 1660, 'giant': 1661, 'goal': 1662, 'graduates': 1663, 'gravity': 1664, 'greater': 1665, 'half': 1666, 'hand': 1667, 'head': 1668, 'healthcare': 1669, 'hear': 1670, 'hearing': 1671, 'himself': 1672, 'hit': 1673, 'holding': 1674, 'homophobic': 1675, 'homosexuals': 1676, 'honestly': 1677, 'hope': 1678, 'husbands': 1679, 'hydrogen': 1680, 'hypocritical': 1681, 'identify': 1682, 'identity': 1683, 'idiots': 1684, 'ill': 1685, 'immigrant': 1686, 'impeach': 1687, 'importance': 1688, 'incest': 1689, 'includes': 1690, 'increase': 1691, 'infinite': 1692, 'instant': 1693, 'intellectual': 1694, 'intercourse': 1695, 'invented': 1696, 'involve': 1697, 'involved': 1698, 'itself': 1699, 'jealous': 1700, 'joke': 1701, 'justify': 1702, 'lack': 1703, 'laid': 1704, 'land': 1705, 'languages': 1706, 'largest': 1707, 'latest': 1708, 'learning': 1709, 'leftist': 1710, 'legally': 1711, 'levels': 1712, 'lighter': 1713, 'liked': 1714, 'likes': 1715, 'limit': 1716, 'link': 1717, 'local': 1718, 'locked': 1719, 'logical': 1720, 'longer': 1721, 'looks': 1722, 'losing': 1723, 'machines': 1724, 'manipulate': 1725, 'marijuana': 1726, 'maximum': 1727, 'meant': 1728, 'meat': 1729, 'mechanical': 1730, 'mentioned': 1731, 'metrics': 1732, 'millions': 1733, 'mine': 1734, 'mining': 1735, 'minorities': 1736, 'misogynistic': 1737, 'miss': 1738, 'mistake': 1739, 'model': 1740, 'mood': 1741, 'movement': 1742, 'moving': 1743, 'multiple': 1744, 'murdered': 1745, 'naked': 1746, 'narcissists': 1747, 'native': 1748, 'natives': 1749, 'needed': 1750, 'neighbor': 1751, 'neighborhood': 1752, 'nose': 1753, 'note': 1754, 'novel': 1755, 'nuke': 1756, 'objects': 1757, 'occur': 1758, 'odd': 1759, 'officer': 1760, 'official': 1761, 'opinions': 1762, 'options': 1763, 'outlets': 1764, 'overweight': 1765, 'owner': 1766, 'peaceful': 1767, 'penalty': 1768, 'percent': 1769, 'period': 1770, 'phones': 1771, 'photo': 1772, 'photography': 1773, 'physically': 1774, 'played': 1775, 'plead': 1776, 'politician': 1777, 'poop': 1778, 'poorly': 1779, 'positive': 1780, 'posting': 1781, 'powers': 1782, 'pregnancy': 1783, 'present': 1784, 'pressure': 1785, 'prime': 1786, 'private': 1787, 'proclaimed': 1788, 'professional': 1789, 'programming': 1790, 'progressives': 1791, 'promiscuous': 1792, 'promote': 1793, 'prospects': 1794, 'protect': 1795, 'protesters': 1796, 'provide': 1797, 'psychology': 1798, 'psychopaths': 1799, 'pull': 1800, 'punishment': 1801, 'puppies': 1802, 'pursue': 1803, 'push': 1804, 'pussy': 1805, 'quick': 1806, 'rat': 1807, 'reaching': 1808, 'reaction': 1809, 'reading': 1810, 'reality': 1811, 'reasons': 1812, 'recent': 1813, 'recently': 1814, 'relationships': 1815, 'relative': 1816, 'reparations': 1817, 'request': 1818, 'requirements': 1819, 'research': 1820, 'revealing': 1821, 'revenge': 1822, 'revolution': 1823, 'reward': 1824, 'ride': 1825, 'rise': 1826, 'role': 1827, 'rubbing': 1828, 'ruining': 1829, 'running': 1830, 'salt': 1831, 'scene': 1832, 'schedule': 1833, 'schemes': 1834, 'scholarship': 1835, 'sea': 1836, 'search': 1837, 'secular': 1838, 'security': 1839, 'seduce': 1840, 'seeing': 1841, 'seek': 1842, 'seeking': 1843, 'sees': 1844, 'selling': 1845, 'sent': 1846, 'sentence': 1847, 'settings': 1848, 'shall': 1849, 'shift': 1850, 'shop': 1851, 'shot': 1852, 'signature': 1853, 'simultaneously': 1854, 'singing': 1855, 'sisters': 1856, 'sites': 1857, 'slave': 1858, 'smoke': 1859, 'smoking': 1860, 'soap': 1861, 'solving': 1862, 'somebody': 1863, 'sometimes': 1864, 'specifically': 1865, 'spread': 1866, 'stand': 1867, 'star': 1868, 'staring': 1869, 'statement': 1870, 'stealing': 1871, 'stock': 1872, 'stream': 1873, 'streets': 1874, 'strikes': 1875, 'strong': 1876, 'studies': 1877, 'success': 1878, 'successful': 1879, 'supported': 1880, 'supremacy': 1881, 'sure': 1882, 'syllabus': 1883, 'sympathy': 1884, 'taken': 1885, 'takes': 1886, 'teachers': 1887, 'teaching': 1888, 'teenage': 1889, 'teenager': 1890, 'teens': 1891, 'temperature': 1892, 'tend': 1893, 'territory': 1894, 'test': 1895, 'thin': 1896, 'throughout': 1897, 'toilets': 1898, 'took': 1899, 'torture': 1900, 'traditions': 1901, 'transfer': 1902, 'travel': 1903, 'troll': 1904, 'trouble': 1905, 'truth': 1906, 'turned': 1907, 'undergraduate': 1908, 'uneducated': 1909, 'unemployed': 1910, 'united': 1911, 'useless': 1912, 'user': 1913, 'users': 1914, 'uses': 1915, 'vehicles': 1916, 'versa': 1917, 'vice': 1918, 'videos': 1919, 'visit': 1920, 'volume': 1921, 'voted': 1922, 'wake': 1923, 'wall': 1924, 'wars': 1925, 'weaker': 1926, 'wealth': 1927, 'weather': 1928, 'web': 1929, 'weekend': 1930, 'weight': 1931, 'weird': 1932, 'went': 1933, 'west': 1934, 'whereas': 1935, 'whom': 1936, 'wide': 1937, 'wife': 1938, 'wind': 1939, 'wing': 1940, 'worked': 1941, 'worried': 1942, 'x': 1943, 'y': 1944, '–': 1945, '’re': 1946, '’ve': 1947})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElbnYTgLSunc"
      },
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "device = \"cpu\"\n",
        "#set batch size\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C5xjf0yTPQt"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6wnquh-TVjN"
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsATQG_dTev1",
        "outputId": "26fac12b-ba1e-415b-8dd8-a2ea2588a690"
      },
      "source": [
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(1948, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 254,257 trainable parameters\n",
            "torch.Size([1948, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYtTULlqTnzV",
        "outputId": "1c4a858c-1d5d-47c2-a08a-74633bf7b99f"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "print(\"curent device:\", device)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "curent device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqXlyQlT3xV"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoevj1w5UB0V"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta9Ja0ARUFVF",
        "outputId": "d7f69372-567f-4734-af40-6147b0a4823d"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "        \n",
        "    print(\"Epoch:\", epoch + 1)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tTrain Loss: 0.002 | Train Acc: 99.93%\n",
            "\t Val. Loss: 1.627 |  Val. Acc: 79.55%\n",
            "Epoch: 2\n",
            "\tTrain Loss: 0.002 | Train Acc: 99.93%\n",
            "\t Val. Loss: 1.634 |  Val. Acc: 79.80%\n",
            "Epoch: 3\n",
            "\tTrain Loss: 0.001 | Train Acc: 99.93%\n",
            "\t Val. Loss: 1.698 |  Val. Acc: 79.88%\n",
            "Epoch: 4\n",
            "\tTrain Loss: 0.028 | Train Acc: 98.89%\n",
            "\t Val. Loss: 1.263 |  Val. Acc: 79.96%\n",
            "Epoch: 5\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.61%\n",
            "\t Val. Loss: 1.351 |  Val. Acc: 79.98%\n",
            "Epoch: 6\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.82%\n",
            "\t Val. Loss: 1.527 |  Val. Acc: 79.63%\n",
            "Epoch: 7\n",
            "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
            "\t Val. Loss: 1.625 |  Val. Acc: 79.88%\n",
            "Epoch: 8\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.86%\n",
            "\t Val. Loss: 1.700 |  Val. Acc: 79.38%\n",
            "Epoch: 9\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.18%\n",
            "\t Val. Loss: 1.595 |  Val. Acc: 77.71%\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.86%\n",
            "\t Val. Loss: 1.536 |  Val. Acc: 79.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUVwQo6eCcC6"
      },
      "source": [
        "##Referencias\n",
        "https://www.kaggle.com/anindya2906/glove6b"
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpsiegel/Projects/blob/master/caseStudy_Jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda588a8",
      "metadata": {
        "id": "eda588a8"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "### Background\n",
        "\n",
        "This case study is losely based on an actual market research problem. The client tested a (relatively) large number of advertising messages over the years. These tests involved respondents evaluating the credibility and appeal of those messages. These evaluations are aggregated to a score which is then binned using deciles. Top decile claims are likely to be used in actual advertising campaigns. \n",
        "\n",
        "We try to predict the claim performance (as represented by the decile) from the text by applying a popular pre-trained model.\n",
        "\n",
        "### Your task\n",
        "\n",
        "Fill in the blanks to make a basic analysis work. Add to it as much as you like. During the subsequent interview, you can explain your solution and approach.\n",
        "\n",
        "### Data\n",
        "\n",
        "There are three column in the data, `Message_Text` (The advertising message), `score` (The survey-based score) and `label` (Decile).\n",
        "\n",
        "Our client wants to predict `label` from `Message_Text`. There are 10 classes in total.\n",
        "\n",
        "The data structure is based on real data, however, for confidentiality reasons it is not our actual client data.\n",
        "\n",
        "### Model\n",
        "\n",
        "The code below apply *distilbert model* to do the classification. Please fill the blanks.\n",
        "\n",
        "We will use pretraiend model from [huggingface](https://huggingface.co/) library. Hugginface is an open source AI library where published cutting-edge advanced AI models. You can find [courses](https://huggingface.co/course/chapter1/1) online.\n",
        " \n",
        "This case study is [text classification](https://huggingface.co/tasks/text-classification) task.\n",
        "If you are not familiar with [Bert](https://en.wikipedia.org/wiki/BERT_(language_model)), please check this [paper](https://arxiv.org/abs/1810.04805). Please also check [attention machenism](https://arxiv.org/abs/1706.03762) and transformer. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "PUcO4Ns-BRM-"
      },
      "id": "PUcO4Ns-BRM-"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eeef000a",
      "metadata": {
        "id": "eeef000a"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet \n",
        "!pip install datasets --quiet\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil --quiet\n",
        "!pip install psutil --quiet\n",
        "!pip install humanize --quiet\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU unit\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]  # Only one GPU on Colab and not guaranteed\n",
        "\n",
        "def printm():\n",
        "  \"\"\"Prints available ram and graphic memory\"\"\"\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" | Used: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "  print(\"VRAM Free: {0:.0f}MB | Used: {1:.0f}MB | Using {2:3.0f}% Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil * 100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "metadata": {
        "id": "vwt3bflOwc34"
      },
      "id": "vwt3bflOwc34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive for workspace\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "def mount_gdrive():\n",
        "  \"\"\"Sets up google drive directory access\"\"\"\n",
        "  path = \"/content/drive\"\n",
        "  drive.mount(path, force_remount=True)\n",
        "  \n",
        "my_dir = \"/content/drive/MyDrive/CaseStudySkim/\"\n",
        "mount_gdrive()\n",
        "print(os.listdir(my_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb4bzbYfxpEz",
        "outputId": "ec704bec-4471-4c45-8439-e495c5eeedd1"
      },
      "id": "gb4bzbYfxpEz",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['caseStudy_Jan.ipynb', 'sampled_data_NLP.xltx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "486de0c1",
      "metadata": {
        "id": "486de0c1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
        "                          TrainingArguments, Trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Exploration"
      ],
      "metadata": {
        "id": "VV8jKh5vA-az"
      },
      "id": "VV8jKh5vA-az"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b52a71e1",
      "metadata": {
        "id": "b52a71e1",
        "outputId": "5fd88250-7d1b-411b-f679-11607365eed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (7211, 3) \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Message_Text   label     score\n",
              "0                           Impeccable stain removal  class7  0.634615\n",
              "1  With Odour Resistance Formula - Still fresh at...  class9  0.875000\n",
              "2                                    Original recipe  class8  0.788462\n",
              "3  Natural hair gene awakening for 1000 new hair ...  class4  0.383333\n",
              "4                             Plastic-free packaging  class5  0.483871"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3c57cd8-9eaf-49f1-a540-c2ba83fe0dd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message_Text</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Impeccable stain removal</td>\n",
              "      <td>class7</td>\n",
              "      <td>0.634615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>With Odour Resistance Formula - Still fresh at...</td>\n",
              "      <td>class9</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original recipe</td>\n",
              "      <td>class8</td>\n",
              "      <td>0.788462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Natural hair gene awakening for 1000 new hair ...</td>\n",
              "      <td>class4</td>\n",
              "      <td>0.383333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Plastic-free packaging</td>\n",
              "      <td>class5</td>\n",
              "      <td>0.483871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3c57cd8-9eaf-49f1-a540-c2ba83fe0dd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3c57cd8-9eaf-49f1-a540-c2ba83fe0dd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3c57cd8-9eaf-49f1-a540-c2ba83fe0dd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data = pd.read_excel(my_dir + \"sampled_data_NLP.xltx\")\n",
        "print(\"Shape: \", data.shape, \"\\n\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aaa018a2",
      "metadata": {
        "id": "aaa018a2",
        "outputId": "de8b77ed-d98f-4837-e6ee-7ac4f2d5d8c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unwanted characters: \n",
            "\n",
            " Message_Text    Yumos: 2 fragrances in 1¬†fabcon - every time ...\n",
            "label                                                      class2\n",
            "score                                                    0.105263\n",
            "Name: 1254, dtype: object \n",
            "\n",
            "Message_Text    \"It‚Äôs better than any other Deodorants that ...\n",
            "label                                                     class10\n",
            "score                                                    0.928571\n",
            "Name: 1649, dtype: object \n",
            "\n",
            "Non-english languages: \n",
            "\n",
            " Message_Text    Vrij van conserveermiddelen\n",
            "label                                class5\n",
            "score                              0.433333\n",
            "Name: 2000, dtype: object \n",
            "\n",
            "Message_Text    Textura ideal con muchos tomates\n",
            "label                                     class9\n",
            "score                                       0.85\n",
            "Name: 1104, dtype: object\n"
          ]
        }
      ],
      "source": [
        "symbol_example1 = 1254\n",
        "symbol_example2 = 1649\n",
        "dutch_example = 2000\n",
        "spanish_example = 1104\n",
        "print(\"Unwanted characters: \\n\\n\", data.iloc[symbol_example1], \"\\n\")\n",
        "print(data.iloc[symbol_example2], \"\\n\")\n",
        "print(\"Non-english languages: \\n\\n\", data.iloc[dutch_example], \"\\n\")\n",
        "print(data.iloc[spanish_example])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c68a66",
      "metadata": {
        "id": "53c68a66"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0rc1 --quiet\n",
        "!pip install chardet\n",
        "!pip install langid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhW0RenlKgLR",
        "outputId": "983adce9-375d-4cad-af9a-f3bf2f5af294"
      },
      "id": "qhW0RenlKgLR",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from langid) (1.21.6)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941188 sha256=25f2c46fd83158fdb32c3afd1f44d54e18a3a693a7e13dacc7ca0298448d4d07\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/bb/7f/11e4db39477278161e882eadc46fb558949a28b13470fc74b8\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "41f8f845",
      "metadata": {
        "id": "41f8f845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70988a7b-2f8e-4451-c702-6b35ff441230"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('it', -6.865324020385742)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Please preprocess label column into correct format to make it run model smoothly\n",
        "# your code here....\n",
        "\n",
        "data[\"Message_Text\"] = data[\"Message_Text\"].apply(lambda x: ''.join([\"\" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
        "\n",
        "#print(data.iloc[symbol_example1], \"\\n\")\n",
        "#print(data.iloc[symbol_example2])\n",
        "\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "def detect_language(string, translator=translator):\n",
        "  try:\n",
        "    ret = translator.detect(string).lang == \"en\"\n",
        "  except AttributeError:\n",
        "    print(string)\n",
        "    ret = False\n",
        "  return ret\n",
        "\n",
        "import langid\n",
        "def detect_lang(string):\n",
        "  return langid.classify(string)[0] == \"en\"\n",
        "\n",
        "#df = df.drop(df[df.score < 50].index)\n",
        "#df[df['column name'].map(len) < 2]#\n",
        "\n",
        "#data_noneng = data[data[\"Message_Text\"].map(detect_lang) == False]\n",
        "#for i in range(773):\n",
        "#  print(data_noneng.iloc[i][\"Message_Text\"])\n",
        "\n",
        "#import langid\n",
        "langid.classify(\"More space, better taste\")\n",
        " \n",
        "\n",
        "# DEJAR AMBOS DATASETS, UNO CON TODO LOS LANGS, OTRO CON LA REDUCCION PIOLA HECHA CON LANGID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc9af36",
      "metadata": {
        "id": "9fc9af36"
      },
      "outputs": [],
      "source": [
        "# convert pandas into dataset and get train and test dataset\n",
        "ds = (Dataset.from_pandas(data).train_test_split(train_size=0.8, test_size=0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35f3e79",
      "metadata": {
        "id": "c35f3e79",
        "outputId": "15d6dc01-b88b-4010-eba7-fb814772a9ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Message_Text': 'Now uses the power of nature for longer lasting fragrance',\n",
              " 'label': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              " 'score': 0.35294117647058826,\n",
              " 'idx': 5807}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# peek at one example\n",
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9316ee",
      "metadata": {
        "id": "3a9316ee"
      },
      "source": [
        "## Tokenizer\n",
        "\n",
        "We are using huggingface [AutoClass](https://huggingface.co/docs/transformers/model_doc/auto). For the [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer), please check here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93dc9dd",
      "metadata": {
        "id": "c93dc9dd"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "# please write the correct parameters here....\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d5abd4",
      "metadata": {
        "id": "04d5abd4"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_encode(examples):\n",
        "    return tokenizer(examples[\"Message_Text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsYUMM8iFBkg"
      },
      "id": "ZsYUMM8iFBkg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8511de31",
      "metadata": {
        "id": "8511de31",
        "outputId": "3c73489f-3a88-4106-af52-a36b629f8a05",
        "colab": {
          "referenced_widgets": [
            "17c34c69bb414831bc61de16c4d5d5a7",
            "7d860e1c54a3480ea57145e6f718aae4"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17c34c69bb414831bc61de16c4d5d5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d860e1c54a3480ea57145e6f718aae4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 7025\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1757\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols = ds[\"train\"].column_names\n",
        "cols.remove(\"label\")\n",
        "ds_enc = ds.map(tokenize_and_encode, batched=True, remove_columns=cols)\n",
        "ds_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06919b4b",
      "metadata": {
        "id": "06919b4b",
        "outputId": "57ad8241-f4ea-440a-f9d7-158772300041",
        "colab": {
          "referenced_widgets": [
            "d381df97579a43cc95707077561bf978",
            "a14f347393b04dbe98135104b7a453be"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d381df97579a43cc95707077561bf978",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7025 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a14f347393b04dbe98135104b7a453be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1757 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# cast label IDs to floats\n",
        "ds_enc.set_format(\"torch\")\n",
        "ds_enc = (ds_enc\n",
        "          .map(lambda x : {\"float_label\": x[\"label\"].to(torch.float)}, remove_columns=[\"label\"])\n",
        "          .rename_column(\"float_label\", \"label\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bf5b4f",
      "metadata": {
        "id": "13bf5b4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7ef3ed",
      "metadata": {
        "id": "9b7ef3ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9c495659",
      "metadata": {
        "id": "9c495659"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e3bd53",
      "metadata": {
        "id": "78e3bd53"
      },
      "outputs": [],
      "source": [
        "model = (AutoModelForSequenceClassification\n",
        "         .from_pretrained(\n",
        "            # please add your code here....\n",
        "          ).to('cuda')\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f0f86a",
      "metadata": {
        "id": "b8f0f86a",
        "outputId": "dfd5abe4-362a-4089-c1f1-70a2aa33e64c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  2085,  3594,  1996,  2373,  1997,  3267,  2005,  2936,  9879,\n",
              "         24980,   102]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'label': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's peek the data\n",
        "ds_enc[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62a279d",
      "metadata": {
        "id": "b62a279d"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "  # please put your code here....\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, \n",
        "                  args=args, \n",
        "                  train_dataset=ds_enc[\"train\"], \n",
        "                  eval_dataset=ds_enc[\"test\"], \n",
        "                  tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06001128",
      "metadata": {
        "id": "06001128"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f92dc3",
      "metadata": {
        "id": "72f92dc3"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b743288f",
      "metadata": {
        "id": "b743288f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e11f76ae",
      "metadata": {
        "id": "e11f76ae"
      },
      "source": [
        "# Improvement?\n",
        "\n",
        "Congrats! You finish your model training.\n",
        "\n",
        "But this is a very basic model, there are still lots of improvements could be done. \n",
        "\n",
        "For example, improving model accuracy by tuning hyperparameter, changing different models, logging model to diagnose models. \n",
        "You could also try explinable AI to interpret why model gives this prediction. \n",
        "\n",
        "Client is also interested in directly predicting socres, you could also try that.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745a60af",
      "metadata": {
        "id": "745a60af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f4e7bd",
      "metadata": {
        "id": "c2f4e7bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_pytorch_latest_p36",
      "language": "python",
      "name": "conda_pytorch_latest_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
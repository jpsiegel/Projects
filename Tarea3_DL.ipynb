{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea3-DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJnAa812A/6RD/pTuUk23Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpsiegel/Projects/blob/master/Tarea3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ET622QKRj9"
      },
      "source": [
        "#Tarea 3 Jan P. Siegel - Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EARkwmAr12gB"
      },
      "source": [
        "##Allocate resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yumMEzxTJ1ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d69717-1772-491f-c3de-37ca7ef48fa2"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "import psutil\n",
        "import humanize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7ocfSQcd2bU",
        "outputId": "a5ee29cb-d989-475a-cb9a-1133093e2ce1"
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]  # Only one GPU on Colab and not guaranteed\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" | Used: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "  print(\"VRAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAM Free: 12.7 GB  | Used: 118.4 MB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvwy3-acKNKl",
        "outputId": "bfd7e06a-5e40-428c-ba73-e7fb73c3cbdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_dir = \"/content/drive/MyDrive/DL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGA7PU9ejJdl"
      },
      "source": [
        "# Download Roms\n",
        "!wget http://www.atarimania.com/roms/Roms.rar > /dev/null\n",
        "# Decompresed files\n",
        "!unrar e Roms.rar > /dev/null\n",
        "!unzip 'ROMS.zip' > /dev/null\n",
        "# Add Roms folder to atary_py PATH\n",
        "!python -m atari_py.import_roms 'ROMS' > /dev/null\n",
        "# > /dev/null omits command output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoWNXSTZ1xux"
      },
      "source": [
        "##Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WMiFXZSwGgD"
      },
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import cv2\n",
        "\n",
        "# pasar a escala de grises y recortar imagen\n",
        "def _process_frame84(frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    frame = frame[:155,10:]\n",
        "    #x_t = cv2.resize(frame, (84, 84),  interpolation=cv2.INTER_LINEAR)\n",
        "    x_t = cv2.resize(frame, (84, 84),interpolation=cv2.INTER_AREA)\n",
        "    return x_t.astype(np.uint8)\n",
        "\n",
        "class ProcessFrame84(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84))\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        return _process_frame84(obs), reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        return _process_frame84(self.env.reset())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "tqI3xgULw6nj",
        "outputId": "66cef18f-756e-44d3-92f2-7066a95ccad2"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from gym.wrappers import AtariPreprocessing\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "#Create environment\n",
        "game = 'Enduro-v0'\n",
        "env = gym.make(game,frameskip=4) # saltamos de a 4 frames para acelerar entrenamiento\n",
        "\n",
        "# For reproducibility\n",
        "seed = 0\n",
        "env.seed(seed)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "plt.imshow(np.squeeze(obs))\n",
        "plt.title('Gym Enduro Interface')\n",
        "plt.show()\n",
        "\n",
        "env = ProcessFrame84(env) # pasamos el wrapper al enviroment\n",
        "env = FrameStack(env,num_stack=4) # un estado definido como el actual mas los 3 anteriores\n",
        "obs = env.reset()\n",
        "\n",
        "for _ in range(100):\n",
        "  action = random.randint(0,env.action_space.n-1) # seleccionar accion random\n",
        "  obs, reward, done, info = env.step(action)\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(np.squeeze(np.array(obs)[0,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(np.squeeze(np.array(obs)[1,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(np.squeeze(np.array(obs)[2,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(np.squeeze(np.array(obs)[3,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"obs shape:\", obs.shape)\n",
        "print(\"actions:\", env.get_action_meanings(), \"amount:\", env.action_space.n)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "obs shape: (4, 84, 84)\n",
            "actions: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE'] amount: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6wuPkDuJjL"
      },
      "source": [
        "### Actividad 1\n",
        "Definimos un estado como un stack de el frame actual, más los 3 frames anteriores, por lo que cada estado (que será el input de la red) corresponde a 4 pasos de Enduro. Esto es clave para que la red convolucional pueda tener una noción de velocidad del jugador y de los demás competidores. La velocidad solo puede obtenerse comparando posiciones en frames contiguas, lo cual es información indispensable para que un agente pueda aprender a jugar Enduro competentemente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0YDMlXdjy7"
      },
      "source": [
        "### Fill replay memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tke1H0jD0Xfa"
      },
      "source": [
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = [] # Can be a list a Deque or another type of list\n",
        "        self.next_replace_position = 0\n",
        "\n",
        "    def push(self, state, action, next_state, reward, done):\n",
        "        \"\"\"Saves a transition.\n",
        "        e.g. ('state', 'action', 'next_state', 'reward','done')\n",
        "        \"\"\"\n",
        "        memory_data = (state, action, next_state, reward, done)\n",
        "        if len(self) >= self.capacity:\n",
        "          self.memory[self.next_replace_position] = memory_data\n",
        "          self.next_replace_position += 1\n",
        "          if self.next_replace_position > self.capacity - 1:\n",
        "            self.next_replace_position = 0\n",
        "        else:\n",
        "          self.memory.append(memory_data)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "       \"\"\" Samples a transition with a defined batch size\"\"\"\n",
        "       sampled_tuples = random.sample(self.memory, batch_size) # list of tuples\n",
        "       zipped = tuple(zip(*sampled_tuples))\n",
        "       return zipped\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSeQ-3WddCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1524745-0090-40ea-8dcc-7b0b419e6ba8"
      },
      "source": [
        "memory_size = 500000\n",
        "replay_memory = ReplayMemory(memory_size)\n",
        "\n",
        "current_obs = env.reset()\n",
        "for _ in range(memory_size):\n",
        "  if _ % 100000 == 0:\n",
        "    print(f\"{_}/{memory_size}\")\n",
        "  #print(_, replay_memory.next_replace_position, len(replay_memory))\n",
        "  action = random.randint(0,env.action_space.n-1) # seleccionar accion random\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  replay_memory.push(current_obs, action, obs, reward, done)\n",
        "  current_obs = obs\n",
        "  if done: # si pierde partimos nuevo episodio\n",
        "    current_obs = env.reset()\n",
        "  else:\n",
        "    current_obs = obs\n",
        "printm()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/500000\n",
            "100000/500000\n",
            "200000/500000\n",
            "300000/500000\n",
            "400000/500000\n",
            "RAM Free: 8.3 GB  | Used: 4.6 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GRfqj131q9x"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD0EXVo_1FMy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class Dueling_DQN(nn.Module):\n",
        "    def __init__(self, in_channels, num_actions):\n",
        "        super(Dueling_DQN, self).__init__()\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "\n",
        "        self.fc1_val = nn.Linear(in_features=7*7*64, out_features=512)\n",
        "        self.fc2_val = nn.Linear(in_features=512, out_features=1)\n",
        "\n",
        "        self.fc1_adv = nn.Linear(in_features=7*7*64, out_features=512)\n",
        "        self.fc2_adv = nn.Linear(in_features=512, out_features=num_actions)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      # X es un tensor (batch_size x 4 x 84 x 84) que representa un batch de stacks de estados\n",
        "      batch_size = x.size(0)\n",
        "\n",
        "      # forward pass red convolucional\n",
        "      x = self.relu(self.conv1(x))\n",
        "      x = self.relu(self.conv2(x))\n",
        "      x = self.relu(self.conv3(x))\n",
        "      x = torch.flatten(x, start_dim=1) # start_dim 1 para mantener separado el batch\n",
        "      #print(\"State embedding:\", x.shape, x)\n",
        "      \n",
        "      # forward pass rama fully-connected para V(s)\n",
        "      v_s = self.relu(self.fc1_val(x))\n",
        "      v_s = self.fc2_val(v_s).expand(batch_size, self.num_actions)\n",
        "      #print(\"V(s):\", v_s.shape, v_s)\n",
        "\n",
        "      # forward pass rama fully-connected para A(s,a)\n",
        "      adv = self.relu(self.fc1_adv(x))\n",
        "      adv = self.fc2_adv(adv)\n",
        "      #print(\"A(s,a):\", adv.shape, adv)\n",
        "      #print(\"mean A(s,a):\", torch.mean(adv, 1, keepdim=True).shape, torch.mean(adv, 1, keepdim=True))\n",
        "\n",
        "      # Calculo de Q(s,a) a partir de ecuacion (4)\n",
        "      Q_values = v_s + (adv - torch.mean(adv, 1, keepdim=True)) # testeado\n",
        "\n",
        "      return Q_values # batch_size x num_actions"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i719vkMq1srh"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C77orgGvqGui"
      },
      "source": [
        "def exploration(total_steps):\n",
        "  \"\"\" retorna probabilidad de que explore con accion random \"\"\"\n",
        "  if total_steps >= 1000000:\n",
        "    epsilon = 0.1\n",
        "  else:\n",
        "    m = -0.9 / 1000000\n",
        "    n = 1\n",
        "    epsilon = m * total_steps + n\n",
        "  return epsilon"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv1TE3Vv3WsX"
      },
      "source": [
        "# Define parameters and instance NNs\n",
        "\n",
        "from torch import device\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "frame_history_len = 4 # Cantidad de frames de cada estado (definido en el pre-procesamiento)\n",
        "batch_size = 32\n",
        "gamma = 0.99 # Factor de descuento\n",
        "learning_starts = 50000 # Paso en que se comienza a utilizar la red para escoger acciones (siguiendo política e-greedy)\n",
        "learning_freq = 4 # Frecuencia de pasos en que se modifican los pesos (loss backprop) en la red Q\n",
        "target_update_freq = 10000 # Frecuencia en que se actualizan los pesos de la red target Q' (cada x backprops, updateo Q')\n",
        "LR = 0.00025 # Tasa de aprendizaje\n",
        "\n",
        "in_channels = frame_history_len\n",
        "input_shape = (84,84)\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "# define Q target and Q \n",
        "Q = Dueling_DQN(in_channels, num_actions).to(device) # esta es la que de verdad quiero entrenar\n",
        "Q_target = Dueling_DQN(in_channels, num_actions).to(device) # para estabilidad, esta me entrega los labels\n",
        "\n",
        "# Optimizador, pueden elegir entre Adam o RMSProp\n",
        "optimizer = optim.Adam(Q.parameters(), lr=LR)\n",
        "\n",
        "LOG_EVERY_N_STEPS = 50000 # (Opcional) Frecuencia en la que se muestran resultados en consola\n",
        "STEPS_PER_EPOCH = 250000 # Pasos por época\n",
        "N_EPOCHS = 6 # Número de épocas"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37rt28Z01owa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "c159babf-9952-45b1-d854-f5485f68a112"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch import tensor, no_grad\n",
        "import numpy as np\n",
        "\n",
        "# Load checkpoint: probablemente se quede sin memoria durante entrenamiento,\n",
        "# por eso hay que guardar checkpoint (pesos) en drive cada cierto tiempo\n",
        "# luego cargamos checkpoint, rellenamos memory buffer, y retomamos\n",
        "# pero el rellenado debe ser usando el modelo que tenemos hasta ahora! no random como el inicial\n",
        "\n",
        "# Reseteamos nuestro ambiente para empezar el entrenamiento\n",
        "last_obs = env.reset()\n",
        "current_reward = 0\n",
        "backprops = 0\n",
        "episodes_rewards = []\n",
        "epsilon_history = []\n",
        "error_history = []\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS),position=0,leave=True):\n",
        "  for t in tqdm(range(STEPS_PER_EPOCH),position=0,leave=True):\n",
        "    total_steps = t + STEPS_PER_EPOCH * epoch # steps acumulados a traves de las epocas\n",
        "    ### 1. Choose actions and update replay memory buffer\n",
        "    if t < learning_starts and epoch == 0:\n",
        "      action = np.random.randint(num_actions)\n",
        "    else:\n",
        "      # epsilon greedy exploration\n",
        "      sample = random.random()\n",
        "      threshold = exploration(total_steps)  # la funcion exploration permite calcular el threshold para la política e-greedy\n",
        "      epsilon_history.append(threshold)\n",
        "      if sample <= threshold:\n",
        "        action = np.random.randint(num_actions)\n",
        "      else:\n",
        "        with no_grad(): # no actualizamos gradientes pq estamos evaluando\n",
        "          # Seleccionar la acción segun la red Q\n",
        "          last_obs_tensor = torch.from_numpy(np.array(last_obs)).to(device) / 255.0 # pasamos a tensor y normalizamos\n",
        "          last_obs_tensor_batched = last_obs_tensor.unsqueeze(0).repeat(batch_size, 1, 1, 1) # last obs solo es 1 estado, pero necesitamos batch_size estados para la red\n",
        "          all_q_values = Q(last_obs_tensor_batched)\n",
        "          action = ((all_q_values).data.max(1)[1])[0] # selecciono indice de mejor q_value\n",
        "\n",
        "    obs, reward, done, _ = env.step(action) # ejecuto accion seleccionada\n",
        "    replay_memory.push(last_obs, action, obs, reward, done) # actualizo experiencia en buffer\n",
        "    current_reward += reward\n",
        "    if done:\n",
        "      # Termino episodio!\n",
        "      obs = env.reset()\n",
        "      # Guardar reward acumulado del episodio\n",
        "      episodes_rewards.append(current_reward)\n",
        "      current_reward = 0\n",
        "\n",
        "    # update last_obs\n",
        "    last_obs = obs\n",
        "\n",
        "    ### 2. Perform experience replay and train the network.\n",
        "    if (t > learning_starts and t % learning_freq == 0):\n",
        "      obs_t, act_t, next_obs, rew_t, done_mask = replay_memory.sample(batch_size) # esto me deja listas de largo batch size\n",
        "          \n",
        "      # Pasar los arreglos a tensores y al device actual\n",
        "      obs_t = torch.from_numpy(np.array(obs_t)).to(device)\n",
        "      act_t = torch.from_numpy(np.array(act_t)).to(device)\n",
        "      next_obs = torch.from_numpy(np.array(next_obs)).to(device)\n",
        "      rew_t = torch.from_numpy(np.array(rew_t)).to(device)\n",
        "      done_mask = torch.from_numpy(np.array(done_mask)).to(device)\n",
        "\n",
        "      # Normalizar tensores de entrada\n",
        "      obs_t = obs_t / 255.0\n",
        "      next_obs = next_obs / 255.0\n",
        "\n",
        "      # construir Y (labels)\n",
        "      with no_grad(): # esto no debe ser parte del backprop, solo consigue los labels\n",
        "        q_tp1_values = Q(next_obs)\n",
        "        _, a_prime = q_tp1_values.max(1) # selecciono la mejor accion para el estado siguiente\n",
        "        q_target_tp1_values = Q_target(next_obs)\n",
        "        q_target_s_a_prime = q_target_tp1_values.gather(1, a_prime.unsqueeze(1)).squeeze() # selecciono el q_value de la target network segun la mejor accion en el estado siguiente\n",
        "        # si termina en este episodio, los q_values de target son 0 y dejamos solo el reward\n",
        "        q_target_s_a_prime = (1 - done_mask.type(torch.float)) * q_target_s_a_prime \n",
        "        \n",
        "        y = rew_t + gamma * q_target_s_a_prime\n",
        "\n",
        "      ## Loss calculation\n",
        "      q_values = Q(obs_t)\n",
        "      q_s_a = q_values.gather(1, act_t.unsqueeze(1)).squeeze() # selecciono el q de cada accion\n",
        "      error = (y - q_s_a) ** 2\n",
        "      error = torch.mean(error.clamp(-1, 1)) # clipeamos para estabilidad\n",
        "      error_history.append(error)\n",
        "\n",
        "      # backwards pass\n",
        "      optimizer.zero_grad()\n",
        "      error.backward()\n",
        "\n",
        "      # update\n",
        "      optimizer.step()\n",
        "      backprops += 1\n",
        "\n",
        "      # Actualizar pesos de red target (cada target_update_freq actualizaciones de los parámetros de Q)\n",
        "      if backprops % target_update_freq == 0:\n",
        "        print(\"Copying model wieghts...\")\n",
        "        Q_target.load_state_dict(Q.state_dict()) # copiamos pesos de Q a Qtarget\n",
        "    \n",
        "    if t % LOG_EVERY_N_STEPS == 0:\n",
        "      print(\"\\nEpoch:\", epoch + 1)\n",
        "      print(\"Current steps:\", t, \"Total Steps:\", total_steps)\n",
        "      try:\n",
        "        print(\"Last 5 rewards:\", episodes_rewards[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough rewards\")\n",
        "      try:\n",
        "        print(\"Last 5 epsilons:\", epsilon_history[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough epsilons\")\n",
        "      try:\n",
        "        print(\"Last 5 errors:\", error_history[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough errors\")\n",
        "      printm()\n",
        "      # Mostrar resultados actuales\n",
        "      # e.g. Mejor reward y promedio de ultimos 100 episodios\n",
        "      # entre otros.\n",
        "      \n",
        "\n",
        "    # Guardar modelo y resultados!\n",
        "    # importante si se les cierra el entrenamiento"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 167/250000 [00:00<05:04, 821.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Current steps: 0 Total Steps: 0\n",
            "Last 5 rewards: []\n",
            "Last 5 epsilons: []\n",
            "Last 5 errors: []\n",
            "RAM Free: 6.6 GB  | Used: 7.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 49993/250000 [00:55<03:49, 871.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Current steps: 50000 Total Steps: 50000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.955]\n",
            "Last 5 errors: []\n",
            "RAM Free: 6.6 GB  | Used: 7.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 67917/250000 [14:39<2:15:14, 22.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ce9aaf3013f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_q_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# selecciono indice de mejor q_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ejecuto accion seleccionada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# actualizo experiencia en buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcurrent_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/frame_stack.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-904df4f293bf>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_process_frame84\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8utkgyN96dY"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDFXLJCH99UX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGKiBwr299rv"
      },
      "source": [
        "###Testing visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4XKh9o1-CRo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "\n",
        "frames_show = frames[:300]\n",
        "\n",
        "plt.figure(figsize=(frames_show[0].shape[1] / 15.0, frames_show[0].shape[0] / 15.0), dpi = 72)\n",
        "patch = plt.imshow(frames_show[0],cmap='gray')\n",
        "plt.axis('off')\n",
        "animate = lambda i: patch.set_data(frames_show[i])\n",
        "ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(frames_show), interval = 100)\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
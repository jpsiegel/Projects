{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea3-DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPe/gjiesWBzxglm7ZMysFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpsiegel/Projects/blob/master/Tarea3_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ET622QKRj9"
      },
      "source": [
        "#Tarea 3 Jan P. Siegel - Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EARkwmAr12gB"
      },
      "source": [
        "##Allocate resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yumMEzxTJ1ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d69717-1772-491f-c3de-37ca7ef48fa2"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "import psutil\n",
        "import humanize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7ocfSQcd2bU",
        "outputId": "a5ee29cb-d989-475a-cb9a-1133093e2ce1"
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]  # Only one GPU on Colab and not guaranteed\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" | Used: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "  print(\"VRAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAM Free: 12.7 GB  | Used: 118.4 MB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvwy3-acKNKl",
        "outputId": "bfd7e06a-5e40-428c-ba73-e7fb73c3cbdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_dir = \"/content/drive/MyDrive/DL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGA7PU9ejJdl"
      },
      "source": [
        "# Download Roms\n",
        "!wget http://www.atarimania.com/roms/Roms.rar > /dev/null\n",
        "# Decompresed files\n",
        "!unrar e Roms.rar > /dev/null\n",
        "!unzip 'ROMS.zip' > /dev/null\n",
        "# Add Roms folder to atary_py PATH\n",
        "!python -m atari_py.import_roms 'ROMS' > /dev/null\n",
        "# > /dev/null omits command output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoWNXSTZ1xux"
      },
      "source": [
        "##Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WMiFXZSwGgD"
      },
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import cv2\n",
        "\n",
        "# pasar a escala de grises y recortar imagen\n",
        "def _process_frame84(frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    frame = frame[:155,10:]\n",
        "    #x_t = cv2.resize(frame, (84, 84),  interpolation=cv2.INTER_LINEAR)\n",
        "    x_t = cv2.resize(frame, (84, 84),interpolation=cv2.INTER_AREA)\n",
        "    return x_t.astype(np.uint8)\n",
        "\n",
        "class ProcessFrame84(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84))\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        return _process_frame84(obs), reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        return _process_frame84(self.env.reset())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "tqI3xgULw6nj",
        "outputId": "29d9d1ce-56e1-400d-a5c3-0b18deb05f29"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from gym.wrappers import AtariPreprocessing\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "#Create environment\n",
        "game = 'Enduro-v0'\n",
        "env = gym.make(game,frameskip=4) # saltamos de a 4 frames para acelerar entrenamiento\n",
        "\n",
        "# For reproducibility\n",
        "seed = 0\n",
        "env.seed(seed)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "plt.imshow(np.squeeze(obs))\n",
        "plt.title('Gym Enduro Interface')\n",
        "plt.show()\n",
        "\n",
        "env = ProcessFrame84(env) # pasamos el wrapper al enviroment\n",
        "env = FrameStack(env,num_stack=4) # un estado definido como el actual mas los 3 anteriores\n",
        "obs = env.reset()\n",
        "\n",
        "for _ in range(100):\n",
        "  action = random.randint(0,env.action_space.n-1) # seleccionar accion random\n",
        "  obs, reward, done, info = env.step(action)\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(np.squeeze(np.array(obs)[0,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(np.squeeze(np.array(obs)[1,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(np.squeeze(np.array(obs)[2,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(np.squeeze(np.array(obs)[3,:,:]),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"obs shape:\", obs.shape)\n",
        "print(\"actions:\", env.get_action_meanings(), \"amount:\", env.action_space.n)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "obs shape: (4, 84, 84)\n",
            "actions: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE'] amount: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6wuPkDuJjL"
      },
      "source": [
        "### Actividad 1\n",
        "Definimos un estado como un stack de el frame actual, más los 3 frames anteriores, por lo que cada estado (que será el input de la red) corresponde a 4 pasos de Enduro. Esto es clave para que la red convolucional pueda tener una noción de velocidad del jugador y de los demás competidores. La velocidad solo puede obtenerse comparando posiciones en frames contiguas, lo cual es información indispensable para que un agente pueda aprender a jugar Enduro competentemente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0YDMlXdjy7"
      },
      "source": [
        "### Fill replay memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tke1H0jD0Xfa"
      },
      "source": [
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = [] # Can be a list a Deque or another type of list\n",
        "        self.next_replace_position = 0\n",
        "\n",
        "    def push(self, state, action, next_state, reward, done):\n",
        "        \"\"\"Saves a transition.\n",
        "        e.g. ('state', 'action', 'next_state', 'reward','done')\n",
        "        \"\"\"\n",
        "        memory_data = (state, action, next_state, reward, done)\n",
        "        if len(self) >= self.capacity:\n",
        "          self.memory[self.next_replace_position] = memory_data\n",
        "          self.next_replace_position += 1\n",
        "          if self.next_replace_position > self.capacity - 1:\n",
        "            self.next_replace_position = 0\n",
        "        else:\n",
        "          self.memory.append(memory_data)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "       \"\"\" Samples a transition with a defined batch size\"\"\"\n",
        "       sampled_tuples = random.sample(self.memory, batch_size) # list of tuples\n",
        "       zipped = tuple(zip(*sampled_tuples))\n",
        "       return zipped\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSeQ-3WddCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0558d08-679e-433a-bd02-bca3c2c38c20"
      },
      "source": [
        "memory_size = 500000\n",
        "replay_memory = ReplayMemory(memory_size)\n",
        "\n",
        "print(\"Filling Replay Memory...\")\n",
        "current_obs = env.reset()\n",
        "for _ in range(memory_size):\n",
        "  if _ % 100000 == 0:\n",
        "    print(f\"{_}/{memory_size}\")\n",
        "  #print(_, replay_memory.next_replace_position, len(replay_memory))\n",
        "  action = random.randint(0,env.action_space.n-1) # seleccionar accion random\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  replay_memory.push(current_obs, action, obs, reward, done)\n",
        "  current_obs = obs\n",
        "  if done: # si pierde partimos nuevo episodio\n",
        "    current_obs = env.reset()\n",
        "  else:\n",
        "    current_obs = obs\n",
        "print(\"Memory Filled!, Space taken:\")\n",
        "printm()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling Replay Memory...\n",
            "0/500000\n",
            "100000/500000\n",
            "200000/500000\n",
            "300000/500000\n",
            "400000/500000\n",
            "Memory Filled!, Space taken:\n",
            "RAM Free: 10.7 GB  | Used: 7.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdzeHmvO7HZ4",
        "outputId": "4b4a6069-2088-4aba-c8d2-702dcb7feab2"
      },
      "source": [
        "a = tensor(4).item()\n",
        "print(a)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GRfqj131q9x"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD0EXVo_1FMy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class Dueling_DQN(nn.Module):\n",
        "    def __init__(self, in_channels, num_actions):\n",
        "        super(Dueling_DQN, self).__init__()\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "\n",
        "        self.fc1_val = nn.Linear(in_features=7*7*64, out_features=512)\n",
        "        self.fc2_val = nn.Linear(in_features=512, out_features=1)\n",
        "\n",
        "        self.fc1_adv = nn.Linear(in_features=7*7*64, out_features=512)\n",
        "        self.fc2_adv = nn.Linear(in_features=512, out_features=num_actions)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      # X es un tensor (batch_size x 4 x 84 x 84) que representa un batch de stacks de estados\n",
        "      batch_size = x.size(0)\n",
        "\n",
        "      # forward pass red convolucional\n",
        "      x = self.relu(self.conv1(x))\n",
        "      x = self.relu(self.conv2(x))\n",
        "      x = self.relu(self.conv3(x))\n",
        "      x = torch.flatten(x, start_dim=1) # start_dim 1 para mantener separado el batch\n",
        "      #print(\"State embedding:\", x.shape, x)\n",
        "      \n",
        "      # forward pass rama fully-connected para V(s)\n",
        "      v_s = self.relu(self.fc1_val(x))\n",
        "      v_s = self.fc2_val(v_s).expand(batch_size, self.num_actions)\n",
        "      #print(\"V(s):\", v_s.shape, v_s)\n",
        "\n",
        "      # forward pass rama fully-connected para A(s,a)\n",
        "      adv = self.relu(self.fc1_adv(x))\n",
        "      adv = self.fc2_adv(adv)\n",
        "      #print(\"A(s,a):\", adv.shape, adv)\n",
        "      #print(\"mean A(s,a):\", torch.mean(adv, 1, keepdim=True).shape, torch.mean(adv, 1, keepdim=True))\n",
        "\n",
        "      # Calculo de Q(s,a) a partir de ecuacion (4)\n",
        "      Q_values = v_s + (adv - torch.mean(adv, 1, keepdim=True)) # testeado\n",
        "\n",
        "      return Q_values # batch_size x num_actions"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i719vkMq1srh"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C77orgGvqGui"
      },
      "source": [
        "def exploration(total_steps):\n",
        "  \"\"\" retorna probabilidad de que explore con accion random \"\"\"\n",
        "  if total_steps >= 1000000:\n",
        "    epsilon = 0.1\n",
        "  else:\n",
        "    m = -0.9 / 1000000\n",
        "    n = 1\n",
        "    epsilon = m * total_steps + n\n",
        "  return epsilon"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv1TE3Vv3WsX"
      },
      "source": [
        "# Define parameters and instance NNs\n",
        "\n",
        "from torch import device\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "frame_history_len = 4 # Cantidad de frames de cada estado (definido en el pre-procesamiento)\n",
        "batch_size = 32\n",
        "gamma = 0.99 # Factor de descuento\n",
        "learning_starts = 50000 # Paso en que se comienza a utilizar la red para escoger acciones (siguiendo política e-greedy)\n",
        "learning_freq = 4 # Frecuencia de pasos en que se modifican los pesos (loss backprop) en la red Q\n",
        "target_update_freq = 10000 # Frecuencia en que se actualizan los pesos de la red target Q' (cada x backprops, updateo Q')\n",
        "LR = 0.00025 # Tasa de aprendizaje\n",
        "\n",
        "in_channels = frame_history_len\n",
        "input_shape = (84,84)\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "# define Q target and Q \n",
        "Q = Dueling_DQN(in_channels, num_actions).to(device) # esta es la que de verdad quiero entrenar\n",
        "Q_target = Dueling_DQN(in_channels, num_actions).to(device) # para estabilidad, esta me entrega los labels\n",
        "\n",
        "# Optimizador, pueden elegir entre Adam o RMSProp\n",
        "optimizer = optim.Adam(Q.parameters(), lr=LR)\n",
        "\n",
        "LOG_EVERY_N_STEPS = 50000 # (Opcional) Frecuencia en la que se muestran resultados en consola\n",
        "STEPS_PER_EPOCH = 250000 # Pasos por época\n",
        "N_EPOCHS = 10 # Número de épocas"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37rt28Z01owa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1034274-7a95-4a6f-d0d9-35a4ee97c961"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch import tensor, no_grad\n",
        "import numpy as np\n",
        "\n",
        "# Load checkpoint: probablemente se quede sin memoria durante entrenamiento,\n",
        "# por eso hay que guardar checkpoint (pesos) en drive cada cierto tiempo\n",
        "# luego cargamos checkpoint, rellenamos memory buffer, y retomamos\n",
        "# pero el rellenado debe ser usando el modelo que tenemos hasta ahora! no random como el inicial\n",
        "\n",
        "# Reseteamos nuestro ambiente para empezar el entrenamiento\n",
        "last_obs = env.reset()\n",
        "current_reward = 0\n",
        "backprops = 0\n",
        "episodes_rewards = []\n",
        "epsilon_history = []\n",
        "error_history = []\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS),position=0,leave=True):\n",
        "  for t in tqdm(range(STEPS_PER_EPOCH),position=0,leave=True):\n",
        "    total_steps = t + STEPS_PER_EPOCH * epoch # steps acumulados a traves de las epocas\n",
        "    ### 1. Choose actions and update replay memory buffer\n",
        "    if t < learning_starts and epoch == 0:\n",
        "      action = np.random.randint(num_actions)\n",
        "    else:\n",
        "      # epsilon greedy exploration\n",
        "      sample = random.random()\n",
        "      threshold = exploration(total_steps)  # la funcion exploration permite calcular el threshold para la política e-greedy\n",
        "      epsilon_history.append(threshold)\n",
        "      if sample <= threshold:\n",
        "        action = np.random.randint(num_actions)\n",
        "      else:\n",
        "        with no_grad(): # no actualizamos gradientes pq estamos evaluando\n",
        "          # Seleccionar la acción segun la red Q\n",
        "          last_obs_tensor = torch.from_numpy(np.array(last_obs)).to(device) / 255.0 # pasamos a tensor y normalizamos\n",
        "          last_obs_tensor_batched = last_obs_tensor.unsqueeze(0).repeat(batch_size, 1, 1, 1) # last obs solo es 1 estado, pero necesitamos batch_size estados para la red\n",
        "          all_q_values = Q(last_obs_tensor_batched)\n",
        "          action = ((all_q_values).data.max(1)[1])[0].item() # selecciono indice de mejor q_value\n",
        "\n",
        "    obs, reward, done, _ = env.step(action) # ejecuto accion seleccionada\n",
        "    replay_memory.push(last_obs, action, obs, reward, done) # actualizo experiencia en buffer\n",
        "    current_reward += reward\n",
        "    if done:\n",
        "      # Termino episodio!\n",
        "      obs = env.reset()\n",
        "      # Guardar reward acumulado del episodio\n",
        "      episodes_rewards.append(current_reward)\n",
        "      current_reward = 0\n",
        "\n",
        "    # update last_obs\n",
        "    last_obs = obs\n",
        "\n",
        "    ### 2. Perform experience replay and train the network.\n",
        "    if (t > learning_starts and t % learning_freq == 0):\n",
        "      obs_t, act_t, next_obs, rew_t, done_mask = replay_memory.sample(batch_size) # esto me deja listas de largo batch size\n",
        "      # Pasar los arreglos a tensores y al device actual\n",
        "      obs_t = torch.from_numpy(np.array(obs_t)).to(device)\n",
        "      act_t = torch.from_numpy(np.array(act_t)).to(device)\n",
        "      next_obs = torch.from_numpy(np.array(next_obs)).to(device)\n",
        "      rew_t = torch.from_numpy(np.array(rew_t)).to(device)\n",
        "      done_mask = torch.from_numpy(np.array(done_mask)).to(device)\n",
        "\n",
        "      # Normalizar tensores de entrada\n",
        "      obs_t = obs_t / 255.0\n",
        "      next_obs = next_obs / 255.0\n",
        "\n",
        "      # construir Y (labels)\n",
        "      with no_grad(): # esto no debe ser parte del backprop, solo consigue los labels\n",
        "        q_tp1_values = Q(next_obs)\n",
        "        _, a_prime = q_tp1_values.max(1) # selecciono la mejor accion para el estado siguiente\n",
        "        q_target_tp1_values = Q_target(next_obs)\n",
        "        q_target_s_a_prime = q_target_tp1_values.gather(1, a_prime.unsqueeze(1)).squeeze() # selecciono el q_value de la target network segun la mejor accion en el estado siguiente\n",
        "        # si termina en este episodio, los q_values de target son 0 y dejamos solo el reward\n",
        "        q_target_s_a_prime = (1 - done_mask.type(torch.float)) * q_target_s_a_prime \n",
        "        \n",
        "        y = rew_t + gamma * q_target_s_a_prime\n",
        "\n",
        "      ## Loss calculation\n",
        "      q_values = Q(obs_t)\n",
        "      q_s_a = q_values.gather(1, act_t.unsqueeze(1)).squeeze() # selecciono el q de cada accion\n",
        "      error = (y - q_s_a) ** 2\n",
        "      error = torch.mean(error.clamp(-1, 1)) # clipeamos para estabilidad\n",
        "      error_history.append(error)\n",
        "\n",
        "      # backwards pass\n",
        "      optimizer.zero_grad()\n",
        "      error.backward()\n",
        "\n",
        "      # update\n",
        "      optimizer.step()\n",
        "      backprops += 1\n",
        "\n",
        "      # Actualizar pesos de red target (cada target_update_freq actualizaciones de los parámetros de Q)\n",
        "      if backprops % target_update_freq == 0:\n",
        "        print(\"Copying model wieghts...\")\n",
        "        Q_target.load_state_dict(Q.state_dict()) # copiamos pesos de Q a Qtarget\n",
        "    \n",
        "    if t % LOG_EVERY_N_STEPS == 0:\n",
        "      print(\"\\nEpoch:\", epoch + 1)\n",
        "      print(\"Current steps:\", t, \"Total Steps:\", total_steps)\n",
        "      try:\n",
        "        print(\"Last 5 rewards:\", episodes_rewards[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough rewards\")\n",
        "      try:\n",
        "        print(\"Last 5 epsilons:\", epsilon_history[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough epsilons\")\n",
        "      try:\n",
        "        print(\"Last 5 errors:\", error_history[-5:])\n",
        "      except IndexError:\n",
        "        print(\"Not enough errors\")\n",
        "      printm()\n",
        "      # Mostrar resultados actuales\n",
        "      # e.g. Mejor reward y promedio de ultimos 100 episodios\n",
        "      # entre otros.\n",
        "  model_save_path = my_dir + \"/DQN_model{}.pt\".format(epoch)\n",
        "  torch.save(Q.state_dict(), model_save_path)    \n",
        "\n",
        "    # Guardar modelo y resultados!\n",
        "    # importante si se les cierra el entrenamiento"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 182/250000 [00:00<04:36, 904.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Current steps: 0 Total Steps: 0\n",
            "Last 5 rewards: []\n",
            "Last 5 epsilons: []\n",
            "Last 5 errors: []\n",
            "RAM Free: 10.7 GB  | Used: 7.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 50031/250000 [00:54<04:19, 771.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Current steps: 50000 Total Steps: 50000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.955]\n",
            "Last 5 errors: []\n",
            "RAM Free: 10.7 GB  | Used: 7.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 90037/250000 [03:01<08:42, 306.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 100056/250000 [03:34<08:07, 307.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Current steps: 100000 Total Steps: 100000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.9100036, 0.9100026999999999, 0.9100018, 0.9100009, 0.91]\n",
            "Last 5 errors: [tensor(5.0542e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.2453e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(3.8949e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.6644e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(5.0048e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.6 GB  | Used: 8.0 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 130045/250000 [05:11<06:33, 305.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 150047/250000 [06:16<05:32, 300.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Current steps: 150000 Total Steps: 150000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.8650036, 0.8650027, 0.8650017999999999, 0.8650009, 0.865]\n",
            "Last 5 errors: [tensor(2.2542e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(9.4088e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.4403e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.0095e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.3219e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.6 GB  | Used: 8.2 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 170049/250000 [07:23<04:26, 300.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 200049/250000 [09:03<02:58, 279.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "Current steps: 200000 Total Steps: 200000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.8200035999999999, 0.8200027, 0.8200018, 0.8200008999999999, 0.82]\n",
            "Last 5 errors: [tensor(3.1488e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.9118e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.5854e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.3721e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(8.2863e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.6 GB  | Used: 8.5 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 210049/250000 [09:37<02:15, 295.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [11:53<00:00, 350.41it/s]\n",
            "  0%|          | 140/250000 [00:00<06:16, 662.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Current steps: 0 Total Steps: 250000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.7750036, 0.7750026999999999, 0.7750018, 0.7750009, 0.775]\n",
            "Last 5 errors: [tensor(2.5575e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.0117e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(3.6808e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.4818e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.2223e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.6 GB  | Used: 8.8 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 50001/250000 [01:12<05:14, 635.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Current steps: 50000 Total Steps: 300000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.7300036, 0.7300027, 0.7300017999999999, 0.7300009000000001, 0.73]\n",
            "Last 5 errors: [tensor(2.5575e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.0117e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(3.6808e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.4818e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.2223e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.6 GB  | Used: 8.8 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n",
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 90056/250000 [03:32<09:31, 280.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 100049/250000 [04:07<08:47, 284.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Current steps: 100000 Total Steps: 350000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.6850035999999999, 0.6850027, 0.6850018, 0.6850008999999999, 0.685]\n",
            "Last 5 errors: [tensor(3.9240e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.9430e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(8.9903e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.0758e-07, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(8.6700e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.5 GB  | Used: 9.0 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 130037/250000 [05:52<07:10, 278.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 150041/250000 [07:03<06:08, 271.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Current steps: 150000 Total Steps: 400000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.6400036, 0.6400026999999999, 0.6400018, 0.6400009, 0.6399999999999999]\n",
            "Last 5 errors: [tensor(4.7482e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.3531e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(3.5979e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.8169e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(3.4467e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.5 GB  | Used: 9.3 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 170048/250000 [08:14<04:38, 286.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 200047/250000 [10:03<03:13, 258.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2\n",
            "Current steps: 200000 Total Steps: 450000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.5950036, 0.5950027, 0.5950017999999999, 0.5950008999999999, 0.595]\n",
            "Last 5 errors: [tensor(6.3654e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.3391e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.3489e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.5501e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.5212e-08, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.5 GB  | Used: 9.6 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 210045/250000 [10:40<02:25, 273.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [13:06<00:00, 317.92it/s]\n",
            "  0%|          | 125/250000 [00:00<06:49, 609.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3\n",
            "Current steps: 0 Total Steps: 500000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.5500035999999999, 0.5500027, 0.5500018, 0.5500008999999999, 0.55]\n",
            "Last 5 errors: [tensor(3.7195e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.7447e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(5.6007e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.7152e-11, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.5209e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.5 GB  | Used: 9.8 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 50027/250000 [01:24<06:56, 480.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3\n",
            "Current steps: 50000 Total Steps: 550000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.5050036, 0.5050026999999999, 0.5050018, 0.5050009, 0.5049999999999999]\n",
            "Last 5 errors: [tensor(3.7195e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.7447e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(5.6007e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.7152e-11, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.5209e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.5 GB  | Used: 9.9 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n",
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 90053/250000 [03:52<09:58, 267.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 100033/250000 [04:29<09:17, 268.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3\n",
            "Current steps: 100000 Total Steps: 600000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.46000359999999996, 0.4600027, 0.4600018, 0.46000089999999993, 0.45999999999999996]\n",
            "Last 5 errors: [tensor(3.4409e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(6.4525e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(6.4206e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.6292e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(8.0934e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.4 GB  | Used: 10.1 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 130061/250000 [06:21<07:26, 268.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 150029/250000 [07:35<06:19, 263.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3\n",
            "Current steps: 150000 Total Steps: 650000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.4150035999999999, 0.41500269999999995, 0.4150018, 0.4150009, 0.4149999999999999]\n",
            "Last 5 errors: [tensor(9.9929e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.7736e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(6.5489e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.0091e-09, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(9.0631e-10, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.4 GB  | Used: 10.4 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 170051/250000 [08:51<04:54, 271.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 200041/250000 [10:45<03:16, 254.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3\n",
            "Current steps: 200000 Total Steps: 700000\n",
            "Last 5 rewards: [0.0, 2.0, 2.0, 9.0, 0.0]\n",
            "Last 5 epsilons: [0.3700036, 0.3700026999999999, 0.37000179999999994, 0.37000089999999997, 0.37]\n",
            "Last 5 errors: [tensor(5.6966e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(6.1078e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.3081e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.6540e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(2.7514e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.4 GB  | Used: 10.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 210057/250000 [11:23<02:31, 264.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [13:55<00:00, 299.23it/s]\n",
            "  0%|          | 116/250000 [00:00<07:19, 568.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4\n",
            "Current steps: 0 Total Steps: 750000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 1.0, 1.0]\n",
            "Last 5 epsilons: [0.32500359999999995, 0.3250027, 0.3250017999999999, 0.3250008999999999, 0.32499999999999996]\n",
            "Last 5 errors: [tensor(0.0313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(5.5566e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(9.2691e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(5.4411e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.0467e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.4 GB  | Used: 10.9 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 50016/250000 [01:37<07:15, 458.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4\n",
            "Current steps: 50000 Total Steps: 800000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.2800035999999999, 0.28000269999999994, 0.28000179999999997, 0.2800009, 0.2799999999999999]\n",
            "Last 5 errors: [tensor(0.0313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(5.5566e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(9.2691e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(5.4411e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.0467e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 10.4 GB  | Used: 10.9 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n",
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 90049/250000 [04:13<10:32, 253.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 100027/250000 [04:52<10:14, 244.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4\n",
            "Current steps: 100000 Total Steps: 850000\n",
            "Last 5 rewards: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Last 5 epsilons: [0.23500359999999998, 0.2350026999999999, 0.23500179999999993, 0.23500089999999996, 0.235]\n",
            "Last 5 errors: [tensor(4.5268e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.8606e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(4.1602e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.0483e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(7.4516e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 9.4 GB  | Used: 11.2 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 130041/250000 [06:50<07:55, 252.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 150024/250000 [08:10<06:32, 254.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4\n",
            "Current steps: 150000 Total Steps: 900000\n",
            "Last 5 rewards: [0.0, 1.0, 4.0, 30.0, 0.0]\n",
            "Last 5 epsilons: [0.19000359999999994, 0.19000269999999997, 0.1900017999999999, 0.19000089999999992, 0.18999999999999995]\n",
            "Last 5 errors: [tensor(0.0313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(6.4222e-06, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.5284e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.3863e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>), tensor(1.4462e-05, device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 9.4 GB  | Used: 11.5 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 170055/250000 [09:30<05:17, 252.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 200029/250000 [11:30<03:18, 251.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4\n",
            "Current steps: 200000 Total Steps: 950000\n",
            "Last 5 rewards: [16.0, 0.0, 2.0, 16.0, 3.0]\n",
            "Last 5 epsilons: [0.1450035999999999, 0.14500269999999993, 0.14500179999999996, 0.1450009, 0.1449999999999999]\n",
            "Last 5 errors: [tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0298, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0298, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 9.4 GB  | Used: 11.7 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 210064/250000 [12:10<02:38, 252.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [14:52<00:00, 280.22it/s]\n",
            "  0%|          | 107/250000 [00:00<08:04, 516.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5\n",
            "Current steps: 0 Total Steps: 1000000\n",
            "Last 5 rewards: [13.0, 23.0, 14.0, 7.0, 18.0]\n",
            "Last 5 epsilons: [0.10000359999999997, 0.10000269999999989, 0.10000179999999992, 0.10000089999999995, 0.1]\n",
            "Last 5 errors: [tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 8.5 GB  | Used: 12.0 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 50003/250000 [01:48<07:36, 437.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5\n",
            "Current steps: 50000 Total Steps: 1050000\n",
            "Last 5 rewards: [4.0, 29.0, 8.0, 22.0, 10.0]\n",
            "Last 5 epsilons: [0.1, 0.1, 0.1, 0.1, 0.1]\n",
            "Last 5 errors: [tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 8.5 GB  | Used: 12.0 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n",
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 90056/250000 [04:31<10:40, 249.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 100029/250000 [05:12<10:18, 242.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5\n",
            "Current steps: 100000 Total Steps: 1100000\n",
            "Last 5 rewards: [21.0, 16.0, 11.0, 40.0, 11.0]\n",
            "Last 5 epsilons: [0.1, 0.1, 0.1, 0.1, 0.1]\n",
            "Last 5 errors: [tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0300, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0315, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0940, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 7.3 GB  | Used: 12.3 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 130049/250000 [07:15<08:07, 246.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 150036/250000 [08:36<06:48, 244.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5\n",
            "Current steps: 150000 Total Steps: 1150000\n",
            "Last 5 rewards: [28.0, 6.0, 14.0, 7.0, 24.0]\n",
            "Last 5 epsilons: [0.1, 0.1, 0.1, 0.1, 0.1]\n",
            "Last 5 errors: [tensor(0.0922, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0315, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0301, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 2.6 GB  | Used: 12.4 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 170053/250000 [09:57<05:24, 246.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 200041/250000 [11:59<03:29, 238.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5\n",
            "Current steps: 200000 Total Steps: 1200000\n",
            "Last 5 rewards: [11.0, 46.0, 32.0, 28.0, 43.0]\n",
            "Last 5 epsilons: [0.1, 0.1, 0.1, 0.1, 0.1]\n",
            "Last 5 errors: [tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0227, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.1237, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>), tensor(0.0627, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)]\n",
            "RAM Free: 1.6 GB  | Used: 12.4 GB\n",
            "VRAM Free: 15109MB | Used: 0MB | Util   0% Total 15109MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 210060/250000 [12:40<02:48, 237.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying model wieghts...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 211222/250000 [21:36<129:39:21, 12.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-144acfe7dd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# no actualizamos gradientes pq estamos evaluando\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0;31m# Seleccionar la acción segun la red Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mlast_obs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m \u001b[0;31m# pasamos a tensor y normalizamos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mlast_obs_tensor_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_obs_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# last obs solo es 1 estado, pero necesitamos batch_size estados para la red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mall_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_obs_tensor_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8utkgyN96dY"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lDh4HKJS9aL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGKiBwr299rv"
      },
      "source": [
        "###Testing visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4XKh9o1-CRo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "\n",
        "frames_show = frames[:300]\n",
        "\n",
        "plt.figure(figsize=(frames_show[0].shape[1] / 15.0, frames_show[0].shape[0] / 15.0), dpi = 72)\n",
        "patch = plt.imshow(frames_show[0],cmap='gray')\n",
        "plt.axis('off')\n",
        "animate = lambda i: patch.set_data(frames_show[i])\n",
        "ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(frames_show), interval = 100)\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}